{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OFDSdvxj6ApJ",
    "outputId": "8d7e03b8-3c29-4e9e-f4a0-dd1b619499a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PySastrawi in c:\\users\\dzikr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install PySastrawi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sgol4Y_Y6ApP",
    "outputId": "bd880933-4700-4196-d8e7-bf0eeea86d4f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dzikr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "nMmyJPc5v2s8"
   },
   "outputs": [],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import pickle\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import nltk\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras import layers, models, callbacks, optimizers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "AyCMTd3BxH5v"
   },
   "outputs": [],
   "source": [
    "# Load the intents file\n",
    "with open('nlp_dataset_faq.json') as data_file:\n",
    "    intents = json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LzYlZchPxkrj",
    "outputId": "a02e3f10-25e2-49bd-99e0-2e6b517310d9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\dzikr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download the 'punkt_tab' data package\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Pre-processing\n",
    "words = []\n",
    "classes = []\n",
    "documents = []\n",
    "ignore = ['','!', '\"', \"'\", '(', ')', ',', '-', '.', ':', ';', '?', '[', ']', '_',\n",
    "          'adalah', 'akan', 'aku', 'anda', 'atau', 'dalam', 'dan',\n",
    "          'dari', 'dengan', 'di', 'dia', 'harus', 'ini', 'itu', 'jika', 'kami', 'kamu', 'ke',\n",
    "          'kita', 'mereka', 'oleh', 'pada', 'saya', 'sebuah', 'sedang', 'sementara', 'tanpa',\n",
    "          'tapi', 'telah', 'untuk', 'yang', '{', '}', 'merasa']\n",
    "\n",
    "\n",
    "\n",
    "#tokenize\n",
    "for intent in intents:\n",
    "    for pattern in intent['patterns']:\n",
    "        w = nltk.word_tokenize(pattern.lower())  # Tokenizing\n",
    "        words.extend([word for word in w if word not in ignore])  #Ignore\n",
    "        documents.append((w, intent['tag']))\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3OjNRWsryAlH",
    "outputId": "ad6913c3-fa46-4cf9-c12c-29f3ab63c088"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1535 documents\n",
      "76 classes ['apa_itu_gangguan_mental', 'badmood_dampak', 'badmood_efek_jangka_panjang', 'badmood_gejala', 'badmood_pengobatan', 'badmood_penyebab', 'badmood_preventif', 'badmood_solusi_pribadi', 'badmood_terhadap_kesehatan_fisik', 'badmood_terhadap_pekerjaan', 'bunuh_diri', 'cara_mengatasi_benci', 'cara_mengatasi_bingung', 'cara_mengatasi_cemburu', 'cara_mengatasi_dendam', 'cara_mengatasi_frustasi', 'cara_mengatasi_gangguan_mental', 'cara_mengatasi_hampa', 'cara_mengatasi_iri', 'cara_mengatasi_kecewa', 'cara_mengatasi_kesal', 'cara_mengatasi_malu', 'cara_mengatasi_marah', 'cara_mengatasi_merasa_sendiri', 'cara_mengatasi_sedih', 'cara_mengatasi_takut', 'cara_mengatasi_takut_gagal', 'cara_mengatasi_tidak_dihargai', 'diagnosis_gangguan_mental', 'dukungan_mental_terapi', 'efek_gangguan_mental', 'emosi_bingung', 'emosi_frustrasi', 'emosi_hampa', 'emosi_kecewa', 'emosi_lelah', 'emosi_marah', 'emosi_sedih', 'emosi_senang', 'emosi_takut', 'emosi_takut_gagal', 'emosi_terbebani', 'emosi_tertekan', 'emosi_tidak_dihargai', 'gangguan_mental_dan_bipolar', 'gangguan_mental_dan_depresi', 'gangguan_mental_dan_kecemasan', 'gangguan_mental_dan_psikoedukasi', 'gangguan_mental_dan_psikoterapi', 'gangguan_mental_dan_stigma', 'gangguan_mental_untuk_anak', 'gejala_gangguan_mental', 'kabar_baik', 'kabar_buruk', 'kabar_netral', 'mood_bahagia', 'mood_cemas', 'mood_marahan', 'mood_membaik', 'mood_motivation', 'mood_sedih', 'mood_stress_relief', 'penanganan_gangguan_mental', 'pencegahan_gangguan_mental', 'pengobatan_gangguan_mental', 'penyebab_gangguan_mental', 'perbedaan_gangguan_mental_dan_stres', 'perkenalan_diri', 'perpisahan', 'salam_halo', 'salam_hi_tes', 'salam_terima_kasih', 'sapaan_pagi', 'sapaan_tanya_kabar', 'tanya_bantuan_terdekat', 'ucapan_terima_kasih']\n",
      "528 unique stemmed words ['abai', 'ada', 'adil', 'agar', 'ahli', 'ajar', 'akhir', 'akibat', 'aktif', 'aktivitas', 'aku', 'alami', 'alas', 'alih', 'alkohol', 'aman', 'amarah', 'amarahku', 'ambil', 'anak', 'anggap', 'antara', 'antidepresan', 'apa', 'apakah', 'arah', 'arti', 'asa', 'asal', 'asmara', 'atas', 'atur', 'awal', 'awat', 'bad', 'badan', 'bagai', 'bagaimana', 'bagi', 'bahagia', 'bahaya', 'bahwa', 'baik', 'balas', 'balik', 'banget', 'bangkit', 'bantu', 'banyak', 'baru', 'beban', 'beda', 'begitu', 'belum', 'benar', 'benci', 'berani', 'berapa', 'berat', 'beri', 'besar', 'biar', 'biasa', 'bicara', 'bingung', 'bipolar', 'bisa', 'boleh', 'buat', 'bugar', 'bukan', 'buruk', 'butuh', 'capai', 'capek', 'cara', 'cari', 'cegah', 'cemas', 'cemburu', 'cepat', 'cerah', 'cerita', 'cerna', 'chat', 'chatbot', 'cinta', 'ciri', 'coba', 'cuaca', 'cukup', 'dadah', 'damai', 'dampak', 'dapat', 'darah', 'datang', 'daya', 'definisi', 'dekat', 'dendam', 'dengan', 'dengar', 'depan', 'depresi', 'derita', 'deteksi', 'dewasa', 'diagnosis', 'diet', 'diri', 'dokter', 'dong', 'down', 'dukung', 'dunia', 'edukasi', 'efek', 'efektif', 'ekonomi', 'ekspektasi', 'elektrokonvulsif', 'emosi', 'emosional', 'enak', 'energi', 'energik', 'episode', 'erti', 'faktor', 'fisik', 'fokus', 'frustrasi', 'fungsi', 'gagal', 'ganggu', 'gaya', 'gejala', 'gelap', 'gelisah', 'gembira', 'genetik', 'genetika', 'guna', 'habis', 'hadap', 'hai', 'hal', 'halang', 'hallo', 'halo', 'hambat', 'hampa', 'hantu', 'hanya', 'harap', 'harga', 'hari', 'hasil', 'hati', 'hebat', 'henti', 'hi', 'hidup', 'hilang', 'hindar', 'hormat', 'hormon', 'hubung', 'identifikasi', 'ikut', 'implementasi', 'imun', 'indikator', 'individu', 'ingin', 'insomnia', 'inspirasi', 'intens', 'intervensi', 'iri', 'isi', 'isolasi', 'istimewa', 'istirahat', 'jadi', 'jaga', 'jalan', 'jangka', 'jawab', 'jebak', 'jelas', 'jenak', 'jengkel', 'jenis', 'jepit', 'jernih', 'juga', 'jumpa', 'jurnal', 'kabar', 'kait', 'kalau', 'kantor', 'karena', 'kasih', 'kata', 'kategori', 'kebal', 'kecewa', 'kecil', 'kelola', 'kelompok', 'keluar', 'keluarga', 'kemarin', 'kembali', 'kembang', 'kena', 'kenal', 'kenapa', 'kendali', 'kepada', 'kepala', 'keras', 'kerja', 'kerjasamanya', 'kesal', 'ketika', 'kewalahan', 'khawatir', 'khianat', 'khusus', 'kognitif', 'komunikasi', 'kondisi', 'konflik', 'konselor', 'kontrol', 'kosong', 'kronis', 'kualitas', 'kuasa', 'kunjung', 'kurang', 'lagi', 'lain', 'laku', 'lalu', 'lama', 'lancar', 'lang', 'langkah', 'langsung', 'lanjut', 'lari', 'lawan', 'layan', 'layar', 'lebih', 'ledak', 'lelah', 'lemah', 'lengkap', 'lepas', 'lesu', 'lewat', 'libat', 'lihat', 'lingkung', 'luap', 'luar', 'luka', 'lumpuh', 'lupa', 'maju', 'makan', 'makasih', 'makin', 'makna', 'maksud', 'malam', 'malas', 'malu', 'mampu', 'mana', 'mandiri', 'manfaat', 'mania', 'marah', 'masa', 'masalah', 'masuk', 'masyarakat', 'mati', 'medis', 'meditasi', 'menang', 'mengapa', 'menghadang', 'mental', 'meski', 'metabolisme', 'metode', 'mikrofon', 'milik', 'moga', 'mood', 'moodku', 'moral', 'motivasi', 'mudah', 'mulai', 'muncul', 'murung', 'musik', 'nali', 'nama', 'nan', 'napas', 'negatif', 'netral', 'nggak', 'nih', 'nomor', 'normal', 'nyaman', 'nyata', 'obat', 'olah', 'olahraga', 'optimis', 'orang', 'pagi', 'paham', 'paling', 'panggil', 'panjang', 'parah', 'pasti', 'peduli', 'pengaruh', 'penting', 'penuh', 'peran', 'perangkap', 'percaya', 'pergi', 'perhati', 'periksa', 'perilaku', 'peristiwa', 'perlu', 'pernah', 'pertama', 'picu', 'pikir', 'pikul', 'pilih', 'pola', 'positif', 'preventif', 'pribadi', 'produktif', 'produktivitas', 'profesional', 'proses', 'psikoedukasi', 'psikologi', 'psikologis', 'psikoterapi', 'psikoterapis', 'puas', 'pulih', 'pun', 'pundak', 'punya', 'puruk', 'putus', 'ragu', 'rasa', 'reda', 'rekan', 'rekomendasi', 'relaksasi', 'remaja', 'remeh', 'rencana', 'rendah', 'rentan', 'rileks', 'risiko', 'rumah', 'rusak', 'saat', 'sabar', 'sadar', 'saja', 'sakit', 'salah', 'sama', 'sampai', 'sana', 'sangat', 'santai', 'saran', 'sebab', 'sebut', 'sedia', 'sedih', 'sedikit', 'segala', 'segar', 'segera', 'sehat', 'sekali', 'sekaligus', 'sekarang', 'sekitar', 'selalu', 'selamat', 'selesai', 'semangat', 'sembuh', 'sempurna', 'semua', 'senang', 'sendiri', 'seperti', 'sepi', 'serah', 'sering', 'serta', 'sesal', 'sesat', 'sesi', 'sesuai', 'sesuatu', 'sia', 'siap', 'siapa', 'sibuk', 'sih', 'sikap', 'simpan', 'singgung', 'singkat', 'sini', 'sisa', 'sistem', 'situasi', 'solusi', 'sosial', 'spesial', 'stabil', 'stigma', 'stres', 'suara', 'suasana', 'sudah', 'suka', 'sulit', 'supaya', 'syukur', 'tahan', 'tahu', 'tak', 'takut', 'tanda', 'tangan', 'tanggung', 'tanya', 'target', 'tarik', 'tegang', 'tekan', 'teknik', 'telah', 'telepon', 'teman', 'tempat', 'temu', 'tenang', 'tengah', 'tenggelam', 'tentang', 'tentu', 'tepat', 'terap', 'terapi', 'terima', 'terlalu', 'terus', 'tes', 'tetap', 'tetapi', 'tiap', 'tiba', 'tidak', 'tidur', 'tinggal', 'tinggi', 'tingkat', 'tips', 'tolong', 'tonjol', 'trauma', 'tua', 'tubuh', 'tuju', 'tunjuk', 'tuntut', 'turun', 'uang', 'ubah', 'ujung', 'umum', 'untung', 'usaha', 'utama', 'waktu', 'waris', 'warna', 'was-was', 'waspada', 'ya', 'yakin', 'yoga']\n"
     ]
    }
   ],
   "source": [
    "# Melakukan stemming dan normalisasi data\n",
    "words = [stemmer.stem(w.lower()) for w in words if w not in ignore]\n",
    "words = sorted(list(set(words)))\n",
    "\n",
    "# Menghapus class duplikat dengan 'set'\n",
    "classes = sorted(list(set(classes)))\n",
    "\n",
    "print(len(documents), \"documents\")\n",
    "print(len(classes), \"classes\", classes)\n",
    "print(len(words), \"unique stemmed words\", words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "o3bG67i3yL2q"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "training = []\n",
    "output_empty = [0] * len(classes)\n",
    "\n",
    "for doc in documents:\n",
    "    pattern_words = [stemmer.stem(word.lower()) for word in doc[0]]\n",
    "    bag = [1 if w in pattern_words else 0 for w in words]\n",
    "\n",
    "    output_row = output_empty[:]\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "\n",
    "    training.append([bag, output_row])\n",
    "\n",
    "random.shuffle(training)\n",
    "training = np.array(training, dtype=object)\n",
    "\n",
    "train_x = np.array([item[0] for item in training])\n",
    "train_y = np.array([item[1] for item in training])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "        layers.Input(shape=(len(train_x[0]),), name='input_layer'),\n",
    "        layers.Dense(256, activation='relu', kernel_regularizer='l2', name='hidden_layer1'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3, name='dropout1'),\n",
    "        layers.Dense(128, activation='relu', kernel_regularizer='l2', name='hidden_layer2'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3, name='dropout2'),\n",
    "        layers.Dense(len(train_y[0]), activation='softmax', name='output_layer')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ hidden_layer1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">135,424</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ hidden_layer2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">76</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,804</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ hidden_layer1 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m135,424\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout1 (\u001b[38;5;33mDropout\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ hidden_layer2 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout2 (\u001b[38;5;33mDropout\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m76\u001b[0m)                  │           \u001b[38;5;34m9,804\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">179,660</span> (701.80 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m179,660\u001b[0m (701.80 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">178,892</span> (698.80 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m178,892\u001b[0m (698.80 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K_FOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2j75XSbGyalB",
    "outputId": "bbad24ff-51fd-4440-d144-bfe4011cf099"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dzikr\\AppData\\Local\\Temp\\ipykernel_1124\\3785205646.py:1: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "\n",
      "=== Training Fold 1/5 ===\n",
      "Epoch 1/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0158 - loss: 9.9675 - val_accuracy: 0.0261 - val_loss: 8.6633\n",
      "Epoch 2/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0277 - loss: 8.8465 - val_accuracy: 0.0293 - val_loss: 8.2045\n",
      "Epoch 3/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0488 - loss: 8.2125 - val_accuracy: 0.0586 - val_loss: 7.6769\n",
      "Epoch 4/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0919 - loss: 7.6294 - val_accuracy: 0.1140 - val_loss: 7.2250\n",
      "Epoch 5/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1037 - loss: 7.1962 - val_accuracy: 0.1498 - val_loss: 6.8651\n",
      "Epoch 6/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1675 - loss: 6.7964 - val_accuracy: 0.1824 - val_loss: 6.5663\n",
      "Epoch 7/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2071 - loss: 6.5507 - val_accuracy: 0.2313 - val_loss: 6.2998\n",
      "Epoch 8/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2685 - loss: 6.2297 - val_accuracy: 0.3062 - val_loss: 6.0554\n",
      "Epoch 9/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3298 - loss: 5.9472 - val_accuracy: 0.3453 - val_loss: 5.8459\n",
      "Epoch 10/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3479 - loss: 5.7586 - val_accuracy: 0.3909 - val_loss: 5.6391\n",
      "Epoch 11/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4314 - loss: 5.4563 - val_accuracy: 0.4137 - val_loss: 5.4504\n",
      "Epoch 12/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4601 - loss: 5.2522 - val_accuracy: 0.4593 - val_loss: 5.2673\n",
      "Epoch 13/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5125 - loss: 5.0817 - val_accuracy: 0.4658 - val_loss: 5.1028\n",
      "Epoch 14/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5442 - loss: 4.9082 - val_accuracy: 0.4788 - val_loss: 4.9378\n",
      "Epoch 15/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5788 - loss: 4.6749 - val_accuracy: 0.5179 - val_loss: 4.7856\n",
      "Epoch 16/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6215 - loss: 4.4689 - val_accuracy: 0.5407 - val_loss: 4.6407\n",
      "Epoch 17/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6681 - loss: 4.3080 - val_accuracy: 0.5537 - val_loss: 4.5127\n",
      "Epoch 18/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6644 - loss: 4.2388 - val_accuracy: 0.5733 - val_loss: 4.3810\n",
      "Epoch 19/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6865 - loss: 4.0875 - val_accuracy: 0.5961 - val_loss: 4.2550\n",
      "Epoch 20/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7260 - loss: 3.9151 - val_accuracy: 0.6091 - val_loss: 4.1326\n",
      "Epoch 21/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7309 - loss: 3.8202 - val_accuracy: 0.6124 - val_loss: 4.0382\n",
      "Epoch 22/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7591 - loss: 3.6731 - val_accuracy: 0.6059 - val_loss: 3.9308\n",
      "Epoch 23/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7823 - loss: 3.5952 - val_accuracy: 0.6254 - val_loss: 3.8340\n",
      "Epoch 24/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7850 - loss: 3.4600 - val_accuracy: 0.6287 - val_loss: 3.7431\n",
      "Epoch 25/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8171 - loss: 3.3442 - val_accuracy: 0.6352 - val_loss: 3.6569\n",
      "Epoch 26/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7954 - loss: 3.2825 - val_accuracy: 0.6384 - val_loss: 3.5873\n",
      "Epoch 27/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8305 - loss: 3.1429 - val_accuracy: 0.6384 - val_loss: 3.5203\n",
      "Epoch 28/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8364 - loss: 3.0659 - val_accuracy: 0.6352 - val_loss: 3.4511\n",
      "Epoch 29/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8356 - loss: 2.9591 - val_accuracy: 0.6417 - val_loss: 3.3894\n",
      "Epoch 30/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8377 - loss: 2.9061 - val_accuracy: 0.6482 - val_loss: 3.3167\n",
      "Epoch 31/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8560 - loss: 2.8003 - val_accuracy: 0.6515 - val_loss: 3.2444\n",
      "Epoch 32/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8561 - loss: 2.7540 - val_accuracy: 0.6547 - val_loss: 3.1970\n",
      "Epoch 33/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8675 - loss: 2.6470 - val_accuracy: 0.6580 - val_loss: 3.1341\n",
      "Epoch 34/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8783 - loss: 2.5692 - val_accuracy: 0.6547 - val_loss: 3.0899\n",
      "Epoch 35/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9043 - loss: 2.4836 - val_accuracy: 0.6547 - val_loss: 3.0374\n",
      "Epoch 36/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8726 - loss: 2.4501 - val_accuracy: 0.6547 - val_loss: 2.9925\n",
      "Epoch 37/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8926 - loss: 2.3453 - val_accuracy: 0.6580 - val_loss: 2.9466\n",
      "Epoch 38/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9107 - loss: 2.3037 - val_accuracy: 0.6515 - val_loss: 2.9050\n",
      "Epoch 39/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8974 - loss: 2.2735 - val_accuracy: 0.6678 - val_loss: 2.8483\n",
      "Epoch 40/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9296 - loss: 2.1769 - val_accuracy: 0.6645 - val_loss: 2.8046\n",
      "Epoch 41/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9113 - loss: 2.1356 - val_accuracy: 0.6775 - val_loss: 2.7577\n",
      "Epoch 42/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9268 - loss: 2.0639 - val_accuracy: 0.6775 - val_loss: 2.7256\n",
      "Epoch 43/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9040 - loss: 2.0430 - val_accuracy: 0.6678 - val_loss: 2.6865\n",
      "Epoch 44/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9363 - loss: 1.9620 - val_accuracy: 0.6743 - val_loss: 2.6380\n",
      "Epoch 45/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9255 - loss: 1.9231 - val_accuracy: 0.6612 - val_loss: 2.6088\n",
      "Epoch 46/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9212 - loss: 1.8491 - val_accuracy: 0.6710 - val_loss: 2.5819\n",
      "Epoch 47/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9337 - loss: 1.8079 - val_accuracy: 0.6775 - val_loss: 2.5343\n",
      "Epoch 48/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9395 - loss: 1.7476 - val_accuracy: 0.6873 - val_loss: 2.4939\n",
      "Epoch 49/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9476 - loss: 1.7086 - val_accuracy: 0.6906 - val_loss: 2.4714\n",
      "Epoch 50/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9374 - loss: 1.6513 - val_accuracy: 0.6743 - val_loss: 2.4559\n",
      "Epoch 51/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9443 - loss: 1.5966 - val_accuracy: 0.6840 - val_loss: 2.4371\n",
      "Epoch 52/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9607 - loss: 1.5591 - val_accuracy: 0.6906 - val_loss: 2.4133\n",
      "Epoch 53/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9563 - loss: 1.5047 - val_accuracy: 0.6906 - val_loss: 2.3613\n",
      "Epoch 54/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9523 - loss: 1.4995 - val_accuracy: 0.6906 - val_loss: 2.3349\n",
      "Epoch 55/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9551 - loss: 1.4398 - val_accuracy: 0.6971 - val_loss: 2.2963\n",
      "Epoch 56/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9419 - loss: 1.4283 - val_accuracy: 0.6906 - val_loss: 2.2826\n",
      "Epoch 57/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9577 - loss: 1.3600 - val_accuracy: 0.7003 - val_loss: 2.2424\n",
      "Epoch 58/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9670 - loss: 1.3019 - val_accuracy: 0.6971 - val_loss: 2.2333\n",
      "Epoch 59/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9534 - loss: 1.3166 - val_accuracy: 0.7003 - val_loss: 2.2208\n",
      "Epoch 60/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9571 - loss: 1.2591 - val_accuracy: 0.6971 - val_loss: 2.2191\n",
      "Epoch 61/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9726 - loss: 1.2276 - val_accuracy: 0.6938 - val_loss: 2.2097\n",
      "Epoch 62/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9617 - loss: 1.2271 - val_accuracy: 0.7003 - val_loss: 2.1807\n",
      "Epoch 63/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9660 - loss: 1.1641 - val_accuracy: 0.6938 - val_loss: 2.1537\n",
      "Epoch 64/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9719 - loss: 1.1170 - val_accuracy: 0.7036 - val_loss: 2.1269\n",
      "Epoch 65/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9678 - loss: 1.0912 - val_accuracy: 0.7068 - val_loss: 2.1112\n",
      "Epoch 66/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9713 - loss: 1.0696 - val_accuracy: 0.6971 - val_loss: 2.1171\n",
      "Epoch 67/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9664 - loss: 1.0625 - val_accuracy: 0.7003 - val_loss: 2.1045\n",
      "Epoch 68/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9730 - loss: 1.0185 - val_accuracy: 0.7036 - val_loss: 2.0873\n",
      "Epoch 69/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9681 - loss: 1.0027 - val_accuracy: 0.6971 - val_loss: 2.0813\n",
      "Epoch 70/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9726 - loss: 0.9792 - val_accuracy: 0.6938 - val_loss: 2.0894\n",
      "Epoch 71/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9693 - loss: 0.9495 - val_accuracy: 0.6938 - val_loss: 2.0479\n",
      "Epoch 72/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9802 - loss: 0.9076 - val_accuracy: 0.7003 - val_loss: 2.0092\n",
      "Epoch 73/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9781 - loss: 0.9075 - val_accuracy: 0.6971 - val_loss: 2.0145\n",
      "Epoch 74/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9698 - loss: 0.9003 - val_accuracy: 0.7003 - val_loss: 1.9784\n",
      "Epoch 75/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9666 - loss: 0.8696 - val_accuracy: 0.7003 - val_loss: 1.9769\n",
      "Epoch 76/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9690 - loss: 0.8423 - val_accuracy: 0.6906 - val_loss: 1.9719\n",
      "Epoch 77/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9764 - loss: 0.8288 - val_accuracy: 0.7003 - val_loss: 1.9559\n",
      "Epoch 78/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9784 - loss: 0.7767 - val_accuracy: 0.6938 - val_loss: 1.9129\n",
      "Epoch 79/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9682 - loss: 0.7847 - val_accuracy: 0.6938 - val_loss: 1.9066\n",
      "Epoch 80/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9811 - loss: 0.7538 - val_accuracy: 0.7036 - val_loss: 1.9020\n",
      "Epoch 81/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9784 - loss: 0.7374 - val_accuracy: 0.6938 - val_loss: 1.8925\n",
      "Epoch 82/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9774 - loss: 0.7258 - val_accuracy: 0.7068 - val_loss: 1.8642\n",
      "Epoch 83/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9784 - loss: 0.7082 - val_accuracy: 0.7036 - val_loss: 1.9194\n",
      "Epoch 84/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9781 - loss: 0.6845 - val_accuracy: 0.7003 - val_loss: 1.8693\n",
      "Epoch 85/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9727 - loss: 0.6763 - val_accuracy: 0.6971 - val_loss: 1.8492\n",
      "Epoch 86/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9723 - loss: 0.6774 - val_accuracy: 0.7166 - val_loss: 1.8379\n",
      "Epoch 87/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9810 - loss: 0.6444 - val_accuracy: 0.7036 - val_loss: 1.8058\n",
      "Epoch 88/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9802 - loss: 0.6385 - val_accuracy: 0.7134 - val_loss: 1.8138\n",
      "Epoch 89/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9830 - loss: 0.6200 - val_accuracy: 0.7101 - val_loss: 1.8032\n",
      "Epoch 90/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9795 - loss: 0.5981 - val_accuracy: 0.7068 - val_loss: 1.8099\n",
      "Epoch 91/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9828 - loss: 0.5866 - val_accuracy: 0.7068 - val_loss: 1.8022\n",
      "Epoch 92/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9760 - loss: 0.5843 - val_accuracy: 0.7134 - val_loss: 1.7935\n",
      "Epoch 93/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9827 - loss: 0.5660 - val_accuracy: 0.7101 - val_loss: 1.7818\n",
      "Epoch 94/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9900 - loss: 0.5369 - val_accuracy: 0.7166 - val_loss: 1.7990\n",
      "Epoch 95/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9893 - loss: 0.5242 - val_accuracy: 0.7101 - val_loss: 1.7801\n",
      "Epoch 96/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9829 - loss: 0.5169 - val_accuracy: 0.7068 - val_loss: 1.8163\n",
      "Epoch 97/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9739 - loss: 0.5360 - val_accuracy: 0.7166 - val_loss: 1.8229\n",
      "Epoch 98/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9765 - loss: 0.5088 - val_accuracy: 0.7166 - val_loss: 1.8015\n",
      "Epoch 99/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9829 - loss: 0.4980 - val_accuracy: 0.7166 - val_loss: 1.7906\n",
      "Epoch 100/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9816 - loss: 0.4893 - val_accuracy: 0.7199 - val_loss: 1.7441\n",
      "Fold 1 - Validation Accuracy: 0.7199\n",
      "\n",
      "=== Training Fold 2/5 ===\n",
      "Epoch 1/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8703 - loss: 0.8635 - val_accuracy: 0.9837 - val_loss: 0.4081\n",
      "Epoch 2/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8941 - loss: 0.7672 - val_accuracy: 0.9805 - val_loss: 0.4182\n",
      "Epoch 3/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9263 - loss: 0.6386 - val_accuracy: 0.9707 - val_loss: 0.4311\n",
      "Epoch 4/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9210 - loss: 0.6271 - val_accuracy: 0.9609 - val_loss: 0.4407\n",
      "Epoch 5/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9469 - loss: 0.5672 - val_accuracy: 0.9674 - val_loss: 0.4454\n",
      "Epoch 6/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9389 - loss: 0.5646 - val_accuracy: 0.9544 - val_loss: 0.4656\n",
      "Epoch 7/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9405 - loss: 0.5393 - val_accuracy: 0.9544 - val_loss: 0.4672\n",
      "Epoch 8/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9642 - loss: 0.4939 - val_accuracy: 0.9577 - val_loss: 0.4836\n",
      "Epoch 9/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9613 - loss: 0.4964 - val_accuracy: 0.9544 - val_loss: 0.4827\n",
      "Epoch 10/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9598 - loss: 0.4660 - val_accuracy: 0.9609 - val_loss: 0.4877\n",
      "Epoch 11/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9609 - loss: 0.4702 - val_accuracy: 0.9511 - val_loss: 0.5073\n",
      "Fold 2 - Validation Accuracy: 0.9837\n",
      "\n",
      "=== Training Fold 3/5 ===\n",
      "Epoch 1/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8891 - loss: 0.7836 - val_accuracy: 0.9739 - val_loss: 0.4247\n",
      "Epoch 2/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8941 - loss: 0.7051 - val_accuracy: 0.9577 - val_loss: 0.4489\n",
      "Epoch 3/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9281 - loss: 0.6006 - val_accuracy: 0.9674 - val_loss: 0.4537\n",
      "Epoch 4/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9292 - loss: 0.6089 - val_accuracy: 0.9642 - val_loss: 0.4604\n",
      "Epoch 5/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9322 - loss: 0.5516 - val_accuracy: 0.9544 - val_loss: 0.4765\n",
      "Epoch 6/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9474 - loss: 0.5283 - val_accuracy: 0.9511 - val_loss: 0.4844\n",
      "Epoch 7/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9383 - loss: 0.5224 - val_accuracy: 0.9479 - val_loss: 0.4969\n",
      "Epoch 8/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9548 - loss: 0.5175 - val_accuracy: 0.9414 - val_loss: 0.4989\n",
      "Epoch 9/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9623 - loss: 0.4503 - val_accuracy: 0.9381 - val_loss: 0.5170\n",
      "Epoch 10/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9483 - loss: 0.5061 - val_accuracy: 0.9414 - val_loss: 0.5350\n",
      "Epoch 11/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9569 - loss: 0.4543 - val_accuracy: 0.9251 - val_loss: 0.5410\n",
      "Fold 3 - Validation Accuracy: 0.9739\n",
      "\n",
      "=== Training Fold 4/5 ===\n",
      "Epoch 1/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8791 - loss: 0.7481 - val_accuracy: 0.9609 - val_loss: 0.4253\n",
      "Epoch 2/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8941 - loss: 0.7201 - val_accuracy: 0.9544 - val_loss: 0.4526\n",
      "Epoch 3/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9120 - loss: 0.6334 - val_accuracy: 0.9414 - val_loss: 0.4750\n",
      "Epoch 4/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9131 - loss: 0.6304 - val_accuracy: 0.9349 - val_loss: 0.4881\n",
      "Epoch 5/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9129 - loss: 0.5694 - val_accuracy: 0.9414 - val_loss: 0.5172\n",
      "Epoch 6/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9322 - loss: 0.5514 - val_accuracy: 0.9349 - val_loss: 0.5228\n",
      "Epoch 7/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9579 - loss: 0.4798 - val_accuracy: 0.9349 - val_loss: 0.5227\n",
      "Epoch 8/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9488 - loss: 0.4884 - val_accuracy: 0.9316 - val_loss: 0.5329\n",
      "Epoch 9/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9534 - loss: 0.4548 - val_accuracy: 0.9153 - val_loss: 0.5598\n",
      "Epoch 10/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9563 - loss: 0.4581 - val_accuracy: 0.9055 - val_loss: 0.5848\n",
      "Epoch 11/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9624 - loss: 0.4591 - val_accuracy: 0.9023 - val_loss: 0.5796\n",
      "Fold 4 - Validation Accuracy: 0.9609\n",
      "\n",
      "=== Training Fold 5/5 ===\n",
      "Epoch 1/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8745 - loss: 0.7626 - val_accuracy: 0.9577 - val_loss: 0.4230\n",
      "Epoch 2/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8928 - loss: 0.6978 - val_accuracy: 0.9479 - val_loss: 0.4305\n",
      "Epoch 3/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9092 - loss: 0.6027 - val_accuracy: 0.9316 - val_loss: 0.4706\n",
      "Epoch 4/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9088 - loss: 0.6005 - val_accuracy: 0.9316 - val_loss: 0.4746\n",
      "Epoch 5/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9401 - loss: 0.5319 - val_accuracy: 0.9218 - val_loss: 0.5105\n",
      "Epoch 6/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9471 - loss: 0.4989 - val_accuracy: 0.9251 - val_loss: 0.5129\n",
      "Epoch 7/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9292 - loss: 0.5400 - val_accuracy: 0.9055 - val_loss: 0.5635\n",
      "Epoch 8/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9421 - loss: 0.4949 - val_accuracy: 0.9055 - val_loss: 0.5556\n",
      "Epoch 9/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9579 - loss: 0.4799 - val_accuracy: 0.8893 - val_loss: 0.5695\n",
      "Epoch 10/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9586 - loss: 0.4567 - val_accuracy: 0.8893 - val_loss: 0.5648\n",
      "Epoch 11/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9610 - loss: 0.4459 - val_accuracy: 0.8762 - val_loss: 0.6117\n",
      "Fold 5 - Validation Accuracy: 0.9577\n",
      "\n",
      "=== Average Validation Accuracy: 0.9192 ===\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "# Hyperparameters\n",
    "num_folds = 5\n",
    "batch_size = 8\n",
    "learning_rate = 1e-4\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "fold_accuracies = []\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(train_x)):\n",
    "    print(f\"\\n=== Training Fold {fold + 1}/{num_folds} ===\")\n",
    "    \n",
    "    X_train, X_val = train_x[train_index], train_x[val_index]\n",
    "    y_train, y_val = train_y[train_index], train_y[val_index]\n",
    "\n",
    "    tensorboard_callback = callbacks.TensorBoard(log_dir=f'./logs/fold_{fold+1}')\n",
    "    early_stopping_callback = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    \n",
    "    optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[tensorboard_callback, early_stopping_callback],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "    print(f\"Fold {fold + 1} - Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    fold_accuracies.append(val_accuracy)\n",
    "    \n",
    "avg_accuracy = np.mean(fold_accuracies)\n",
    "print(f\"\\n=== Average Validation Accuracy: {avg_accuracy:.4f} ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = callbacks.EarlyStopping(monitor='accuracy', patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training tanpa split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8728 - loss: 0.7374\n",
      "Epoch 2/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8580 - loss: 0.7293\n",
      "Epoch 3/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8966 - loss: 0.6350\n",
      "Epoch 4/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9230 - loss: 0.5432\n",
      "Epoch 5/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9278 - loss: 0.5508\n",
      "Epoch 6/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9173 - loss: 0.5456\n",
      "Epoch 7/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9545 - loss: 0.4656\n",
      "Epoch 8/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9533 - loss: 0.4770\n",
      "Epoch 9/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9563 - loss: 0.4392\n",
      "Epoch 10/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9615 - loss: 0.4422\n",
      "Epoch 11/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9409 - loss: 0.4629\n",
      "Epoch 12/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9595 - loss: 0.4128\n",
      "Epoch 13/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9598 - loss: 0.4120\n",
      "Epoch 14/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9676 - loss: 0.4087\n",
      "Epoch 15/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9623 - loss: 0.4140\n",
      "Epoch 16/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9692 - loss: 0.3881\n",
      "Epoch 17/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9754 - loss: 0.3688\n",
      "Epoch 18/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9695 - loss: 0.3790\n",
      "Epoch 19/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9825 - loss: 0.3694\n",
      "Epoch 20/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9746 - loss: 0.3680\n",
      "Epoch 21/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9692 - loss: 0.3743\n",
      "Epoch 22/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9719 - loss: 0.3592\n",
      "Epoch 23/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9691 - loss: 0.3502\n",
      "Epoch 24/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9746 - loss: 0.3442\n",
      "Epoch 25/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9792 - loss: 0.3335\n",
      "Epoch 26/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9677 - loss: 0.3630\n",
      "Epoch 27/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9810 - loss: 0.3081\n",
      "Epoch 28/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9711 - loss: 0.3326\n",
      "Epoch 29/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9820 - loss: 0.3242\n",
      "Epoch 30/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9709 - loss: 0.3332\n",
      "Epoch 31/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9711 - loss: 0.3285\n",
      "Epoch 32/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9863 - loss: 0.2979\n",
      "Epoch 33/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9773 - loss: 0.3089\n",
      "Epoch 34/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9799 - loss: 0.2968\n",
      "Epoch 35/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9715 - loss: 0.3208\n",
      "Epoch 36/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9855 - loss: 0.2772\n",
      "Epoch 37/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9789 - loss: 0.2888\n",
      "Epoch 38/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9694 - loss: 0.3067\n",
      "Epoch 39/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9784 - loss: 0.2831\n",
      "Epoch 40/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9843 - loss: 0.2674\n",
      "Epoch 41/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9749 - loss: 0.3023\n",
      "Epoch 42/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9775 - loss: 0.2728\n",
      "Epoch 43/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9837 - loss: 0.2633\n",
      "Epoch 44/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9810 - loss: 0.2638\n",
      "Epoch 45/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9817 - loss: 0.2631\n",
      "Epoch 46/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9847 - loss: 0.2513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train and save the final model\n",
    "model.fit(train_x, train_y, epochs=100, batch_size=8, callbacks=[tensorboard_callback, early_stopping_callback], verbose=1)\n",
    "model.save('final_model_trained_on_full_data.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save\n",
    "try:\n",
    "    with open(\"training_data.json\", \"w\") as file:\n",
    "        # Convert non-serializable data like NumPy arrays or other objects to lists\n",
    "        data = {'words': words, 'classes': classes, 'train_x': train_x.tolist(), 'train_y': train_y.tolist()}\n",
    "        json.dump(data, file)\n",
    "except IOError as e:\n",
    "    print(f\"Error saving training data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "try:\n",
    "    with open(\"training_data\", \"wb\") as file:\n",
    "        pickle.dump({'words': words, 'classes': classes, 'train_x': train_x, 'train_y': train_y}, file)\n",
    "except IOError as e:\n",
    "    print(f\"Error saving training data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DrOW8S1Y0un5",
    "outputId": "eae11a39-7021-45a3-d529-8717486e4090"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Load\n",
    "try:\n",
    "    with open(\"training_data\", \"rb\") as file:\n",
    "        data = pickle.load(file)\n",
    "\n",
    "    words = data['words']\n",
    "    classes = data['classes']\n",
    "    train_x = np.array(data['train_x'])\n",
    "    train_y = np.array(data['train_y'])\n",
    "except IOError as e:\n",
    "    print(f\"Error loading training data: {e}\")\n",
    "\n",
    "# Load model\n",
    "try:\n",
    "    model = keras.models.load_model('final_model_trained_on_full_data.h5')\n",
    "except IOError as e:\n",
    "    print(f\"Error loading model: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "XVD-P16Q19Ar"
   },
   "outputs": [],
   "source": [
    "def clean_up_sentence(sentence):\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    sentence_words = [stemmer.stem(word.lower()) for word in sentence_words]\n",
    "    return sentence_words\n",
    "\n",
    "def bow(sentence, words, show_details=False):\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    bag = np.zeros(len(words), dtype=np.float32)\n",
    "    for idx, w in enumerate(words):\n",
    "        if w in sentence_words:\n",
    "            bag[idx] = 1\n",
    "            if show_details:\n",
    "                print(f\"Found in bag: {w}\")\n",
    "    return bag\n",
    "\n",
    "ERROR_THRESHOLD = 0.40\n",
    "\n",
    "\n",
    "\n",
    "def classify(sentence):\n",
    "    input_data = bow(sentence, words)\n",
    "    results = model.predict(np.array([input_data]))[0]\n",
    "    results = [[i, r] for i, r in enumerate(results) if r >= ERROR_THRESHOLD]\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return [(classes[r[0]], r[1]) for r in results]\n",
    "\n",
    "def response(sentence, userID='123', show_details=False):\n",
    "    results = classify(sentence)\n",
    "    if results:\n",
    "        for intent in intents:\n",
    "            if intent['tag'] == results[0][0]:\n",
    "                return random.choice(intent['responses'])\n",
    "    return \"Maaf, saya belum mengerti apa yang Anda bicarakan, perlu bantuan?.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FO4ujct85h_h",
    "outputId": "a2cddf3f-f8f6-46fa-f780-79074e416a53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 to close\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " cara mengatasi rasa cemas\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Kadang-kadang kecemasan bisa sangat mengganggu. Jangan ragu untuk mencari cara untuk menenangkan diri atau berbicara dengan seorang profesional.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " bagaimana cara mengatasi kesedihan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Luangkan waktu untuk diri sendiri dan lakukan hal-hal yang kamu nikmati.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " bagaimana cara mengatasi kesedihan?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Luangkan waktu untuk diri sendiri dan lakukan hal-hal yang kamu nikmati.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " bagaimana cara mengatasi kesedihan?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Luangkan waktu untuk menangis jika perlu, itu adalah cara yang sehat untuk melepaskan emosi.\n"
     ]
    }
   ],
   "source": [
    "print(\"0 to close\")\n",
    "while True:\n",
    "    message = input(\"\")\n",
    "    if message == \"0\":\n",
    "        break\n",
    "    result = response(message)\n",
    "\n",
    "    if result is not None and \"~\" in result:\n",
    "        order = (result[1:])\n",
    "        action(order)\n",
    "    else:\n",
    "        print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xRRvDLhl0kI_",
    "outputId": "180f72b1-0bec-45f4-eb82-9b704c1713d2"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('final_model_trained_on_full_data.h5')\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "\n",
    "with open('model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
