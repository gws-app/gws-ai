{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OFDSdvxj6ApJ",
    "outputId": "8d7e03b8-3c29-4e9e-f4a0-dd1b619499a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PySastrawi in c:\\users\\dzikr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install PySastrawi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sgol4Y_Y6ApP",
    "outputId": "bd880933-4700-4196-d8e7-bf0eeea86d4f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dzikr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "nMmyJPc5v2s8"
   },
   "outputs": [],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import pickle\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import nltk\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras import layers, models, callbacks, optimizers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "AyCMTd3BxH5v"
   },
   "outputs": [],
   "source": [
    "# Load the intents file\n",
    "with open('nlp_dataset_faq.json') as data_file:\n",
    "    intents = json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apa', 'kabar', '?']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dzikr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "pattern = \"Apa kabar?\"\n",
    "w = nltk.word_tokenize(pattern.lower())\n",
    "print(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LzYlZchPxkrj",
    "outputId": "a02e3f10-25e2-49bd-99e0-2e6b517310d9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\dzikr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download the 'punkt_tab' data package\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Pre-processing\n",
    "words = []\n",
    "classes = []\n",
    "documents = []\n",
    "ignore = ['','!', '\"', \"'\", '(', ')', ',', '-', '.', ':', ';','[', ']', '_','?','.'\n",
    "          'adalah', 'akan', 'aku', 'anda', 'atau', 'dalam', 'dan',\n",
    "          'dari', 'dengan', 'di', 'dia', 'harus', 'ini', 'itu', 'jika', 'kami', 'kamu', 'ke',\n",
    "          'kita', 'mereka', 'oleh', 'pada', 'saya', 'sebuah', 'sedang', 'sementara', 'tanpa',\n",
    "          'tapi', 'telah', 'untuk', 'yang', '{', '}', 'merasa']\n",
    "\n",
    "\n",
    "\n",
    "#tokenize\n",
    "for intent in intents:\n",
    "    for pattern in intent['patterns']:\n",
    "        w = nltk.word_tokenize(pattern.lower())  # Tokenizing\n",
    "        words.extend([word for word in w if word not in ignore])  #Ignore\n",
    "        documents.append((w, intent['tag']))\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3OjNRWsryAlH",
    "outputId": "ad6913c3-fa46-4cf9-c12c-29f3ab63c088"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1634 documents\n",
      "81 classes ['apa_itu_gangguan_mental', 'badmood_dampak', 'badmood_efek_jangka_panjang', 'badmood_gejala', 'badmood_pengobatan', 'badmood_penyebab', 'badmood_preventif', 'badmood_solusi_pribadi', 'badmood_terhadap_kesehatan_fisik', 'badmood_terhadap_pekerjaan', 'bunuh_diri', 'cara_mengatasi_benci', 'cara_mengatasi_bingung', 'cara_mengatasi_cemas', 'cara_mengatasi_cemburu', 'cara_mengatasi_dendam', 'cara_mengatasi_diremehkan', 'cara_mengatasi_frustasi', 'cara_mengatasi_gangguan_mental', 'cara_mengatasi_hampa', 'cara_mengatasi_iri', 'cara_mengatasi_kecewa', 'cara_mengatasi_kesal', 'cara_mengatasi_malu', 'cara_mengatasi_marah', 'cara_mengatasi_merasa_sendiri', 'cara_mengatasi_overthinking', 'cara_mengatasi_rasa_bersalah', 'cara_mengatasi_sedih', 'cara_mengatasi_takut', 'cara_mengatasi_takut_gagal', 'cara_mengatasi_tidak_dihargai', 'cara_positive_thinking', 'diagnosis_gangguan_mental', 'dukungan_mental_terapi', 'efek_gangguan_mental', 'emosi_bingung', 'emosi_frustrasi', 'emosi_hampa', 'emosi_kecewa', 'emosi_lelah', 'emosi_marah', 'emosi_sedih', 'emosi_senang', 'emosi_takut', 'emosi_takut_gagal', 'emosi_terbebani', 'emosi_tertekan', 'emosi_tidak_dihargai', 'gangguan_mental_dan_bipolar', 'gangguan_mental_dan_depresi', 'gangguan_mental_dan_kecemasan', 'gangguan_mental_dan_psikoedukasi', 'gangguan_mental_dan_psikoterapi', 'gangguan_mental_dan_stigma', 'gangguan_mental_untuk_anak', 'gejala_gangguan_mental', 'kabar_baik', 'kabar_buruk', 'kabar_netral', 'mood_bahagia', 'mood_cemas', 'mood_marahan', 'mood_membaik', 'mood_motivation', 'mood_sedih', 'mood_stress_relief', 'penanganan_gangguan_mental', 'pencegahan_gangguan_mental', 'pengobatan_gangguan_mental', 'penyebab_gangguan_mental', 'perbedaan_gangguan_mental_dan_stres', 'perkenalan_diri', 'perpisahan', 'salam_halo', 'salam_hi_tes', 'salam_terima_kasih', 'sapaan_pagi', 'sapaan_tanya_kabar', 'tanya_bantuan_terdekat', 'ucapan_terima_kasih']\n",
      "541 unique stemmed words ['abai', 'ada', 'adalah', 'adil', 'agar', 'ahli', 'ajar', 'akhir', 'akibat', 'aktif', 'aktivitas', 'aku', 'alami', 'alas', 'alih', 'alkohol', 'aman', 'amarah', 'amarahku', 'ambil', 'anak', 'anggap', 'antara', 'antidepresan', 'apa', 'apakah', 'arah', 'arti', 'asa', 'asal', 'asmara', 'atas', 'atur', 'awal', 'awat', 'bad', 'badan', 'bagai', 'bagaimana', 'bagi', 'bahagia', 'bahaya', 'bahwa', 'baik', 'balas', 'balik', 'banget', 'bangkit', 'bangun', 'bantu', 'banyak', 'baru', 'beban', 'beda', 'begitu', 'belum', 'benar', 'benci', 'berani', 'berapa', 'berat', 'beri', 'besar', 'biar', 'biasa', 'bicara', 'bingung', 'bipolar', 'bisa', 'boleh', 'buat', 'bugar', 'bukan', 'bukti', 'buruk', 'butuh', 'capai', 'capek', 'cara', 'cari', 'cegah', 'cemas', 'cemburu', 'cepat', 'cerah', 'cerita', 'cerna', 'chat', 'chatbot', 'cinta', 'ciri', 'coba', 'cuaca', 'cukup', 'dadah', 'damai', 'dampak', 'dapat', 'darah', 'datang', 'daya', 'definisi', 'dekat', 'dendam', 'dengan', 'dengar', 'depan', 'depresi', 'derita', 'deteksi', 'dewasa', 'diagnosis', 'diet', 'diri', 'dokter', 'dong', 'down', 'dukung', 'dunia', 'edukasi', 'efek', 'efektif', 'ekonomi', 'ekspektasi', 'elektrokonvulsif', 'emosi', 'emosional', 'enak', 'energi', 'energik', 'episode', 'erti', 'faktor', 'fisik', 'fokus', 'frustrasi', 'fungsi', 'gagal', 'ganggu', 'gaya', 'gejala', 'gelap', 'gelisah', 'gembira', 'genetik', 'genetika', 'guna', 'habis', 'hadap', 'hai', 'hal', 'halang', 'hallo', 'halo', 'hambat', 'hampa', 'hantu', 'hanya', 'harap', 'harga', 'hari', 'hasil', 'hati', 'hebat', 'henti', 'hi', 'hidup', 'hilang', 'hindar', 'hormat', 'hormon', 'hubung', 'identifikasi', 'ikut', 'implementasi', 'imun', 'indikator', 'individu', 'ingin', 'insomnia', 'inspirasi', 'intens', 'intervensi', 'iri', 'isi', 'isolasi', 'istimewa', 'istirahat', 'jadi', 'jaga', 'jalan', 'jangka', 'jawab', 'jebak', 'jelas', 'jenak', 'jengkel', 'jenis', 'jepit', 'jernih', 'juga', 'jumpa', 'jurnal', 'kabar', 'kait', 'kalau', 'kantor', 'karena', 'kasih', 'kata', 'kategori', 'kebal', 'kecewa', 'kecil', 'keliling', 'kelola', 'kelompok', 'keluar', 'keluarga', 'kemarin', 'kembali', 'kembang', 'kena', 'kenal', 'kenapa', 'kendali', 'kepada', 'kepala', 'keras', 'kerja', 'kerjasamanya', 'kesal', 'ketika', 'kewalahan', 'khawatir', 'khianat', 'khusus', 'kognitif', 'komentar', 'komunikasi', 'kondisi', 'konflik', 'konselor', 'kontrol', 'kosong', 'kronis', 'kualitas', 'kuasa', 'kuat', 'kunjung', 'kurang', 'lagi', 'lain', 'laku', 'lalu', 'lama', 'lancar', 'lang', 'langkah', 'langsung', 'lanjut', 'lari', 'lawan', 'layan', 'layar', 'lebih', 'ledak', 'lelah', 'lemah', 'lengkap', 'lepas', 'lesu', 'lewat', 'libat', 'lihat', 'lingkung', 'luap', 'luar', 'luka', 'lumpuh', 'lupa', 'maaf', 'maju', 'makan', 'makasih', 'makin', 'makna', 'maksud', 'malam', 'malas', 'malu', 'mampu', 'mana', 'mandiri', 'manfaat', 'mania', 'marah', 'masa', 'masalah', 'masuk', 'masyarakat', 'mati', 'medis', 'meditasi', 'menang', 'mengapa', 'menghadang', 'mental', 'meski', 'metabolisme', 'metode', 'mikrofon', 'milik', 'minta', 'moga', 'mood', 'moodku', 'moral', 'motivasi', 'mudah', 'mula', 'mulai', 'muncul', 'murung', 'musik', 'nali', 'nama', 'nan', 'napas', 'negatif', 'netral', 'nggak', 'nih', 'nomor', 'normal', 'nyaman', 'nyata', 'obat', 'olah', 'olahraga', 'optimis', 'orang', 'overthinking', 'pagi', 'paham', 'paling', 'pandang', 'panggil', 'panjang', 'parah', 'pasti', 'peduli', 'pengaruh', 'penting', 'penuh', 'peran', 'perangkap', 'percaya', 'pergi', 'perhati', 'periksa', 'perilaku', 'peristiwa', 'perlu', 'pernah', 'pertama', 'pesimis', 'picu', 'pikir', 'pikul', 'pilih', 'pola', 'positif', 'preventif', 'pribadi', 'produktif', 'produktivitas', 'profesional', 'proses', 'psikoedukasi', 'psikologi', 'psikologis', 'psikoterapi', 'psikoterapis', 'puas', 'pulih', 'pun', 'pundak', 'punya', 'puruk', 'putus', 'ragu', 'rasa', 'reda', 'rekan', 'rekomendasi', 'relaksasi', 'remaja', 'remeh', 'rencana', 'rendah', 'rentan', 'rileks', 'risiko', 'rumah', 'rusak', 'saat', 'sabar', 'sadar', 'saja', 'sakit', 'salah', 'sama', 'sampai', 'sana', 'sangat', 'santai', 'saran', 'sebab', 'sebut', 'sedia', 'sedih', 'sedikit', 'segala', 'segar', 'segera', 'sehat', 'sekali', 'sekaligus', 'sekarang', 'sekitar', 'selalu', 'selamat', 'selesai', 'semangat', 'sembuh', 'sempurna', 'semua', 'senang', 'sendiri', 'seperti', 'sepi', 'serah', 'sering', 'serta', 'sesal', 'sesat', 'sesi', 'sesuai', 'sesuatu', 'sia', 'siap', 'siapa', 'sibuk', 'sih', 'sikap', 'simpan', 'singgung', 'singkat', 'sini', 'sisa', 'sisi', 'sistem', 'situasi', 'solusi', 'sosial', 'spesial', 'stabil', 'stigma', 'stres', 'suara', 'suasana', 'sudah', 'suka', 'sulit', 'supaya', 'syukur', 'tahan', 'tahu', 'tak', 'takut', 'tanda', 'tangan', 'tanggung', 'tanya', 'target', 'tarik', 'tegang', 'tekan', 'teknik', 'telah', 'telepon', 'teman', 'tempat', 'temu', 'tenang', 'tengah', 'tenggelam', 'tentang', 'tentu', 'tepat', 'terap', 'terapi', 'terima', 'terlalu', 'terus', 'tes', 'tetap', 'tetapi', 'tiap', 'tiba', 'tidak', 'tidur', 'tinggal', 'tinggi', 'tingkat', 'tips', 'tolong', 'tonjol', 'trauma', 'tua', 'tubuh', 'tuju', 'tunjuk', 'tuntut', 'turun', 'uang', 'ubah', 'ujung', 'umum', 'untung', 'usaha', 'utama', 'waktu', 'waris', 'warna', 'was-was', 'waspada', 'ya', 'yakin', 'yoga']\n"
     ]
    }
   ],
   "source": [
    "# Melakukan stemming dan normalisasi data\n",
    "words = [stemmer.stem(w.lower()) for w in words if w not in ignore]\n",
    "words = sorted(list(set(words)))\n",
    "\n",
    "# Menghapus class duplikat dengan 'set'\n",
    "classes = sorted(list(set(classes)))\n",
    "\n",
    "print(len(documents), \"documents\")\n",
    "print(len(classes), \"classes\", classes)\n",
    "print(len(words), \"unique stemmed words\", words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "o3bG67i3yL2q"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "training = []\n",
    "output_empty = [0] * len(classes)\n",
    "\n",
    "for doc in documents:\n",
    "    pattern_words = [stemmer.stem(word.lower()) for word in doc[0]]\n",
    "    bag = [1 if w in pattern_words else 0 for w in words]\n",
    "\n",
    "    output_row = output_empty[:]\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "\n",
    "    training.append([bag, output_row])\n",
    "\n",
    "random.shuffle(training)\n",
    "training = np.array(training, dtype=object)\n",
    "\n",
    "train_x = np.array([item[0] for item in training])\n",
    "train_y = np.array([item[1] for item in training])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "        layers.Input(shape=(len(train_x[0]),), name='input_layer'),\n",
    "        layers.Dense(256, activation='relu', kernel_regularizer='l2', name='hidden_layer1'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3, name='dropout1'),\n",
    "        layers.Dense(128, activation='relu', kernel_regularizer='l2', name='hidden_layer2'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3, name='dropout2'),\n",
    "        layers.Dense(len(train_y[0]), activation='softmax', name='output_layer')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ hidden_layer1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">138,752</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ hidden_layer2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,449</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ hidden_layer1 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m138,752\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout1 (\u001b[38;5;33mDropout\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ hidden_layer2 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout2 (\u001b[38;5;33mDropout\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m)                  │          \u001b[38;5;34m10,449\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">183,633</span> (717.32 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m183,633\u001b[0m (717.32 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">182,865</span> (714.32 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m182,865\u001b[0m (714.32 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K_FOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2j75XSbGyalB",
    "outputId": "bbad24ff-51fd-4440-d144-bfe4011cf099"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dzikr\\AppData\\Local\\Temp\\ipykernel_20684\\3785205646.py:1: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "\n",
      "=== Training Fold 1/5 ===\n",
      "Epoch 1/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0066 - loss: 10.1489 - val_accuracy: 0.0153 - val_loss: 8.7074\n",
      "Epoch 2/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0122 - loss: 8.9984 - val_accuracy: 0.0275 - val_loss: 8.2094\n",
      "Epoch 3/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0364 - loss: 8.3259 - val_accuracy: 0.1101 - val_loss: 7.6646\n",
      "Epoch 4/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0655 - loss: 7.7250 - val_accuracy: 0.1560 - val_loss: 7.1797\n",
      "Epoch 5/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1068 - loss: 7.4008 - val_accuracy: 0.2141 - val_loss: 6.7905\n",
      "Epoch 6/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1591 - loss: 6.9389 - val_accuracy: 0.2569 - val_loss: 6.4760\n",
      "Epoch 7/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2093 - loss: 6.5206 - val_accuracy: 0.3028 - val_loss: 6.1926\n",
      "Epoch 8/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2617 - loss: 6.2870 - val_accuracy: 0.3486 - val_loss: 5.9359\n",
      "Epoch 9/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3154 - loss: 6.0287 - val_accuracy: 0.4006 - val_loss: 5.6985\n",
      "Epoch 10/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3985 - loss: 5.6867 - val_accuracy: 0.4587 - val_loss: 5.4874\n",
      "Epoch 11/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4314 - loss: 5.5186 - val_accuracy: 0.5260 - val_loss: 5.2831\n",
      "Epoch 12/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4733 - loss: 5.2610 - val_accuracy: 0.5505 - val_loss: 5.1008\n",
      "Epoch 13/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5075 - loss: 5.1036 - val_accuracy: 0.5657 - val_loss: 4.9240\n",
      "Epoch 14/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5384 - loss: 4.8596 - val_accuracy: 0.5810 - val_loss: 4.7535\n",
      "Epoch 15/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5626 - loss: 4.7987 - val_accuracy: 0.5902 - val_loss: 4.5947\n",
      "Epoch 16/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6186 - loss: 4.5428 - val_accuracy: 0.6086 - val_loss: 4.4385\n",
      "Epoch 17/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6142 - loss: 4.4112 - val_accuracy: 0.6116 - val_loss: 4.2964\n",
      "Epoch 18/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6237 - loss: 4.2872 - val_accuracy: 0.6300 - val_loss: 4.1595\n",
      "Epoch 19/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7050 - loss: 4.0417 - val_accuracy: 0.6422 - val_loss: 4.0392\n",
      "Epoch 20/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7163 - loss: 3.9219 - val_accuracy: 0.6544 - val_loss: 3.9125\n",
      "Epoch 21/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7044 - loss: 3.8386 - val_accuracy: 0.6636 - val_loss: 3.8098\n",
      "Epoch 22/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7631 - loss: 3.6112 - val_accuracy: 0.6667 - val_loss: 3.6989\n",
      "Epoch 23/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7413 - loss: 3.6050 - val_accuracy: 0.6667 - val_loss: 3.6177\n",
      "Epoch 24/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7850 - loss: 3.4734 - val_accuracy: 0.6911 - val_loss: 3.5320\n",
      "Epoch 25/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8189 - loss: 3.2707 - val_accuracy: 0.6972 - val_loss: 3.4519\n",
      "Epoch 26/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8049 - loss: 3.2262 - val_accuracy: 0.7095 - val_loss: 3.3606\n",
      "Epoch 27/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8242 - loss: 3.0996 - val_accuracy: 0.6972 - val_loss: 3.2856\n",
      "Epoch 28/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8342 - loss: 3.0115 - val_accuracy: 0.7095 - val_loss: 3.2065\n",
      "Epoch 29/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8475 - loss: 2.9424 - val_accuracy: 0.7187 - val_loss: 3.1314\n",
      "Epoch 30/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8537 - loss: 2.8127 - val_accuracy: 0.7156 - val_loss: 3.0679\n",
      "Epoch 31/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8640 - loss: 2.7648 - val_accuracy: 0.7125 - val_loss: 3.0106\n",
      "Epoch 32/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8650 - loss: 2.7084 - val_accuracy: 0.7034 - val_loss: 2.9505\n",
      "Epoch 33/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8778 - loss: 2.5843 - val_accuracy: 0.7278 - val_loss: 2.8915\n",
      "Epoch 34/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8632 - loss: 2.5539 - val_accuracy: 0.7248 - val_loss: 2.8425\n",
      "Epoch 35/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9031 - loss: 2.4588 - val_accuracy: 0.7217 - val_loss: 2.7931\n",
      "Epoch 36/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8719 - loss: 2.3976 - val_accuracy: 0.7248 - val_loss: 2.7358\n",
      "Epoch 37/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9018 - loss: 2.2991 - val_accuracy: 0.7248 - val_loss: 2.6906\n",
      "Epoch 38/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 2.2263 - val_accuracy: 0.7278 - val_loss: 2.6408\n",
      "Epoch 39/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9056 - loss: 2.1803 - val_accuracy: 0.7248 - val_loss: 2.6033\n",
      "Epoch 40/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9026 - loss: 2.1238 - val_accuracy: 0.7309 - val_loss: 2.5590\n",
      "Epoch 41/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9071 - loss: 2.0506 - val_accuracy: 0.7462 - val_loss: 2.5116\n",
      "Epoch 42/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9292 - loss: 2.0012 - val_accuracy: 0.7492 - val_loss: 2.4725\n",
      "Epoch 43/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9440 - loss: 1.9301 - val_accuracy: 0.7523 - val_loss: 2.4312\n",
      "Epoch 44/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9076 - loss: 1.9191 - val_accuracy: 0.7615 - val_loss: 2.3902\n",
      "Epoch 45/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9371 - loss: 1.8027 - val_accuracy: 0.7554 - val_loss: 2.3628\n",
      "Epoch 46/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9313 - loss: 1.7921 - val_accuracy: 0.7584 - val_loss: 2.3268\n",
      "Epoch 47/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9417 - loss: 1.7295 - val_accuracy: 0.7523 - val_loss: 2.2904\n",
      "Epoch 48/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9549 - loss: 1.6617 - val_accuracy: 0.7554 - val_loss: 2.2524\n",
      "Epoch 49/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9380 - loss: 1.6682 - val_accuracy: 0.7523 - val_loss: 2.2287\n",
      "Epoch 50/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9566 - loss: 1.5871 - val_accuracy: 0.7554 - val_loss: 2.1904\n",
      "Epoch 51/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9389 - loss: 1.5552 - val_accuracy: 0.7523 - val_loss: 2.1787\n",
      "Epoch 52/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9523 - loss: 1.5063 - val_accuracy: 0.7492 - val_loss: 2.1598\n",
      "Epoch 53/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9467 - loss: 1.4920 - val_accuracy: 0.7462 - val_loss: 2.1346\n",
      "Epoch 54/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9429 - loss: 1.4402 - val_accuracy: 0.7554 - val_loss: 2.0990\n",
      "Epoch 55/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9671 - loss: 1.3767 - val_accuracy: 0.7584 - val_loss: 2.0726\n",
      "Epoch 56/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9577 - loss: 1.3561 - val_accuracy: 0.7523 - val_loss: 2.0590\n",
      "Epoch 57/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9505 - loss: 1.3273 - val_accuracy: 0.7523 - val_loss: 2.0230\n",
      "Epoch 58/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9689 - loss: 1.2552 - val_accuracy: 0.7492 - val_loss: 1.9997\n",
      "Epoch 59/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9559 - loss: 1.2517 - val_accuracy: 0.7615 - val_loss: 1.9844\n",
      "Epoch 60/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9577 - loss: 1.2050 - val_accuracy: 0.7645 - val_loss: 1.9521\n",
      "Epoch 61/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9563 - loss: 1.1985 - val_accuracy: 0.7492 - val_loss: 1.9567\n",
      "Epoch 62/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9771 - loss: 1.1128 - val_accuracy: 0.7554 - val_loss: 1.9308\n",
      "Epoch 63/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9687 - loss: 1.1213 - val_accuracy: 0.7615 - val_loss: 1.8982\n",
      "Epoch 64/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9721 - loss: 1.0724 - val_accuracy: 0.7676 - val_loss: 1.8845\n",
      "Epoch 65/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9630 - loss: 1.0810 - val_accuracy: 0.7676 - val_loss: 1.8658\n",
      "Epoch 66/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9610 - loss: 1.0456 - val_accuracy: 0.7676 - val_loss: 1.8476\n",
      "Epoch 67/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9539 - loss: 1.0437 - val_accuracy: 0.7645 - val_loss: 1.8451\n",
      "Epoch 68/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9630 - loss: 0.9994 - val_accuracy: 0.7615 - val_loss: 1.8294\n",
      "Epoch 69/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9752 - loss: 0.9487 - val_accuracy: 0.7584 - val_loss: 1.8416\n",
      "Epoch 70/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9671 - loss: 0.9640 - val_accuracy: 0.7584 - val_loss: 1.8146\n",
      "Epoch 71/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9685 - loss: 0.9187 - val_accuracy: 0.7554 - val_loss: 1.7899\n",
      "Epoch 72/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9630 - loss: 0.8927 - val_accuracy: 0.7523 - val_loss: 1.7953\n",
      "Epoch 73/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9876 - loss: 0.8450 - val_accuracy: 0.7554 - val_loss: 1.7740\n",
      "Epoch 74/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9750 - loss: 0.8490 - val_accuracy: 0.7554 - val_loss: 1.7735\n",
      "Epoch 75/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9743 - loss: 0.8296 - val_accuracy: 0.7584 - val_loss: 1.7505\n",
      "Epoch 76/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9761 - loss: 0.8029 - val_accuracy: 0.7645 - val_loss: 1.7359\n",
      "Epoch 77/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9671 - loss: 0.8022 - val_accuracy: 0.7584 - val_loss: 1.7370\n",
      "Epoch 78/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9727 - loss: 0.7677 - val_accuracy: 0.7615 - val_loss: 1.7154\n",
      "Epoch 79/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9742 - loss: 0.7559 - val_accuracy: 0.7554 - val_loss: 1.7211\n",
      "Epoch 80/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9776 - loss: 0.7230 - val_accuracy: 0.7523 - val_loss: 1.6873\n",
      "Epoch 81/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9819 - loss: 0.7041 - val_accuracy: 0.7645 - val_loss: 1.6928\n",
      "Epoch 82/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9737 - loss: 0.6964 - val_accuracy: 0.7615 - val_loss: 1.6832\n",
      "Epoch 83/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9798 - loss: 0.6680 - val_accuracy: 0.7615 - val_loss: 1.6920\n",
      "Epoch 84/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9673 - loss: 0.6869 - val_accuracy: 0.7615 - val_loss: 1.6789\n",
      "Epoch 85/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9775 - loss: 0.6445 - val_accuracy: 0.7584 - val_loss: 1.6784\n",
      "Epoch 86/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9818 - loss: 0.6186 - val_accuracy: 0.7554 - val_loss: 1.6699\n",
      "Epoch 87/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9808 - loss: 0.6047 - val_accuracy: 0.7584 - val_loss: 1.6642\n",
      "Epoch 88/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9805 - loss: 0.5961 - val_accuracy: 0.7584 - val_loss: 1.6689\n",
      "Epoch 89/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9837 - loss: 0.5884 - val_accuracy: 0.7584 - val_loss: 1.6390\n",
      "Epoch 90/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9888 - loss: 0.5721 - val_accuracy: 0.7615 - val_loss: 1.6502\n",
      "Epoch 91/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9778 - loss: 0.5649 - val_accuracy: 0.7554 - val_loss: 1.6408\n",
      "Epoch 92/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9850 - loss: 0.5499 - val_accuracy: 0.7462 - val_loss: 1.6459\n",
      "Epoch 93/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9839 - loss: 0.5355 - val_accuracy: 0.7492 - val_loss: 1.6278\n",
      "Epoch 94/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9779 - loss: 0.5300 - val_accuracy: 0.7462 - val_loss: 1.6227\n",
      "Epoch 95/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9804 - loss: 0.5187 - val_accuracy: 0.7584 - val_loss: 1.6269\n",
      "Epoch 96/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9783 - loss: 0.5109 - val_accuracy: 0.7706 - val_loss: 1.6002\n",
      "Epoch 97/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9800 - loss: 0.5167 - val_accuracy: 0.7615 - val_loss: 1.6224\n",
      "Epoch 98/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9871 - loss: 0.4831 - val_accuracy: 0.7584 - val_loss: 1.6162\n",
      "Epoch 99/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9797 - loss: 0.4773 - val_accuracy: 0.7615 - val_loss: 1.5791\n",
      "Epoch 100/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9867 - loss: 0.4567 - val_accuracy: 0.7492 - val_loss: 1.5895\n",
      "Fold 1 - Validation Accuracy: 0.7615\n",
      "\n",
      "=== Training Fold 2/5 ===\n",
      "Epoch 1/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9171 - loss: 0.7547 - val_accuracy: 0.9908 - val_loss: 0.3905\n",
      "Epoch 2/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9092 - loss: 0.6990 - val_accuracy: 0.9847 - val_loss: 0.4037\n",
      "Epoch 3/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9201 - loss: 0.6426 - val_accuracy: 0.9786 - val_loss: 0.4243\n",
      "Epoch 4/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9385 - loss: 0.5672 - val_accuracy: 0.9725 - val_loss: 0.4338\n",
      "Epoch 5/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9414 - loss: 0.5428 - val_accuracy: 0.9664 - val_loss: 0.4482\n",
      "Epoch 6/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.5120 - val_accuracy: 0.9664 - val_loss: 0.4498\n",
      "Epoch 7/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9476 - loss: 0.5158 - val_accuracy: 0.9572 - val_loss: 0.4597\n",
      "Epoch 8/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9636 - loss: 0.4876 - val_accuracy: 0.9633 - val_loss: 0.4498\n",
      "Epoch 9/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9623 - loss: 0.4799 - val_accuracy: 0.9511 - val_loss: 0.4672\n",
      "Epoch 10/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9615 - loss: 0.4731 - val_accuracy: 0.9358 - val_loss: 0.4740\n",
      "Epoch 11/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9657 - loss: 0.4440 - val_accuracy: 0.9419 - val_loss: 0.4767\n",
      "Fold 2 - Validation Accuracy: 0.9908\n",
      "\n",
      "=== Training Fold 3/5 ===\n",
      "Epoch 1/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8931 - loss: 0.7230 - val_accuracy: 0.9541 - val_loss: 0.4383\n",
      "Epoch 2/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8979 - loss: 0.6774 - val_accuracy: 0.9450 - val_loss: 0.4678\n",
      "Epoch 3/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9190 - loss: 0.5883 - val_accuracy: 0.9327 - val_loss: 0.5069\n",
      "Epoch 4/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9418 - loss: 0.5425 - val_accuracy: 0.9297 - val_loss: 0.5235\n",
      "Epoch 5/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9314 - loss: 0.5436 - val_accuracy: 0.9235 - val_loss: 0.5495\n",
      "Epoch 6/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9489 - loss: 0.5020 - val_accuracy: 0.9235 - val_loss: 0.5710\n",
      "Epoch 7/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9537 - loss: 0.4817 - val_accuracy: 0.9144 - val_loss: 0.5699\n",
      "Epoch 8/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.4874 - val_accuracy: 0.9205 - val_loss: 0.5945\n",
      "Epoch 9/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9733 - loss: 0.4554 - val_accuracy: 0.9174 - val_loss: 0.6084\n",
      "Epoch 10/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9671 - loss: 0.4376 - val_accuracy: 0.9113 - val_loss: 0.6322\n",
      "Epoch 11/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9760 - loss: 0.4161 - val_accuracy: 0.9205 - val_loss: 0.6181\n",
      "Fold 3 - Validation Accuracy: 0.9541\n",
      "\n",
      "=== Training Fold 4/5 ===\n",
      "Epoch 1/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8688 - loss: 0.7535 - val_accuracy: 0.9602 - val_loss: 0.4217\n",
      "Epoch 2/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8793 - loss: 0.6900 - val_accuracy: 0.9572 - val_loss: 0.4402\n",
      "Epoch 3/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9085 - loss: 0.6136 - val_accuracy: 0.9511 - val_loss: 0.4538\n",
      "Epoch 4/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9325 - loss: 0.5767 - val_accuracy: 0.9450 - val_loss: 0.4707\n",
      "Epoch 5/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9383 - loss: 0.5302 - val_accuracy: 0.9450 - val_loss: 0.4726\n",
      "Epoch 6/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9463 - loss: 0.4913 - val_accuracy: 0.9388 - val_loss: 0.4969\n",
      "Epoch 7/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9518 - loss: 0.4959 - val_accuracy: 0.9358 - val_loss: 0.5011\n",
      "Epoch 8/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9582 - loss: 0.4595 - val_accuracy: 0.9327 - val_loss: 0.5254\n",
      "Epoch 9/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.4503 - val_accuracy: 0.9205 - val_loss: 0.5467\n",
      "Epoch 10/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9587 - loss: 0.4311 - val_accuracy: 0.9205 - val_loss: 0.5528\n",
      "Epoch 11/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9713 - loss: 0.4053 - val_accuracy: 0.9144 - val_loss: 0.5517\n",
      "Fold 4 - Validation Accuracy: 0.9602\n",
      "\n",
      "=== Training Fold 5/5 ===\n",
      "Epoch 1/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8703 - loss: 0.7570 - val_accuracy: 0.9693 - val_loss: 0.4026\n",
      "Epoch 2/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8955 - loss: 0.6915 - val_accuracy: 0.9540 - val_loss: 0.4243\n",
      "Epoch 3/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8895 - loss: 0.6768 - val_accuracy: 0.9417 - val_loss: 0.4490\n",
      "Epoch 4/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9227 - loss: 0.5659 - val_accuracy: 0.9387 - val_loss: 0.4662\n",
      "Epoch 5/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9292 - loss: 0.5351 - val_accuracy: 0.9356 - val_loss: 0.4902\n",
      "Epoch 6/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9486 - loss: 0.4893 - val_accuracy: 0.9417 - val_loss: 0.4738\n",
      "Epoch 7/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9425 - loss: 0.4597 - val_accuracy: 0.9387 - val_loss: 0.4747\n",
      "Epoch 8/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9450 - loss: 0.4879 - val_accuracy: 0.9356 - val_loss: 0.4950\n",
      "Epoch 9/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9744 - loss: 0.4345 - val_accuracy: 0.9356 - val_loss: 0.5287\n",
      "Epoch 10/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9622 - loss: 0.4420 - val_accuracy: 0.9294 - val_loss: 0.5322\n",
      "Epoch 11/100\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9633 - loss: 0.4452 - val_accuracy: 0.9233 - val_loss: 0.5163\n",
      "Fold 5 - Validation Accuracy: 0.9693\n",
      "\n",
      "=== Average Validation Accuracy: 0.9272 ===\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "# Hyperparameters\n",
    "num_folds = 5\n",
    "batch_size = 8\n",
    "learning_rate = 1e-4\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "fold_accuracies = []\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(train_x)):\n",
    "    print(f\"\\n=== Training Fold {fold + 1}/{num_folds} ===\")\n",
    "    \n",
    "    X_train, X_val = train_x[train_index], train_x[val_index]\n",
    "    y_train, y_val = train_y[train_index], train_y[val_index]\n",
    "\n",
    "    tensorboard_callback = callbacks.TensorBoard(log_dir=f'./logs/fold_{fold+1}')\n",
    "    early_stopping_callback = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    \n",
    "    optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[tensorboard_callback, early_stopping_callback],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "    print(f\"Fold {fold + 1} - Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    fold_accuracies.append(val_accuracy)\n",
    "    \n",
    "avg_accuracy = np.mean(fold_accuracies)\n",
    "print(f\"\\n=== Average Validation Accuracy: {avg_accuracy:.4f} ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = callbacks.EarlyStopping(monitor='accuracy', patience=10, restore_best_weights=True)\n",
    "tensorboard_callback = callbacks.TensorBoard(log_dir='./logs/full_training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training tanpa split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8774 - loss: 0.7008\n",
      "Epoch 2/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8915 - loss: 0.6509\n",
      "Epoch 3/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.5823\n",
      "Epoch 4/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9260 - loss: 0.5465\n",
      "Epoch 5/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9217 - loss: 0.5386\n",
      "Epoch 6/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9315 - loss: 0.5000\n",
      "Epoch 7/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9412 - loss: 0.4758\n",
      "Epoch 8/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9617 - loss: 0.4461\n",
      "Epoch 9/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9550 - loss: 0.4466\n",
      "Epoch 10/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9582 - loss: 0.4273\n",
      "Epoch 11/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9699 - loss: 0.3997\n",
      "Epoch 12/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9548 - loss: 0.4059\n",
      "Epoch 13/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9646 - loss: 0.4012\n",
      "Epoch 14/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9688 - loss: 0.3822\n",
      "Epoch 15/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9739 - loss: 0.3742\n",
      "Epoch 16/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9717 - loss: 0.3770\n",
      "Epoch 17/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9745 - loss: 0.3762\n",
      "Epoch 18/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9585 - loss: 0.3729\n",
      "Epoch 19/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9740 - loss: 0.3507\n",
      "Epoch 20/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9748 - loss: 0.3444\n",
      "Epoch 21/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9745 - loss: 0.3407\n",
      "Epoch 22/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9760 - loss: 0.3415\n",
      "Epoch 23/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9759 - loss: 0.3313\n",
      "Epoch 24/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9782 - loss: 0.3253\n",
      "Epoch 25/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9762 - loss: 0.3322\n",
      "Epoch 26/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9883 - loss: 0.3046\n",
      "Epoch 27/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9775 - loss: 0.3098\n",
      "Epoch 28/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9793 - loss: 0.3191\n",
      "Epoch 29/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9820 - loss: 0.3066\n",
      "Epoch 30/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9779 - loss: 0.3100\n",
      "Epoch 31/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9725 - loss: 0.3083\n",
      "Epoch 32/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9825 - loss: 0.3034\n",
      "Epoch 33/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9812 - loss: 0.2816\n",
      "Epoch 34/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9683 - loss: 0.3266\n",
      "Epoch 35/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9721 - loss: 0.2984\n",
      "Epoch 36/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9856 - loss: 0.2752\n",
      "Epoch 37/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9817 - loss: 0.2692\n",
      "Epoch 38/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9758 - loss: 0.2871\n",
      "Epoch 39/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9759 - loss: 0.2755\n",
      "Epoch 40/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9750 - loss: 0.2772\n",
      "Epoch 41/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9795 - loss: 0.2596\n",
      "Epoch 42/100\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9798 - loss: 0.2566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "train_x, train_y = shuffle(train_x, train_y, random_state=42)\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train and save the final model\n",
    "model.fit(train_x, train_y, epochs=100, batch_size=8, callbacks=[tensorboard_callback, early_stopping_callback], verbose=1)\n",
    "model.save('final_model_trained_on_full_data.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save\n",
    "try:\n",
    "    with open(\"training_data.json\", \"w\") as file:\n",
    "        # Convert non-serializable data like NumPy arrays or other objects to lists\n",
    "        data = {'words': words, 'classes': classes, 'train_x': train_x.tolist(), 'train_y': train_y.tolist()}\n",
    "        json.dump(data, file)\n",
    "except IOError as e:\n",
    "    print(f\"Error saving training data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "try:\n",
    "    with open(\"training_data\", \"wb\") as file:\n",
    "        pickle.dump({'words': words, 'classes': classes, 'train_x': train_x, 'train_y': train_y}, file)\n",
    "except IOError as e:\n",
    "    print(f\"Error saving training data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DrOW8S1Y0un5",
    "outputId": "eae11a39-7021-45a3-d529-8717486e4090"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Load\n",
    "try:\n",
    "    with open(\"training_data\", \"rb\") as file:\n",
    "        data = pickle.load(file)\n",
    "\n",
    "    words = data['words']\n",
    "    classes = data['classes']\n",
    "    train_x = np.array(data['train_x'])\n",
    "    train_y = np.array(data['train_y'])\n",
    "except IOError as e:\n",
    "    print(f\"Error loading training data: {e}\")\n",
    "\n",
    "# Load model\n",
    "try:\n",
    "    model = keras.models.load_model('final_model_trained_on_full_data.h5')\n",
    "except IOError as e:\n",
    "    print(f\"Error loading model: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "XVD-P16Q19Ar"
   },
   "outputs": [],
   "source": [
    "def clean_up_sentence(sentence):\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    sentence_words = [stemmer.stem(word.lower()) for word in sentence_words]\n",
    "    return sentence_words\n",
    "\n",
    "def bow(sentence, words, show_details=False):\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    bag = np.zeros(len(words), dtype=np.float32)\n",
    "    for idx, w in enumerate(words):\n",
    "        if w in sentence_words:\n",
    "            bag[idx] = 1\n",
    "            if show_details:\n",
    "                print(f\"Found in bag: {w}\")\n",
    "    return bag\n",
    "\n",
    "ERROR_THRESHOLD = 0.40\n",
    "\n",
    "\n",
    "\n",
    "def classify(sentence):\n",
    "    input_data = bow(sentence, words)\n",
    "    results = model.predict(np.array([input_data]))[0]\n",
    "    results = [[i, r] for i, r in enumerate(results) if r >= ERROR_THRESHOLD]\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return [(classes[r[0]], r[1]) for r in results]\n",
    "\n",
    "def response(sentence, userID='123', show_details=False):\n",
    "    results = classify(sentence)\n",
    "    if results:\n",
    "        for intent in intents:\n",
    "            if intent['tag'] == results[0][0]:\n",
    "                return random.choice(intent['responses'])\n",
    "    return \"Maaf, saya belum mengerti apa yang Anda bicarakan, perlu bantuan?.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FO4ujct85h_h",
    "outputId": "a2cddf3f-f8f6-46fa-f780-79074e416a53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 to close\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " halo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Hallo! Apa kabar? Ada yang bisa saya bantu?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " bagaimana cara mengatasi overthinking?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Alihkan perhatianmu dengan aktivitas seperti meditasi, olahraga, atau hobi yang kamu nikmati.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " saya sedang mengalami overthinking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Berikan waktu untuk dirimu sendiri tanpa tekanan dan praktikkan mindfulness untuk tetap tenang.\n"
     ]
    }
   ],
   "source": [
    "print(\"0 to close\")\n",
    "while True:\n",
    "    message = input(\"\")\n",
    "    if message == \"0\":\n",
    "        break\n",
    "    result = response(message)\n",
    "\n",
    "    if result is not None and \"~\" in result:\n",
    "        order = (result[1:])\n",
    "        action(order)\n",
    "    else:\n",
    "        print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xRRvDLhl0kI_",
    "outputId": "180f72b1-0bec-45f4-eb82-9b704c1713d2"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('final_model_trained_on_full_data.h5')\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "\n",
    "with open('model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
