{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OFDSdvxj6ApJ",
    "outputId": "8d7e03b8-3c29-4e9e-f4a0-dd1b619499a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PySastrawi in c:\\users\\dzikr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install PySastrawi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sgol4Y_Y6ApP",
    "outputId": "bd880933-4700-4196-d8e7-bf0eeea86d4f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dzikr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "nMmyJPc5v2s8"
   },
   "outputs": [],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import pickle\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import nltk\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras import layers, models, callbacks, optimizers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "AyCMTd3BxH5v"
   },
   "outputs": [],
   "source": [
    "# Load the intents file\n",
    "with open('nlp_dataset_faq.json') as data_file:\n",
    "    intents = json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apa', 'kabar', '?']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dzikr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "pattern = \"Apa kabar?\"\n",
    "w = nltk.word_tokenize(pattern.lower())\n",
    "print(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LzYlZchPxkrj",
    "outputId": "a02e3f10-25e2-49bd-99e0-2e6b517310d9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\dzikr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download the 'punkt_tab' data package\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Pre-processing\n",
    "words = []\n",
    "classes = []\n",
    "documents = []\n",
    "ignore = ['','!', '\"', \"'\", '(', ')', ',', '-', '.', ':', ';','[', ']', '_','?','.'\n",
    "          'adalah', 'akan', 'aku', 'anda', 'atau', 'dalam', 'dan',\n",
    "          'dari', 'dengan', 'di', 'dia', 'harus', 'ini', 'itu', 'jika', 'kami', 'kamu', 'ke',\n",
    "          'kita', 'mereka', 'oleh', 'pada', 'saya', 'sebuah', 'sedang', 'sementara', 'tanpa',\n",
    "          'tapi', 'telah', 'untuk', 'yang', '{', '}', 'merasa']\n",
    "\n",
    "\n",
    "\n",
    "#tokenize\n",
    "for intent in intents:\n",
    "    for pattern in intent['patterns']:\n",
    "        w = nltk.word_tokenize(pattern.lower())  # Tokenizing\n",
    "        words.extend([word for word in w if word not in ignore])  #Ignore\n",
    "        documents.append((w, intent['tag']))\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3OjNRWsryAlH",
    "outputId": "ad6913c3-fa46-4cf9-c12c-29f3ab63c088"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1535 documents\n",
      "76 classes ['apa_itu_gangguan_mental', 'badmood_dampak', 'badmood_efek_jangka_panjang', 'badmood_gejala', 'badmood_pengobatan', 'badmood_penyebab', 'badmood_preventif', 'badmood_solusi_pribadi', 'badmood_terhadap_kesehatan_fisik', 'badmood_terhadap_pekerjaan', 'bunuh_diri', 'cara_mengatasi_benci', 'cara_mengatasi_bingung', 'cara_mengatasi_cemburu', 'cara_mengatasi_dendam', 'cara_mengatasi_frustasi', 'cara_mengatasi_gangguan_mental', 'cara_mengatasi_hampa', 'cara_mengatasi_iri', 'cara_mengatasi_kecewa', 'cara_mengatasi_kesal', 'cara_mengatasi_malu', 'cara_mengatasi_marah', 'cara_mengatasi_merasa_sendiri', 'cara_mengatasi_sedih', 'cara_mengatasi_takut', 'cara_mengatasi_takut_gagal', 'cara_mengatasi_tidak_dihargai', 'diagnosis_gangguan_mental', 'dukungan_mental_terapi', 'efek_gangguan_mental', 'emosi_bingung', 'emosi_frustrasi', 'emosi_hampa', 'emosi_kecewa', 'emosi_lelah', 'emosi_marah', 'emosi_sedih', 'emosi_senang', 'emosi_takut', 'emosi_takut_gagal', 'emosi_terbebani', 'emosi_tertekan', 'emosi_tidak_dihargai', 'gangguan_mental_dan_bipolar', 'gangguan_mental_dan_depresi', 'gangguan_mental_dan_kecemasan', 'gangguan_mental_dan_psikoedukasi', 'gangguan_mental_dan_psikoterapi', 'gangguan_mental_dan_stigma', 'gangguan_mental_untuk_anak', 'gejala_gangguan_mental', 'kabar_baik', 'kabar_buruk', 'kabar_netral', 'mood_bahagia', 'mood_cemas', 'mood_marahan', 'mood_membaik', 'mood_motivation', 'mood_sedih', 'mood_stress_relief', 'penanganan_gangguan_mental', 'pencegahan_gangguan_mental', 'pengobatan_gangguan_mental', 'penyebab_gangguan_mental', 'perbedaan_gangguan_mental_dan_stres', 'perkenalan_diri', 'perpisahan', 'salam_halo', 'salam_hi_tes', 'salam_terima_kasih', 'sapaan_pagi', 'sapaan_tanya_kabar', 'tanya_bantuan_terdekat', 'ucapan_terima_kasih']\n",
      "529 unique stemmed words ['abai', 'ada', 'adalah', 'adil', 'agar', 'ahli', 'ajar', 'akhir', 'akibat', 'aktif', 'aktivitas', 'aku', 'alami', 'alas', 'alih', 'alkohol', 'aman', 'amarah', 'amarahku', 'ambil', 'anak', 'anggap', 'antara', 'antidepresan', 'apa', 'apakah', 'arah', 'arti', 'asa', 'asal', 'asmara', 'atas', 'atur', 'awal', 'awat', 'bad', 'badan', 'bagai', 'bagaimana', 'bagi', 'bahagia', 'bahaya', 'bahwa', 'baik', 'balas', 'balik', 'banget', 'bangkit', 'bantu', 'banyak', 'baru', 'beban', 'beda', 'begitu', 'belum', 'benar', 'benci', 'berani', 'berapa', 'berat', 'beri', 'besar', 'biar', 'biasa', 'bicara', 'bingung', 'bipolar', 'bisa', 'boleh', 'buat', 'bugar', 'bukan', 'buruk', 'butuh', 'capai', 'capek', 'cara', 'cari', 'cegah', 'cemas', 'cemburu', 'cepat', 'cerah', 'cerita', 'cerna', 'chat', 'chatbot', 'cinta', 'ciri', 'coba', 'cuaca', 'cukup', 'dadah', 'damai', 'dampak', 'dapat', 'darah', 'datang', 'daya', 'definisi', 'dekat', 'dendam', 'dengan', 'dengar', 'depan', 'depresi', 'derita', 'deteksi', 'dewasa', 'diagnosis', 'diet', 'diri', 'dokter', 'dong', 'down', 'dukung', 'dunia', 'edukasi', 'efek', 'efektif', 'ekonomi', 'ekspektasi', 'elektrokonvulsif', 'emosi', 'emosional', 'enak', 'energi', 'energik', 'episode', 'erti', 'faktor', 'fisik', 'fokus', 'frustrasi', 'fungsi', 'gagal', 'ganggu', 'gaya', 'gejala', 'gelap', 'gelisah', 'gembira', 'genetik', 'genetika', 'guna', 'habis', 'hadap', 'hai', 'hal', 'halang', 'hallo', 'halo', 'hambat', 'hampa', 'hantu', 'hanya', 'harap', 'harga', 'hari', 'hasil', 'hati', 'hebat', 'henti', 'hi', 'hidup', 'hilang', 'hindar', 'hormat', 'hormon', 'hubung', 'identifikasi', 'ikut', 'implementasi', 'imun', 'indikator', 'individu', 'ingin', 'insomnia', 'inspirasi', 'intens', 'intervensi', 'iri', 'isi', 'isolasi', 'istimewa', 'istirahat', 'jadi', 'jaga', 'jalan', 'jangka', 'jawab', 'jebak', 'jelas', 'jenak', 'jengkel', 'jenis', 'jepit', 'jernih', 'juga', 'jumpa', 'jurnal', 'kabar', 'kait', 'kalau', 'kantor', 'karena', 'kasih', 'kata', 'kategori', 'kebal', 'kecewa', 'kecil', 'kelola', 'kelompok', 'keluar', 'keluarga', 'kemarin', 'kembali', 'kembang', 'kena', 'kenal', 'kenapa', 'kendali', 'kepada', 'kepala', 'keras', 'kerja', 'kerjasamanya', 'kesal', 'ketika', 'kewalahan', 'khawatir', 'khianat', 'khusus', 'kognitif', 'komunikasi', 'kondisi', 'konflik', 'konselor', 'kontrol', 'kosong', 'kronis', 'kualitas', 'kuasa', 'kunjung', 'kurang', 'lagi', 'lain', 'laku', 'lalu', 'lama', 'lancar', 'lang', 'langkah', 'langsung', 'lanjut', 'lari', 'lawan', 'layan', 'layar', 'lebih', 'ledak', 'lelah', 'lemah', 'lengkap', 'lepas', 'lesu', 'lewat', 'libat', 'lihat', 'lingkung', 'luap', 'luar', 'luka', 'lumpuh', 'lupa', 'maju', 'makan', 'makasih', 'makin', 'makna', 'maksud', 'malam', 'malas', 'malu', 'mampu', 'mana', 'mandiri', 'manfaat', 'mania', 'marah', 'masa', 'masalah', 'masuk', 'masyarakat', 'mati', 'medis', 'meditasi', 'menang', 'mengapa', 'menghadang', 'mental', 'meski', 'metabolisme', 'metode', 'mikrofon', 'milik', 'moga', 'mood', 'moodku', 'moral', 'motivasi', 'mudah', 'mulai', 'muncul', 'murung', 'musik', 'nali', 'nama', 'nan', 'napas', 'negatif', 'netral', 'nggak', 'nih', 'nomor', 'normal', 'nyaman', 'nyata', 'obat', 'olah', 'olahraga', 'optimis', 'orang', 'pagi', 'paham', 'paling', 'panggil', 'panjang', 'parah', 'pasti', 'peduli', 'pengaruh', 'penting', 'penuh', 'peran', 'perangkap', 'percaya', 'pergi', 'perhati', 'periksa', 'perilaku', 'peristiwa', 'perlu', 'pernah', 'pertama', 'picu', 'pikir', 'pikul', 'pilih', 'pola', 'positif', 'preventif', 'pribadi', 'produktif', 'produktivitas', 'profesional', 'proses', 'psikoedukasi', 'psikologi', 'psikologis', 'psikoterapi', 'psikoterapis', 'puas', 'pulih', 'pun', 'pundak', 'punya', 'puruk', 'putus', 'ragu', 'rasa', 'reda', 'rekan', 'rekomendasi', 'relaksasi', 'remaja', 'remeh', 'rencana', 'rendah', 'rentan', 'rileks', 'risiko', 'rumah', 'rusak', 'saat', 'sabar', 'sadar', 'saja', 'sakit', 'salah', 'sama', 'sampai', 'sana', 'sangat', 'santai', 'saran', 'sebab', 'sebut', 'sedia', 'sedih', 'sedikit', 'segala', 'segar', 'segera', 'sehat', 'sekali', 'sekaligus', 'sekarang', 'sekitar', 'selalu', 'selamat', 'selesai', 'semangat', 'sembuh', 'sempurna', 'semua', 'senang', 'sendiri', 'seperti', 'sepi', 'serah', 'sering', 'serta', 'sesal', 'sesat', 'sesi', 'sesuai', 'sesuatu', 'sia', 'siap', 'siapa', 'sibuk', 'sih', 'sikap', 'simpan', 'singgung', 'singkat', 'sini', 'sisa', 'sistem', 'situasi', 'solusi', 'sosial', 'spesial', 'stabil', 'stigma', 'stres', 'suara', 'suasana', 'sudah', 'suka', 'sulit', 'supaya', 'syukur', 'tahan', 'tahu', 'tak', 'takut', 'tanda', 'tangan', 'tanggung', 'tanya', 'target', 'tarik', 'tegang', 'tekan', 'teknik', 'telah', 'telepon', 'teman', 'tempat', 'temu', 'tenang', 'tengah', 'tenggelam', 'tentang', 'tentu', 'tepat', 'terap', 'terapi', 'terima', 'terlalu', 'terus', 'tes', 'tetap', 'tetapi', 'tiap', 'tiba', 'tidak', 'tidur', 'tinggal', 'tinggi', 'tingkat', 'tips', 'tolong', 'tonjol', 'trauma', 'tua', 'tubuh', 'tuju', 'tunjuk', 'tuntut', 'turun', 'uang', 'ubah', 'ujung', 'umum', 'untung', 'usaha', 'utama', 'waktu', 'waris', 'warna', 'was-was', 'waspada', 'ya', 'yakin', 'yoga']\n"
     ]
    }
   ],
   "source": [
    "# Melakukan stemming dan normalisasi data\n",
    "words = [stemmer.stem(w.lower()) for w in words if w not in ignore]\n",
    "words = sorted(list(set(words)))\n",
    "\n",
    "# Menghapus class duplikat dengan 'set'\n",
    "classes = sorted(list(set(classes)))\n",
    "\n",
    "print(len(documents), \"documents\")\n",
    "print(len(classes), \"classes\", classes)\n",
    "print(len(words), \"unique stemmed words\", words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "o3bG67i3yL2q"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "training = []\n",
    "output_empty = [0] * len(classes)\n",
    "\n",
    "for doc in documents:\n",
    "    pattern_words = [stemmer.stem(word.lower()) for word in doc[0]]\n",
    "    bag = [1 if w in pattern_words else 0 for w in words]\n",
    "\n",
    "    output_row = output_empty[:]\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "\n",
    "    training.append([bag, output_row])\n",
    "\n",
    "random.shuffle(training)\n",
    "training = np.array(training, dtype=object)\n",
    "\n",
    "train_x = np.array([item[0] for item in training])\n",
    "train_y = np.array([item[1] for item in training])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "        layers.Input(shape=(len(train_x[0]),), name='input_layer'),\n",
    "        layers.Dense(256, activation='relu', kernel_regularizer='l2', name='hidden_layer1'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3, name='dropout1'),\n",
    "        layers.Dense(128, activation='relu', kernel_regularizer='l2', name='hidden_layer2'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3, name='dropout2'),\n",
    "        layers.Dense(len(train_y[0]), activation='softmax', name='output_layer')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ hidden_layer1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">135,680</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ hidden_layer2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">76</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,804</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ hidden_layer1 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m135,680\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout1 (\u001b[38;5;33mDropout\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ hidden_layer2 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout2 (\u001b[38;5;33mDropout\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m76\u001b[0m)                  │           \u001b[38;5;34m9,804\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">179,916</span> (702.80 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m179,916\u001b[0m (702.80 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">179,148</span> (699.80 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m179,148\u001b[0m (699.80 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K_FOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2j75XSbGyalB",
    "outputId": "bbad24ff-51fd-4440-d144-bfe4011cf099"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dzikr\\AppData\\Local\\Temp\\ipykernel_16600\\3785205646.py:1: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "\n",
      "=== Training Fold 1/5 ===\n",
      "Epoch 1/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0173 - loss: 10.0398 - val_accuracy: 0.0000e+00 - val_loss: 8.6833\n",
      "Epoch 2/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0199 - loss: 8.9098 - val_accuracy: 0.0228 - val_loss: 8.2170\n",
      "Epoch 3/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0339 - loss: 8.1830 - val_accuracy: 0.0749 - val_loss: 7.7187\n",
      "Epoch 4/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0876 - loss: 7.7185 - val_accuracy: 0.1564 - val_loss: 7.2563\n",
      "Epoch 5/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0994 - loss: 7.2772 - val_accuracy: 0.1987 - val_loss: 6.8845\n",
      "Epoch 6/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1635 - loss: 6.8966 - val_accuracy: 0.2248 - val_loss: 6.5683\n",
      "Epoch 7/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2078 - loss: 6.6024 - val_accuracy: 0.2769 - val_loss: 6.2946\n",
      "Epoch 8/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2676 - loss: 6.2818 - val_accuracy: 0.3420 - val_loss: 6.0597\n",
      "Epoch 9/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3538 - loss: 5.9569 - val_accuracy: 0.3909 - val_loss: 5.8358\n",
      "Epoch 10/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3287 - loss: 5.7891 - val_accuracy: 0.4169 - val_loss: 5.6429\n",
      "Epoch 11/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3803 - loss: 5.5565 - val_accuracy: 0.4430 - val_loss: 5.4419\n",
      "Epoch 12/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4915 - loss: 5.1977 - val_accuracy: 0.4853 - val_loss: 5.2648\n",
      "Epoch 13/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5100 - loss: 5.1140 - val_accuracy: 0.5114 - val_loss: 5.0977\n",
      "Epoch 14/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5327 - loss: 4.9635 - val_accuracy: 0.5375 - val_loss: 4.9442\n",
      "Epoch 15/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5689 - loss: 4.6942 - val_accuracy: 0.5668 - val_loss: 4.7976\n",
      "Epoch 16/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6072 - loss: 4.5361 - val_accuracy: 0.5733 - val_loss: 4.6516\n",
      "Epoch 17/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6497 - loss: 4.3964 - val_accuracy: 0.5765 - val_loss: 4.5265\n",
      "Epoch 18/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6591 - loss: 4.2629 - val_accuracy: 0.6059 - val_loss: 4.3942\n",
      "Epoch 19/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6788 - loss: 4.1302 - val_accuracy: 0.6189 - val_loss: 4.2822\n",
      "Epoch 20/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7047 - loss: 4.0162 - val_accuracy: 0.6221 - val_loss: 4.1795\n",
      "Epoch 21/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7452 - loss: 3.8557 - val_accuracy: 0.6254 - val_loss: 4.0725\n",
      "Epoch 22/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 3.7012 - val_accuracy: 0.6254 - val_loss: 3.9754\n",
      "Epoch 23/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7569 - loss: 3.6199 - val_accuracy: 0.6352 - val_loss: 3.8894\n",
      "Epoch 24/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7802 - loss: 3.4777 - val_accuracy: 0.6384 - val_loss: 3.8020\n",
      "Epoch 25/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8103 - loss: 3.3473 - val_accuracy: 0.6417 - val_loss: 3.7269\n",
      "Epoch 26/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8046 - loss: 3.2565 - val_accuracy: 0.6482 - val_loss: 3.6463\n",
      "Epoch 27/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7993 - loss: 3.2304 - val_accuracy: 0.6515 - val_loss: 3.5710\n",
      "Epoch 28/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8424 - loss: 3.0913 - val_accuracy: 0.6482 - val_loss: 3.5037\n",
      "Epoch 29/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8388 - loss: 3.0208 - val_accuracy: 0.6547 - val_loss: 3.4360\n",
      "Epoch 30/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8495 - loss: 2.8798 - val_accuracy: 0.6678 - val_loss: 3.3686\n",
      "Epoch 31/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8628 - loss: 2.8277 - val_accuracy: 0.6743 - val_loss: 3.3103\n",
      "Epoch 32/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8806 - loss: 2.7415 - val_accuracy: 0.6743 - val_loss: 3.2551\n",
      "Epoch 33/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8646 - loss: 2.6588 - val_accuracy: 0.6710 - val_loss: 3.2004\n",
      "Epoch 34/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8794 - loss: 2.5909 - val_accuracy: 0.6743 - val_loss: 3.1449\n",
      "Epoch 35/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8833 - loss: 2.5108 - val_accuracy: 0.6775 - val_loss: 3.0890\n",
      "Epoch 36/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8833 - loss: 2.4504 - val_accuracy: 0.6873 - val_loss: 3.0418\n",
      "Epoch 37/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8991 - loss: 2.3937 - val_accuracy: 0.6906 - val_loss: 3.0000\n",
      "Epoch 38/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8977 - loss: 2.3494 - val_accuracy: 0.6840 - val_loss: 2.9495\n",
      "Epoch 39/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8908 - loss: 2.2776 - val_accuracy: 0.6873 - val_loss: 2.9083\n",
      "Epoch 40/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9093 - loss: 2.2017 - val_accuracy: 0.6873 - val_loss: 2.8549\n",
      "Epoch 41/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9169 - loss: 2.1289 - val_accuracy: 0.6840 - val_loss: 2.8165\n",
      "Epoch 42/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9146 - loss: 2.0768 - val_accuracy: 0.6873 - val_loss: 2.7925\n",
      "Epoch 43/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9240 - loss: 2.0368 - val_accuracy: 0.6906 - val_loss: 2.7456\n",
      "Epoch 44/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9350 - loss: 1.9303 - val_accuracy: 0.6938 - val_loss: 2.7099\n",
      "Epoch 45/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9323 - loss: 1.9075 - val_accuracy: 0.7003 - val_loss: 2.6702\n",
      "Epoch 46/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9510 - loss: 1.8554 - val_accuracy: 0.6971 - val_loss: 2.6314\n",
      "Epoch 47/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9261 - loss: 1.8237 - val_accuracy: 0.7003 - val_loss: 2.6124\n",
      "Epoch 48/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9353 - loss: 1.7701 - val_accuracy: 0.7036 - val_loss: 2.5746\n",
      "Epoch 49/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9375 - loss: 1.7138 - val_accuracy: 0.7166 - val_loss: 2.5368\n",
      "Epoch 50/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9445 - loss: 1.6816 - val_accuracy: 0.7068 - val_loss: 2.5152\n",
      "Epoch 51/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9446 - loss: 1.6286 - val_accuracy: 0.7068 - val_loss: 2.4773\n",
      "Epoch 52/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9425 - loss: 1.5894 - val_accuracy: 0.7003 - val_loss: 2.4571\n",
      "Epoch 53/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9496 - loss: 1.5502 - val_accuracy: 0.7036 - val_loss: 2.4284\n",
      "Epoch 54/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9545 - loss: 1.4987 - val_accuracy: 0.7101 - val_loss: 2.3942\n",
      "Epoch 55/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9528 - loss: 1.4550 - val_accuracy: 0.7036 - val_loss: 2.3827\n",
      "Epoch 56/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 1.4413 - val_accuracy: 0.7068 - val_loss: 2.3680\n",
      "Epoch 57/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9553 - loss: 1.3955 - val_accuracy: 0.7068 - val_loss: 2.3346\n",
      "Epoch 58/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9665 - loss: 1.3357 - val_accuracy: 0.7068 - val_loss: 2.3082\n",
      "Epoch 59/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9457 - loss: 1.3436 - val_accuracy: 0.7134 - val_loss: 2.2803\n",
      "Epoch 60/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9634 - loss: 1.2746 - val_accuracy: 0.7134 - val_loss: 2.2596\n",
      "Epoch 61/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9634 - loss: 1.2605 - val_accuracy: 0.7166 - val_loss: 2.2465\n",
      "Epoch 62/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9661 - loss: 1.2245 - val_accuracy: 0.7199 - val_loss: 2.2267\n",
      "Epoch 63/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9663 - loss: 1.1895 - val_accuracy: 0.7068 - val_loss: 2.1919\n",
      "Epoch 64/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9617 - loss: 1.1493 - val_accuracy: 0.7036 - val_loss: 2.1817\n",
      "Epoch 65/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9707 - loss: 1.1136 - val_accuracy: 0.7036 - val_loss: 2.1745\n",
      "Epoch 66/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9596 - loss: 1.1036 - val_accuracy: 0.7036 - val_loss: 2.1417\n",
      "Epoch 67/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9700 - loss: 1.0464 - val_accuracy: 0.7068 - val_loss: 2.1116\n",
      "Epoch 68/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9745 - loss: 1.0384 - val_accuracy: 0.7036 - val_loss: 2.0905\n",
      "Epoch 69/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9702 - loss: 1.0238 - val_accuracy: 0.7003 - val_loss: 2.0776\n",
      "Epoch 70/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9691 - loss: 0.9852 - val_accuracy: 0.7036 - val_loss: 2.0656\n",
      "Epoch 71/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9812 - loss: 0.9458 - val_accuracy: 0.7101 - val_loss: 2.0680\n",
      "Epoch 72/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9695 - loss: 0.9469 - val_accuracy: 0.7003 - val_loss: 2.0315\n",
      "Epoch 73/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9854 - loss: 0.8921 - val_accuracy: 0.6906 - val_loss: 2.0145\n",
      "Epoch 74/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9826 - loss: 0.8829 - val_accuracy: 0.7003 - val_loss: 1.9952\n",
      "Epoch 75/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9785 - loss: 0.8675 - val_accuracy: 0.6906 - val_loss: 1.9914\n",
      "Epoch 76/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9797 - loss: 0.8505 - val_accuracy: 0.7101 - val_loss: 1.9851\n",
      "Epoch 77/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9798 - loss: 0.8175 - val_accuracy: 0.6938 - val_loss: 1.9699\n",
      "Epoch 78/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9757 - loss: 0.8059 - val_accuracy: 0.7003 - val_loss: 1.9402\n",
      "Epoch 79/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9818 - loss: 0.7810 - val_accuracy: 0.7003 - val_loss: 1.9288\n",
      "Epoch 80/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9737 - loss: 0.7812 - val_accuracy: 0.7264 - val_loss: 1.9176\n",
      "Epoch 81/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9786 - loss: 0.7465 - val_accuracy: 0.7101 - val_loss: 1.9139\n",
      "Epoch 82/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9742 - loss: 0.7383 - val_accuracy: 0.7003 - val_loss: 1.9247\n",
      "Epoch 83/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9850 - loss: 0.7107 - val_accuracy: 0.7036 - val_loss: 1.8925\n",
      "Epoch 84/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9816 - loss: 0.7034 - val_accuracy: 0.7068 - val_loss: 1.9004\n",
      "Epoch 85/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9882 - loss: 0.6733 - val_accuracy: 0.7134 - val_loss: 1.8940\n",
      "Epoch 86/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9710 - loss: 0.6729 - val_accuracy: 0.7068 - val_loss: 1.8781\n",
      "Epoch 87/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9768 - loss: 0.6720 - val_accuracy: 0.6971 - val_loss: 1.8622\n",
      "Epoch 88/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9888 - loss: 0.6230 - val_accuracy: 0.7036 - val_loss: 1.8453\n",
      "Epoch 89/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9790 - loss: 0.6241 - val_accuracy: 0.7101 - val_loss: 1.8170\n",
      "Epoch 90/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9725 - loss: 0.6170 - val_accuracy: 0.7068 - val_loss: 1.8074\n",
      "Epoch 91/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9840 - loss: 0.5979 - val_accuracy: 0.7101 - val_loss: 1.8239\n",
      "Epoch 92/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9837 - loss: 0.5812 - val_accuracy: 0.7068 - val_loss: 1.8226\n",
      "Epoch 93/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9841 - loss: 0.5683 - val_accuracy: 0.7068 - val_loss: 1.8241\n",
      "Epoch 94/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9910 - loss: 0.5456 - val_accuracy: 0.7166 - val_loss: 1.8387\n",
      "Epoch 95/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9743 - loss: 0.5579 - val_accuracy: 0.6971 - val_loss: 1.8446\n",
      "Epoch 96/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9876 - loss: 0.5305 - val_accuracy: 0.6906 - val_loss: 1.8513\n",
      "Epoch 97/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9830 - loss: 0.5213 - val_accuracy: 0.6873 - val_loss: 1.8538\n",
      "Epoch 98/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9881 - loss: 0.5079 - val_accuracy: 0.6808 - val_loss: 1.8471\n",
      "Epoch 99/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9757 - loss: 0.5083 - val_accuracy: 0.6906 - val_loss: 1.8766\n",
      "Epoch 100/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9859 - loss: 0.4798 - val_accuracy: 0.6840 - val_loss: 1.8600\n",
      "Fold 1 - Validation Accuracy: 0.7068\n",
      "\n",
      "=== Training Fold 2/5 ===\n",
      "Epoch 1/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8919 - loss: 0.8993 - val_accuracy: 0.9870 - val_loss: 0.4966\n",
      "Epoch 2/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8926 - loss: 0.8976 - val_accuracy: 0.9739 - val_loss: 0.5145\n",
      "Epoch 3/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9060 - loss: 0.8051 - val_accuracy: 0.9609 - val_loss: 0.5399\n",
      "Epoch 4/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9252 - loss: 0.7243 - val_accuracy: 0.9642 - val_loss: 0.5484\n",
      "Epoch 5/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9192 - loss: 0.7188 - val_accuracy: 0.9544 - val_loss: 0.5646\n",
      "Epoch 6/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9607 - loss: 0.6046 - val_accuracy: 0.9609 - val_loss: 0.5526\n",
      "Epoch 7/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9433 - loss: 0.6509 - val_accuracy: 0.9609 - val_loss: 0.5618\n",
      "Epoch 8/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9633 - loss: 0.6025 - val_accuracy: 0.9544 - val_loss: 0.5719\n",
      "Epoch 9/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9642 - loss: 0.5883 - val_accuracy: 0.9577 - val_loss: 0.5737\n",
      "Epoch 10/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9521 - loss: 0.5965 - val_accuracy: 0.9446 - val_loss: 0.5978\n",
      "Epoch 11/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9613 - loss: 0.5756 - val_accuracy: 0.9446 - val_loss: 0.6039\n",
      "Fold 2 - Validation Accuracy: 0.9870\n",
      "\n",
      "=== Training Fold 3/5 ===\n",
      "Epoch 1/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8950 - loss: 0.8946 - val_accuracy: 0.9837 - val_loss: 0.4948\n",
      "Epoch 2/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9078 - loss: 0.8156 - val_accuracy: 0.9707 - val_loss: 0.5033\n",
      "Epoch 3/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9274 - loss: 0.7451 - val_accuracy: 0.9707 - val_loss: 0.5158\n",
      "Epoch 4/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9124 - loss: 0.7243 - val_accuracy: 0.9707 - val_loss: 0.5242\n",
      "Epoch 5/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9260 - loss: 0.6593 - val_accuracy: 0.9642 - val_loss: 0.5445\n",
      "Epoch 6/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9166 - loss: 0.6845 - val_accuracy: 0.9609 - val_loss: 0.5417\n",
      "Epoch 7/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9528 - loss: 0.6092 - val_accuracy: 0.9544 - val_loss: 0.5541\n",
      "Epoch 8/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9592 - loss: 0.5568 - val_accuracy: 0.9609 - val_loss: 0.5456\n",
      "Epoch 9/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9585 - loss: 0.5905 - val_accuracy: 0.9642 - val_loss: 0.5528\n",
      "Epoch 10/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9603 - loss: 0.5623 - val_accuracy: 0.9577 - val_loss: 0.5592\n",
      "Epoch 11/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9558 - loss: 0.5542 - val_accuracy: 0.9511 - val_loss: 0.5747\n",
      "Fold 3 - Validation Accuracy: 0.9837\n",
      "\n",
      "=== Training Fold 4/5 ===\n",
      "Epoch 1/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8709 - loss: 0.8871 - val_accuracy: 0.9707 - val_loss: 0.4985\n",
      "Epoch 2/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8797 - loss: 0.8074 - val_accuracy: 0.9544 - val_loss: 0.5270\n",
      "Epoch 3/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9088 - loss: 0.7413 - val_accuracy: 0.9479 - val_loss: 0.5482\n",
      "Epoch 4/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9065 - loss: 0.7193 - val_accuracy: 0.9381 - val_loss: 0.5618\n",
      "Epoch 5/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9111 - loss: 0.6983 - val_accuracy: 0.9381 - val_loss: 0.5620\n",
      "Epoch 6/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9497 - loss: 0.6175 - val_accuracy: 0.9381 - val_loss: 0.5619\n",
      "Epoch 7/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9289 - loss: 0.6052 - val_accuracy: 0.9349 - val_loss: 0.5793\n",
      "Epoch 8/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9545 - loss: 0.5802 - val_accuracy: 0.9446 - val_loss: 0.5969\n",
      "Epoch 9/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9438 - loss: 0.5655 - val_accuracy: 0.9316 - val_loss: 0.6103\n",
      "Epoch 10/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9720 - loss: 0.5431 - val_accuracy: 0.9316 - val_loss: 0.6156\n",
      "Epoch 11/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9623 - loss: 0.5457 - val_accuracy: 0.9186 - val_loss: 0.6534\n",
      "Fold 4 - Validation Accuracy: 0.9707\n",
      "\n",
      "=== Training Fold 5/5 ===\n",
      "Epoch 1/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8556 - loss: 0.9476 - val_accuracy: 0.9642 - val_loss: 0.4972\n",
      "Epoch 2/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8846 - loss: 0.8153 - val_accuracy: 0.9609 - val_loss: 0.5220\n",
      "Epoch 3/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9183 - loss: 0.6802 - val_accuracy: 0.9414 - val_loss: 0.5448\n",
      "Epoch 4/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9144 - loss: 0.6895 - val_accuracy: 0.9446 - val_loss: 0.5625\n",
      "Epoch 5/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9251 - loss: 0.6500 - val_accuracy: 0.9414 - val_loss: 0.5800\n",
      "Epoch 6/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9291 - loss: 0.6334 - val_accuracy: 0.9316 - val_loss: 0.5902\n",
      "Epoch 7/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9485 - loss: 0.5750 - val_accuracy: 0.9381 - val_loss: 0.5970\n",
      "Epoch 8/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9414 - loss: 0.5984 - val_accuracy: 0.9283 - val_loss: 0.6161\n",
      "Epoch 9/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9443 - loss: 0.5720 - val_accuracy: 0.9218 - val_loss: 0.6234\n",
      "Epoch 10/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9528 - loss: 0.5709 - val_accuracy: 0.9153 - val_loss: 0.6432\n",
      "Epoch 11/100\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9651 - loss: 0.5080 - val_accuracy: 0.9186 - val_loss: 0.6540\n",
      "Fold 5 - Validation Accuracy: 0.9642\n",
      "\n",
      "=== Average Validation Accuracy: 0.9225 ===\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "# Hyperparameters\n",
    "num_folds = 5\n",
    "batch_size = 8\n",
    "learning_rate = 1e-4\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "fold_accuracies = []\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(train_x)):\n",
    "    print(f\"\\n=== Training Fold {fold + 1}/{num_folds} ===\")\n",
    "    \n",
    "    X_train, X_val = train_x[train_index], train_x[val_index]\n",
    "    y_train, y_val = train_y[train_index], train_y[val_index]\n",
    "\n",
    "    tensorboard_callback = callbacks.TensorBoard(log_dir=f'./logs/fold_{fold+1}')\n",
    "    early_stopping_callback = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    \n",
    "    optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[tensorboard_callback, early_stopping_callback],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "    print(f\"Fold {fold + 1} - Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    fold_accuracies.append(val_accuracy)\n",
    "    \n",
    "avg_accuracy = np.mean(fold_accuracies)\n",
    "print(f\"\\n=== Average Validation Accuracy: {avg_accuracy:.4f} ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = callbacks.EarlyStopping(monitor='accuracy', patience=10, restore_best_weights=True)\n",
    "tensorboard_callback = callbacks.TensorBoard(log_dir='./logs/full_training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training tanpa split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8558 - loss: 0.8863\n",
      "Epoch 2/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8913 - loss: 0.7749\n",
      "Epoch 3/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9203 - loss: 0.7058\n",
      "Epoch 4/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9050 - loss: 0.6883\n",
      "Epoch 5/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9314 - loss: 0.6274\n",
      "Epoch 6/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9223 - loss: 0.6490\n",
      "Epoch 7/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9375 - loss: 0.5809\n",
      "Epoch 8/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9429 - loss: 0.5670\n",
      "Epoch 9/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9460 - loss: 0.5644\n",
      "Epoch 10/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9498 - loss: 0.5394\n",
      "Epoch 11/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9401 - loss: 0.5727\n",
      "Epoch 12/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9528 - loss: 0.5090\n",
      "Epoch 13/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9604 - loss: 0.4788\n",
      "Epoch 14/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9585 - loss: 0.4910\n",
      "Epoch 15/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9696 - loss: 0.4668\n",
      "Epoch 16/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9741 - loss: 0.4516\n",
      "Epoch 17/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9682 - loss: 0.4581\n",
      "Epoch 18/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9685 - loss: 0.4434\n",
      "Epoch 19/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9733 - loss: 0.4273\n",
      "Epoch 20/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9693 - loss: 0.4249\n",
      "Epoch 21/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9713 - loss: 0.4217\n",
      "Epoch 22/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9766 - loss: 0.3999\n",
      "Epoch 23/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9697 - loss: 0.4147\n",
      "Epoch 24/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9728 - loss: 0.4035\n",
      "Epoch 25/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9725 - loss: 0.4151\n",
      "Epoch 26/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9717 - loss: 0.4049\n",
      "Epoch 27/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9731 - loss: 0.3928\n",
      "Epoch 28/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9814 - loss: 0.3675\n",
      "Epoch 29/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9793 - loss: 0.3681\n",
      "Epoch 30/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9772 - loss: 0.3750\n",
      "Epoch 31/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9761 - loss: 0.3590\n",
      "Epoch 32/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9689 - loss: 0.3674\n",
      "Epoch 33/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9765 - loss: 0.3609\n",
      "Epoch 34/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9802 - loss: 0.3487\n",
      "Epoch 35/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9812 - loss: 0.3307\n",
      "Epoch 36/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9744 - loss: 0.3373\n",
      "Epoch 37/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9776 - loss: 0.3290\n",
      "Epoch 38/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9795 - loss: 0.3433\n",
      "Epoch 39/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9828 - loss: 0.3088\n",
      "Epoch 40/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9827 - loss: 0.3090\n",
      "Epoch 41/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9825 - loss: 0.3015\n",
      "Epoch 42/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9850 - loss: 0.3002\n",
      "Epoch 43/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9820 - loss: 0.3128\n",
      "Epoch 44/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9847 - loss: 0.2881\n",
      "Epoch 45/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9832 - loss: 0.2945\n",
      "Epoch 46/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9790 - loss: 0.2924\n",
      "Epoch 47/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9777 - loss: 0.2809\n",
      "Epoch 48/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9795 - loss: 0.2896\n",
      "Epoch 49/100\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9809 - loss: 0.2836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "train_x, train_y = shuffle(train_x, train_y, random_state=42)\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train and save the final model\n",
    "model.fit(train_x, train_y, epochs=100, batch_size=8, callbacks=[tensorboard_callback, early_stopping_callback], verbose=1)\n",
    "model.save('final_model_trained_on_full_data.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save\n",
    "try:\n",
    "    with open(\"training_data.json\", \"w\") as file:\n",
    "        # Convert non-serializable data like NumPy arrays or other objects to lists\n",
    "        data = {'words': words, 'classes': classes, 'train_x': train_x.tolist(), 'train_y': train_y.tolist()}\n",
    "        json.dump(data, file)\n",
    "except IOError as e:\n",
    "    print(f\"Error saving training data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "try:\n",
    "    with open(\"training_data\", \"wb\") as file:\n",
    "        pickle.dump({'words': words, 'classes': classes, 'train_x': train_x, 'train_y': train_y}, file)\n",
    "except IOError as e:\n",
    "    print(f\"Error saving training data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DrOW8S1Y0un5",
    "outputId": "eae11a39-7021-45a3-d529-8717486e4090"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Load\n",
    "try:\n",
    "    with open(\"training_data\", \"rb\") as file:\n",
    "        data = pickle.load(file)\n",
    "\n",
    "    words = data['words']\n",
    "    classes = data['classes']\n",
    "    train_x = np.array(data['train_x'])\n",
    "    train_y = np.array(data['train_y'])\n",
    "except IOError as e:\n",
    "    print(f\"Error loading training data: {e}\")\n",
    "\n",
    "# Load model\n",
    "try:\n",
    "    model = keras.models.load_model('final_model_trained_on_full_data.h5')\n",
    "except IOError as e:\n",
    "    print(f\"Error loading model: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "XVD-P16Q19Ar"
   },
   "outputs": [],
   "source": [
    "def clean_up_sentence(sentence):\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    sentence_words = [stemmer.stem(word.lower()) for word in sentence_words]\n",
    "    return sentence_words\n",
    "\n",
    "def bow(sentence, words, show_details=False):\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    bag = np.zeros(len(words), dtype=np.float32)\n",
    "    for idx, w in enumerate(words):\n",
    "        if w in sentence_words:\n",
    "            bag[idx] = 1\n",
    "            if show_details:\n",
    "                print(f\"Found in bag: {w}\")\n",
    "    return bag\n",
    "\n",
    "ERROR_THRESHOLD = 0.40\n",
    "\n",
    "\n",
    "\n",
    "def classify(sentence):\n",
    "    input_data = bow(sentence, words)\n",
    "    results = model.predict(np.array([input_data]))[0]\n",
    "    results = [[i, r] for i, r in enumerate(results) if r >= ERROR_THRESHOLD]\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return [(classes[r[0]], r[1]) for r in results]\n",
    "\n",
    "def response(sentence, userID='123', show_details=False):\n",
    "    results = classify(sentence)\n",
    "    if results:\n",
    "        for intent in intents:\n",
    "            if intent['tag'] == results[0][0]:\n",
    "                return random.choice(intent['responses'])\n",
    "    return \"Maaf, saya belum mengerti apa yang Anda bicarakan, perlu bantuan?.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FO4ujct85h_h",
    "outputId": "a2cddf3f-f8f6-46fa-f780-79074e416a53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 to close\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " halo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Selamat sore! Semoga hari Anda menyenangkan, apa yang bisa saya bantu?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " apa kabar\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Saya baik-baik saja, terima kasih telah bertanya!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " apa kabar?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Saya baik-baik saja, terima kasih telah bertanya!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " bagaimana cara mangatasi rasa cemas?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Gangguan kecemasan adalah kondisi di mana seseorang merasa cemas atau khawatir secara berlebihan, yang memengaruhi aktivitas sehari-hari mereka.\n"
     ]
    }
   ],
   "source": [
    "print(\"0 to close\")\n",
    "while True:\n",
    "    message = input(\"\")\n",
    "    if message == \"0\":\n",
    "        break\n",
    "    result = response(message)\n",
    "\n",
    "    if result is not None and \"~\" in result:\n",
    "        order = (result[1:])\n",
    "        action(order)\n",
    "    else:\n",
    "        print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xRRvDLhl0kI_",
    "outputId": "180f72b1-0bec-45f4-eb82-9b704c1713d2"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('final_model_trained_on_full_data.h5')\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "\n",
    "with open('model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
