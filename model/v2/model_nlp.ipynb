{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OFDSdvxj6ApJ",
    "outputId": "8d7e03b8-3c29-4e9e-f4a0-dd1b619499a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PySastrawi in c:\\users\\dzikr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install PySastrawi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sgol4Y_Y6ApP",
    "outputId": "bd880933-4700-4196-d8e7-bf0eeea86d4f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dzikr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "nMmyJPc5v2s8"
   },
   "outputs": [],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import pickle\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import nltk\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras import layers, models, callbacks, optimizers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "AyCMTd3BxH5v"
   },
   "outputs": [],
   "source": [
    "# Load the intents file\n",
    "with open('nlp_dataset_faq.json') as data_file:\n",
    "    intents = json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LzYlZchPxkrj",
    "outputId": "a02e3f10-25e2-49bd-99e0-2e6b517310d9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\dzikr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download the 'punkt_tab' data package\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Pre-processing\n",
    "words = []\n",
    "classes = []\n",
    "documents = []\n",
    "ignore = ['','!', '\"', \"'\", '(', ')', ',', '-', '.', ':', ';','[', ']', '_','?','.'\n",
    "          'adalah', 'akan', 'aku', 'anda', 'atau', 'dalam', 'dan',\n",
    "          'dari', 'dengan', 'di', 'dia', 'harus', 'ini', 'itu', 'jika', 'kami', 'kamu', 'ke',\n",
    "          'kita', 'mereka', 'oleh', 'pada', 'saya', 'sebuah', 'sedang', 'sementara', 'tanpa',\n",
    "          'tapi', 'telah', 'untuk', 'yang', '{', '}', 'merasa']\n",
    "\n",
    "\n",
    "\n",
    "#tokenize\n",
    "for intent in intents:\n",
    "    for pattern in intent['patterns']:\n",
    "        w = nltk.word_tokenize(pattern.lower())  # Tokenizing\n",
    "        words.extend([word for word in w if word not in ignore])  #Ignore\n",
    "        documents.append((w, intent['tag']))\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3OjNRWsryAlH",
    "outputId": "ad6913c3-fa46-4cf9-c12c-29f3ab63c088"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2052 documents\n",
      "102 classes ['agama_kepercayaan_bot', 'apa_itu_gangguan_mental', 'badmood_dampak', 'badmood_efek_jangka_panjang', 'badmood_gejala', 'badmood_pengobatan', 'badmood_penyebab', 'badmood_preventif', 'badmood_solusi_pribadi', 'badmood_terhadap_kesehatan_fisik', 'badmood_terhadap_pekerjaan', 'baru_punya_pacar', 'bertengkar', 'bot_atau_orang_asli', 'bunuh_diri', 'cara_mengatasi_benci', 'cara_mengatasi_bingung', 'cara_mengatasi_cemas', 'cara_mengatasi_cemburu', 'cara_mengatasi_dendam', 'cara_mengatasi_diremehkan', 'cara_mengatasi_frustasi', 'cara_mengatasi_gangguan_mental', 'cara_mengatasi_hampa', 'cara_mengatasi_iri', 'cara_mengatasi_kecewa', 'cara_mengatasi_kesal', 'cara_mengatasi_malu', 'cara_mengatasi_marah', 'cara_mengatasi_merasa_sendiri', 'cara_mengatasi_overthinking', 'cara_mengatasi_rasa_bersalah', 'cara_mengatasi_sedih', 'cara_mengatasi_takut', 'cara_mengatasi_takut_gagal', 'cara_mengatasi_tidak_dihargai', 'cara_positive_thinking', 'diagnosis_gangguan_mental', 'dukungan_mental_terapi', 'efek_gangguan_mental', 'emosi_bingung', 'emosi_frustrasi', 'emosi_hampa', 'emosi_kecewa', 'emosi_lelah', 'emosi_marah', 'emosi_sedih', 'emosi_senang', 'emosi_takut', 'emosi_takut_gagal', 'emosi_terbebani', 'emosi_tertekan', 'emosi_tidak_dihargai', 'gangguan_mental_dan_bipolar', 'gangguan_mental_dan_depresi', 'gangguan_mental_dan_kecemasan', 'gangguan_mental_dan_psikoedukasi', 'gangguan_mental_dan_psikoterapi', 'gangguan_mental_dan_stigma', 'gangguan_mental_untuk_anak', 'gejala_gangguan_mental', 'interaksi_positif_dengan_orang_tua', 'interaksi_positif_pertemanan', 'jalan_dengan_pacar', 'kabar_baik', 'kabar_buruk', 'kabar_netral', 'kata_mati', 'kata_mati_tidak_serius', 'kehilangan_ketertarikan_hidup', 'kehilangan_semangat', 'kesulitan_tidur', 'masalah_dengan_orang_tua', 'masalah_pertemanan', 'masalah_tempat_kerja', 'membanggakan_orangtua', 'mendapat_nilai_jelek', 'mood_bahagia', 'mood_cemas', 'mood_marahan', 'mood_membaik', 'mood_motivation', 'mood_sedih', 'mood_stress_relief', 'patah_hati', 'penanganan_gangguan_mental', 'pencegahan_gangguan_mental', 'pengobatan_gangguan_mental', 'penyebab_gangguan_mental', 'perbedaan_gangguan_mental_dan_stres', 'perkenalan_diri', 'perpisahan', 'putus_pacar', 'salam_halo', 'salam_hi_tes', 'salam_terima_kasih', 'sapaan_pagi', 'sapaan_tanya_kabar', 'stres_tugas', 'tanya_bantuan_terdekat', 'tidak_ingin_dilahirkan', 'ucapan_terima_kasih']\n",
      "647 unique stemmed words ['abai', 'ada', 'adalah', 'adil', 'aduh', 'agama', 'agar', 'ahli', 'aja', 'ajar', 'akhir', 'akibat', 'aktif', 'aktivitas', 'aku', 'alam', 'alami', 'alas', 'alih', 'alkohol', 'aman', 'amarah', 'amarahku', 'ambil', 'anak', 'anggap', 'antara', 'antidepresan', 'anut', 'apa', 'apakah', 'arah', 'arti', 'asa', 'asal', 'asli', 'asmara', 'atas', 'atur', 'awal', 'awat', 'bad', 'badan', 'bagai', 'bagaimana', 'bagi', 'bagus', 'bahagia', 'bahaya', 'bahkan', 'bahwa', 'baik', 'balas', 'balik', 'banding', 'banget', 'bangga', 'bangkit', 'bangun', 'bantu', 'banyak', 'baru', 'beban', 'beda', 'begini', 'begitu', 'belakang', 'belum', 'benar', 'benci', 'beneran', 'berani', 'berapa', 'berat', 'beri', 'besar', 'biar', 'biasa', 'bicara', 'bingung', 'bipolar', 'bisa', 'boleh', 'bos', 'bosan', 'bot', 'buat', 'bugar', 'bukan', 'bukti', 'bunuh', 'burnout', 'buruk', 'butuh', 'cakap', 'capai', 'capek', 'cara', 'cari', 'cegah', 'cemas', 'cemburu', 'cepat', 'cerah', 'cerita', 'cerna', 'chat', 'chatbot', 'cinta', 'ciri', 'coba', 'cocok', 'cuaca', 'cukup', 'dadah', 'damai', 'dampak', 'dapat', 'darah', 'daripada', 'datang', 'datar', 'daya', 'deadline', 'debat', 'definisi', 'deh', 'dekat', 'dendam', 'dengan', 'dengar', 'depan', 'depresi', 'derita', 'deteksi', 'dewasa', 'diagnosis', 'diet', 'diri', 'dokter', 'dong', 'down', 'drama', 'dukung', 'dunia', 'edukasi', 'efek', 'efektif', 'ekonomi', 'ekspektasi', 'elektrokonvulsif', 'emosi', 'emosional', 'enak', 'energi', 'energik', 'episode', 'erti', 'faktor', 'favorit', 'film', 'fisik', 'fokus', 'frustasi', 'frustrasi', 'fungsi', 'gagal', 'ganggu', 'gara-gara', 'gaya', 'gejala', 'gelap', 'gelisah', 'gembira', 'genetik', 'genetika', 'gin', 'guna', 'habis', 'hadap', 'hadeh', 'hadiah', 'hai', 'hal', 'halang', 'hallo', 'halo', 'hambat', 'hampa', 'hancur', 'hantu', 'hanya', 'harap', 'harga', 'hari', 'harus', 'hasil', 'hati', 'hebat', 'hendak', 'henti', 'hi', 'hidup', 'hilang', 'hindar', 'hormat', 'hormon', 'hubung', 'identifikasi', 'ikut', 'impi', 'implementasi', 'imun', 'indah', 'indikator', 'individu', 'ingin', 'insomnia', 'inspirasi', 'instruksi', 'intens', 'internal', 'intervensi', 'iri', 'isi', 'isolasi', 'istimewa', 'istirahat', 'jadi', 'jaga', 'jalan', 'jalin', 'jangka', 'jawab', 'jebak', 'jelas', 'jelek', 'jenak', 'jengkel', 'jenis', 'jepit', 'jernih', 'juga', 'jumpa', 'jurnal', 'kabar', 'kacau', 'kadang', 'kait', 'kalau', 'kali', 'kan', 'kantor', 'karena', 'kasih', 'kata', 'kategori', 'kayak', 'kebal', 'kecewa', 'kecil', 'kejut', 'keliling', 'kelola', 'kelompok', 'keluar', 'keluarga', 'kemarin', 'kembali', 'kembang', 'ken', 'kena', 'kenal', 'kenang', 'kenapa', 'kencan', 'kendali', 'kepada', 'kepala', 'keras', 'kerja', 'kerjasamanya', 'kesal', 'ketika', 'kewalahan', 'khawatir', 'khianat', 'khusus', 'kognitif', 'kolega', 'komentar', 'komunikasi', 'kondisi', 'konflik', 'konselor', 'kontrol', 'kosong', 'kronis', 'kualitas', 'kuasa', 'kuat', 'kunjung', 'kurang', 'lagi', 'lahir', 'lain', 'laku', 'lalu', 'lama', 'lancar', 'lang', 'langkah', 'langsung', 'lanjut', 'lari', 'lawan', 'layan', 'layar', 'lebih', 'ledak', 'lelah', 'lemah', 'lengkap', 'lenyap', 'lepas', 'lesu', 'lewat', 'libat', 'lihat', 'lingkung', 'luap', 'luar', 'luka', 'lumpuh', 'lupa', 'maaf', 'maju', 'makan', 'makasih', 'makin', 'makna', 'maksud', 'malam', 'malas', 'malu', 'mampu', 'mana', 'mandiri', 'manfaat', 'mania', 'manusia', 'marah', 'masa', 'masalah', 'masuk', 'masyarakat', 'mati', 'mau', 'medis', 'meditasi', 'menang', 'mengapa', 'menghadang', 'mental', 'mesin', 'meski', 'metabolisme', 'metode', 'mikrofon', 'milik', 'minat', 'minta', 'moga', 'momen', 'mood', 'moodku', 'moral', 'motivasi', 'mudah', 'mula', 'mulai', 'muncul', 'mungkin', 'murung', 'musik', 'nali', 'nama', 'nan', 'napas', 'negatif', 'netral', 'nggak', 'nih', 'nikmat', 'nilai', 'nomor', 'normal', 'nyaman', 'nyata', 'nyenyak', 'obat', 'olah', 'olahraga', 'optimis', 'orang', 'overthinking', 'pacar', 'pada', 'pagi', 'paham', 'paling', 'pandang', 'panggil', 'panjang', 'parah', 'pasang', 'pasti', 'patah', 'peduli', 'pengaruh', 'penting', 'penuh', 'peran', 'perangkap', 'percaya', 'performa', 'pergi', 'perhati', 'periksa', 'perilaku', 'peristiwa', 'perlu', 'pernah', 'pertama', 'pesimis', 'picu', 'pikir', 'pikul', 'pilih', 'pisah', 'pola', 'politik', 'posisi', 'positif', 'prestasi', 'preventif', 'pribadi', 'produktif', 'produktivitas', 'profesional', 'proses', 'protektif', 'psikoedukasi', 'psikologi', 'psikologis', 'psikoterapi', 'psikoterapis', 'puas', 'pulang', 'pulih', 'pun', 'pundak', 'punya', 'puruk', 'putus', 'ragu', 'raih', 'raportku', 'rasa', 'reda', 'rekan', 'rekomendasi', 'relaksasi', 'remaja', 'remeh', 'rencana', 'rendah', 'renggang', 'rentan', 'resmi', 'restoran', 'rileks', 'risiko', 'robot', 'romantis', 'rumah', 'rumit', 'runtuh', 'rusak', 'saat', 'sabar', 'sadar', 'saja', 'saking', 'sakit', 'salah', 'sama', 'sampai', 'sana', 'sangat', 'santai', 'saran', 'satu', 'sayang', 'sebab', 'sebut', 'sedia', 'sedih', 'sedikit', 'segala', 'segar', 'segera', 'sehat', 'sejati', 'sekali', 'sekaligus', 'sekarang', 'sekitar', 'selain', 'selalu', 'selamat', 'selesai', 'semangat', 'sembuh', 'sempurna', 'semua', 'senang', 'sendiri', 'senyum', 'seperti', 'sepi', 'serah', 'sering', 'serta', 'sesal', 'sesat', 'sesi', 'sesuai', 'sesuatu', 'sia', 'siap', 'siapa', 'sibuk', 'sih', 'sikap', 'simpan', 'singgung', 'singkat', 'sini', 'sisa', 'sisi', 'sistem', 'situasi', 'solusi', 'sosial', 'spesial', 'stabil', 'stigma', 'stres', 'stresful', 'suara', 'suasana', 'sudah', 'suka', 'sukses', 'sulit', 'sumber', 'supaya', 'susah', 'syukur', 'tadi', 'tahan', 'tahu', 'tak', 'takut', 'taman', 'tanda', 'tangan', 'tanggung', 'tangis', 'tanya', 'target', 'tari', 'tarik', 'tegang', 'tekan', 'teknik', 'telah', 'telepon', 'teman', 'tempat', 'temu', 'tenang', 'tengah', 'tenggelam', 'tengkar', 'tentang', 'tentu', 'tepat', 'terap', 'terapi', 'terima', 'terlalu', 'terus', 'tes', 'tetap', 'tetapi', 'tiap', 'tiba', 'tidak', 'tidur', 'tinggal', 'tinggi', 'tingkat', 'tips', 'tolong', 'tonjol', 'tonton', 'trauma', 'tua', 'tubuh', 'tugas', 'tuhan', 'tuju', 'tumpuk', 'tunjuk', 'tuntut', 'turun', 'turut', 'uang', 'ubah', 'uji', 'ujung', 'umum', 'untuk', 'untung', 'usaha', 'utama', 'waktu', 'waris', 'warna', 'was-was', 'waspada', 'wujud', 'ya', 'yakin', 'yoga']\n"
     ]
    }
   ],
   "source": [
    "# Melakukan stemming dan normalisasi data\n",
    "words = [stemmer.stem(w.lower()) for w in words if w not in ignore]\n",
    "words = sorted(list(set(words)))\n",
    "\n",
    "# Menghapus class duplikat dengan 'set'\n",
    "classes = sorted(list(set(classes)))\n",
    "\n",
    "print(len(documents), \"documents\")\n",
    "print(len(classes), \"classes\", classes)\n",
    "print(len(words), \"unique stemmed words\", words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "o3bG67i3yL2q"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "training = []\n",
    "output_empty = [0] * len(classes)\n",
    "\n",
    "for doc in documents:\n",
    "    pattern_words = [stemmer.stem(word.lower()) for word in doc[0]]\n",
    "    bag = [1 if w in pattern_words else 0 for w in words]\n",
    "\n",
    "    output_row = output_empty[:]\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "\n",
    "    training.append([bag, output_row])\n",
    "\n",
    "random.shuffle(training)\n",
    "training = np.array(training, dtype=object)\n",
    "\n",
    "train_x = np.array([item[0] for item in training])\n",
    "train_y = np.array([item[1] for item in training])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "        layers.Input(shape=(len(train_x[0]),), name='input_layer'),\n",
    "        layers.Dense(256, activation='relu', kernel_regularizer='l2', name='hidden_layer1'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3, name='dropout1'),\n",
    "        layers.Dense(128, activation='relu', kernel_regularizer='l2', name='hidden_layer2'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3, name='dropout2'),\n",
    "        layers.Dense(len(train_y[0]), activation='softmax', name='output_layer')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ hidden_layer1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">165,888</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ hidden_layer2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">102</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">13,158</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ hidden_layer1 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m165,888\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout1 (\u001b[38;5;33mDropout\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ hidden_layer2 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout2 (\u001b[38;5;33mDropout\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m102\u001b[0m)                 │          \u001b[38;5;34m13,158\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">213,478</span> (833.90 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m213,478\u001b[0m (833.90 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">212,710</span> (830.90 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m212,710\u001b[0m (830.90 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K_FOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2j75XSbGyalB",
    "outputId": "bbad24ff-51fd-4440-d144-bfe4011cf099"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dzikr\\AppData\\Local\\Temp\\ipykernel_16408\\1385879448.py:1: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "\n",
      "=== Training Fold 1/6 ===\n",
      "Epoch 1/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.0184 - loss: 10.2664 - val_accuracy: 0.0175 - val_loss: 8.8531\n",
      "Epoch 2/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.0260 - loss: 8.8811 - val_accuracy: 0.0468 - val_loss: 8.1705\n",
      "Epoch 3/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.0647 - loss: 8.1031 - val_accuracy: 0.1287 - val_loss: 7.5124\n",
      "Epoch 4/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1065 - loss: 7.5518 - val_accuracy: 0.1901 - val_loss: 7.0419\n",
      "Epoch 5/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1474 - loss: 7.1141 - val_accuracy: 0.2281 - val_loss: 6.6656\n",
      "Epoch 6/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.2103 - loss: 6.7188 - val_accuracy: 0.2807 - val_loss: 6.3375\n",
      "Epoch 7/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.2590 - loss: 6.3823 - val_accuracy: 0.3480 - val_loss: 6.0260\n",
      "Epoch 8/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3127 - loss: 6.0737 - val_accuracy: 0.3947 - val_loss: 5.7593\n",
      "Epoch 9/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3549 - loss: 5.7788 - val_accuracy: 0.4561 - val_loss: 5.5014\n",
      "Epoch 10/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4351 - loss: 5.4981 - val_accuracy: 0.5146 - val_loss: 5.2664\n",
      "Epoch 11/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4714 - loss: 5.2554 - val_accuracy: 0.5614 - val_loss: 5.0508\n",
      "Epoch 12/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5083 - loss: 4.9801 - val_accuracy: 0.5848 - val_loss: 4.8352\n",
      "Epoch 13/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5849 - loss: 4.7249 - val_accuracy: 0.6023 - val_loss: 4.6390\n",
      "Epoch 14/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5964 - loss: 4.5676 - val_accuracy: 0.6228 - val_loss: 4.4476\n",
      "Epoch 15/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6390 - loss: 4.3543 - val_accuracy: 0.6345 - val_loss: 4.2742\n",
      "Epoch 16/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6564 - loss: 4.2075 - val_accuracy: 0.6404 - val_loss: 4.1151\n",
      "Epoch 17/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7083 - loss: 3.9648 - val_accuracy: 0.6579 - val_loss: 3.9620\n",
      "Epoch 18/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7065 - loss: 3.8041 - val_accuracy: 0.6813 - val_loss: 3.8156\n",
      "Epoch 19/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7713 - loss: 3.6219 - val_accuracy: 0.6842 - val_loss: 3.6834\n",
      "Epoch 20/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7823 - loss: 3.4700 - val_accuracy: 0.6930 - val_loss: 3.5641\n",
      "Epoch 21/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7659 - loss: 3.3779 - val_accuracy: 0.7105 - val_loss: 3.4452\n",
      "Epoch 22/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7778 - loss: 3.2661 - val_accuracy: 0.7105 - val_loss: 3.3368\n",
      "Epoch 23/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8080 - loss: 3.0800 - val_accuracy: 0.7251 - val_loss: 3.2382\n",
      "Epoch 24/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8026 - loss: 2.9679 - val_accuracy: 0.7251 - val_loss: 3.1588\n",
      "Epoch 25/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8564 - loss: 2.7970 - val_accuracy: 0.7281 - val_loss: 3.0747\n",
      "Epoch 26/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8597 - loss: 2.7477 - val_accuracy: 0.7281 - val_loss: 2.9854\n",
      "Epoch 27/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8428 - loss: 2.6605 - val_accuracy: 0.7398 - val_loss: 2.9103\n",
      "Epoch 28/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8606 - loss: 2.5468 - val_accuracy: 0.7310 - val_loss: 2.8358\n",
      "Epoch 29/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8716 - loss: 2.4587 - val_accuracy: 0.7339 - val_loss: 2.7702\n",
      "Epoch 30/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8802 - loss: 2.3431 - val_accuracy: 0.7310 - val_loss: 2.6927\n",
      "Epoch 31/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8791 - loss: 2.3093 - val_accuracy: 0.7427 - val_loss: 2.6358\n",
      "Epoch 32/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9022 - loss: 2.1752 - val_accuracy: 0.7456 - val_loss: 2.5728\n",
      "Epoch 33/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9062 - loss: 2.1065 - val_accuracy: 0.7515 - val_loss: 2.5208\n",
      "Epoch 34/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9134 - loss: 2.0177 - val_accuracy: 0.7515 - val_loss: 2.4637\n",
      "Epoch 35/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9186 - loss: 1.9457 - val_accuracy: 0.7456 - val_loss: 2.4164\n",
      "Epoch 36/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9140 - loss: 1.8695 - val_accuracy: 0.7515 - val_loss: 2.3566\n",
      "Epoch 37/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9098 - loss: 1.8356 - val_accuracy: 0.7456 - val_loss: 2.3176\n",
      "Epoch 38/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9164 - loss: 1.7738 - val_accuracy: 0.7485 - val_loss: 2.2577\n",
      "Epoch 39/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9313 - loss: 1.7110 - val_accuracy: 0.7456 - val_loss: 2.2165\n",
      "Epoch 40/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9293 - loss: 1.6597 - val_accuracy: 0.7544 - val_loss: 2.1762\n",
      "Epoch 41/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9283 - loss: 1.5830 - val_accuracy: 0.7456 - val_loss: 2.1404\n",
      "Epoch 42/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9482 - loss: 1.5262 - val_accuracy: 0.7515 - val_loss: 2.1055\n",
      "Epoch 43/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9435 - loss: 1.4667 - val_accuracy: 0.7602 - val_loss: 2.0780\n",
      "Epoch 44/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9348 - loss: 1.4393 - val_accuracy: 0.7573 - val_loss: 2.0315\n",
      "Epoch 45/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9415 - loss: 1.4014 - val_accuracy: 0.7544 - val_loss: 1.9954\n",
      "Epoch 46/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9575 - loss: 1.3316 - val_accuracy: 0.7602 - val_loss: 1.9665\n",
      "Epoch 47/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9550 - loss: 1.3103 - val_accuracy: 0.7602 - val_loss: 1.9390\n",
      "Epoch 48/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9584 - loss: 1.2479 - val_accuracy: 0.7602 - val_loss: 1.9079\n",
      "Epoch 49/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9609 - loss: 1.2071 - val_accuracy: 0.7632 - val_loss: 1.8794\n",
      "Epoch 50/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9596 - loss: 1.1646 - val_accuracy: 0.7602 - val_loss: 1.8587\n",
      "Epoch 51/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9565 - loss: 1.1533 - val_accuracy: 0.7661 - val_loss: 1.8383\n",
      "Epoch 52/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9529 - loss: 1.1148 - val_accuracy: 0.7661 - val_loss: 1.8063\n",
      "Epoch 53/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9642 - loss: 1.0542 - val_accuracy: 0.7632 - val_loss: 1.7840\n",
      "Epoch 54/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9565 - loss: 1.0458 - val_accuracy: 0.7602 - val_loss: 1.7527\n",
      "Epoch 55/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9602 - loss: 1.0102 - val_accuracy: 0.7690 - val_loss: 1.7441\n",
      "Epoch 56/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9742 - loss: 0.9526 - val_accuracy: 0.7690 - val_loss: 1.7138\n",
      "Epoch 57/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9709 - loss: 0.9311 - val_accuracy: 0.7661 - val_loss: 1.7177\n",
      "Epoch 58/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9655 - loss: 0.9145 - val_accuracy: 0.7573 - val_loss: 1.6916\n",
      "Epoch 59/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9673 - loss: 0.8878 - val_accuracy: 0.7602 - val_loss: 1.6836\n",
      "Epoch 60/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9736 - loss: 0.8540 - val_accuracy: 0.7573 - val_loss: 1.6547\n",
      "Epoch 61/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.8272 - val_accuracy: 0.7544 - val_loss: 1.6470\n",
      "Epoch 62/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9630 - loss: 0.8095 - val_accuracy: 0.7602 - val_loss: 1.6196\n",
      "Epoch 63/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9720 - loss: 0.7886 - val_accuracy: 0.7544 - val_loss: 1.6139\n",
      "Epoch 64/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9737 - loss: 0.7570 - val_accuracy: 0.7544 - val_loss: 1.6107\n",
      "Epoch 65/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9784 - loss: 0.7378 - val_accuracy: 0.7515 - val_loss: 1.5820\n",
      "Epoch 66/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9746 - loss: 0.7047 - val_accuracy: 0.7719 - val_loss: 1.5709\n",
      "Epoch 67/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9684 - loss: 0.7036 - val_accuracy: 0.7544 - val_loss: 1.5517\n",
      "Epoch 68/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9734 - loss: 0.6735 - val_accuracy: 0.7632 - val_loss: 1.5309\n",
      "Epoch 69/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9784 - loss: 0.6451 - val_accuracy: 0.7544 - val_loss: 1.5251\n",
      "Epoch 70/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9751 - loss: 0.6307 - val_accuracy: 0.7632 - val_loss: 1.4911\n",
      "Epoch 71/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9796 - loss: 0.6080 - val_accuracy: 0.7632 - val_loss: 1.5153\n",
      "Epoch 72/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9695 - loss: 0.6214 - val_accuracy: 0.7602 - val_loss: 1.5496\n",
      "Epoch 73/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9775 - loss: 0.5813 - val_accuracy: 0.7690 - val_loss: 1.4993\n",
      "Epoch 74/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9809 - loss: 0.5730 - val_accuracy: 0.7456 - val_loss: 1.5058\n",
      "Epoch 75/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9820 - loss: 0.5394 - val_accuracy: 0.7573 - val_loss: 1.4802\n",
      "Epoch 76/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9850 - loss: 0.5230 - val_accuracy: 0.7632 - val_loss: 1.4407\n",
      "Epoch 77/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9715 - loss: 0.5394 - val_accuracy: 0.7632 - val_loss: 1.4214\n",
      "Epoch 78/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9782 - loss: 0.5133 - val_accuracy: 0.7690 - val_loss: 1.4418\n",
      "Epoch 79/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9848 - loss: 0.4880 - val_accuracy: 0.7719 - val_loss: 1.4072\n",
      "Epoch 80/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9785 - loss: 0.4848 - val_accuracy: 0.7573 - val_loss: 1.4564\n",
      "Epoch 81/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9802 - loss: 0.4814 - val_accuracy: 0.7632 - val_loss: 1.4450\n",
      "Epoch 82/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9675 - loss: 0.4834 - val_accuracy: 0.7515 - val_loss: 1.4508\n",
      "Epoch 83/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9753 - loss: 0.4817 - val_accuracy: 0.7515 - val_loss: 1.4308\n",
      "Epoch 84/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9682 - loss: 0.4682 - val_accuracy: 0.7632 - val_loss: 1.4159\n",
      "Epoch 85/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9794 - loss: 0.4558 - val_accuracy: 0.7515 - val_loss: 1.4661\n",
      "Epoch 86/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9849 - loss: 0.4191 - val_accuracy: 0.7544 - val_loss: 1.4271\n",
      "Epoch 87/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9872 - loss: 0.4073 - val_accuracy: 0.7573 - val_loss: 1.4601\n",
      "Epoch 88/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9846 - loss: 0.4068 - val_accuracy: 0.7632 - val_loss: 1.4242\n",
      "Epoch 89/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9794 - loss: 0.3954 - val_accuracy: 0.7632 - val_loss: 1.3981\n",
      "Epoch 90/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9818 - loss: 0.3958 - val_accuracy: 0.7719 - val_loss: 1.3708\n",
      "Epoch 91/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9798 - loss: 0.3993 - val_accuracy: 0.7719 - val_loss: 1.4098\n",
      "Epoch 92/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9755 - loss: 0.3947 - val_accuracy: 0.7632 - val_loss: 1.3844\n",
      "Epoch 93/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9829 - loss: 0.3785 - val_accuracy: 0.7661 - val_loss: 1.3608\n",
      "Epoch 94/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9826 - loss: 0.3548 - val_accuracy: 0.7690 - val_loss: 1.3487\n",
      "Epoch 95/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9846 - loss: 0.3541 - val_accuracy: 0.7602 - val_loss: 1.3907\n",
      "Epoch 96/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9870 - loss: 0.3452 - val_accuracy: 0.7515 - val_loss: 1.3630\n",
      "Epoch 97/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9811 - loss: 0.3455 - val_accuracy: 0.7602 - val_loss: 1.4052\n",
      "Epoch 98/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9727 - loss: 0.3460 - val_accuracy: 0.7602 - val_loss: 1.3960\n",
      "Epoch 99/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9830 - loss: 0.3269 - val_accuracy: 0.7719 - val_loss: 1.3742\n",
      "Epoch 100/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9825 - loss: 0.3347 - val_accuracy: 0.7865 - val_loss: 1.3723\n",
      "Fold 1 - Validation Accuracy: 0.7690\n",
      "\n",
      "=== Training Fold 2/6 ===\n",
      "Epoch 1/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9172 - loss: 0.6099 - val_accuracy: 0.9649 - val_loss: 0.3164\n",
      "Epoch 2/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9210 - loss: 0.5435 - val_accuracy: 0.9708 - val_loss: 0.3191\n",
      "Epoch 3/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9283 - loss: 0.4816 - val_accuracy: 0.9620 - val_loss: 0.3277\n",
      "Epoch 4/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9560 - loss: 0.4037 - val_accuracy: 0.9649 - val_loss: 0.3359\n",
      "Epoch 5/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9697 - loss: 0.3802 - val_accuracy: 0.9591 - val_loss: 0.3474\n",
      "Epoch 6/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9644 - loss: 0.3783 - val_accuracy: 0.9474 - val_loss: 0.3590\n",
      "Epoch 7/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9721 - loss: 0.3508 - val_accuracy: 0.9503 - val_loss: 0.3618\n",
      "Epoch 8/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9613 - loss: 0.3815 - val_accuracy: 0.9327 - val_loss: 0.3845\n",
      "Epoch 9/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9607 - loss: 0.3481 - val_accuracy: 0.9269 - val_loss: 0.4003\n",
      "Epoch 10/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9715 - loss: 0.3427 - val_accuracy: 0.9327 - val_loss: 0.4007\n",
      "Epoch 11/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9751 - loss: 0.3348 - val_accuracy: 0.9269 - val_loss: 0.4130\n",
      "Fold 2 - Validation Accuracy: 0.9649\n",
      "\n",
      "=== Training Fold 3/6 ===\n",
      "Epoch 1/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.8958 - loss: 0.6049 - val_accuracy: 0.9649 - val_loss: 0.3365\n",
      "Epoch 2/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9124 - loss: 0.5347 - val_accuracy: 0.9561 - val_loss: 0.3436\n",
      "Epoch 3/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9360 - loss: 0.4611 - val_accuracy: 0.9591 - val_loss: 0.3602\n",
      "Epoch 4/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9492 - loss: 0.4107 - val_accuracy: 0.9357 - val_loss: 0.4115\n",
      "Epoch 5/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9497 - loss: 0.4138 - val_accuracy: 0.9357 - val_loss: 0.4335\n",
      "Epoch 6/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9425 - loss: 0.3821 - val_accuracy: 0.9298 - val_loss: 0.4369\n",
      "Epoch 7/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9671 - loss: 0.3667 - val_accuracy: 0.9327 - val_loss: 0.4371\n",
      "Epoch 8/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9743 - loss: 0.3264 - val_accuracy: 0.9298 - val_loss: 0.4487\n",
      "Epoch 9/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9681 - loss: 0.3394 - val_accuracy: 0.9269 - val_loss: 0.4626\n",
      "Epoch 10/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9757 - loss: 0.3116 - val_accuracy: 0.9211 - val_loss: 0.4579\n",
      "Epoch 11/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9796 - loss: 0.3053 - val_accuracy: 0.9094 - val_loss: 0.4868\n",
      "Fold 3 - Validation Accuracy: 0.9649\n",
      "\n",
      "=== Training Fold 4/6 ===\n",
      "Epoch 1/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.8870 - loss: 0.6343 - val_accuracy: 0.9620 - val_loss: 0.3432\n",
      "Epoch 2/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9097 - loss: 0.5608 - val_accuracy: 0.9474 - val_loss: 0.3709\n",
      "Epoch 3/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9185 - loss: 0.4869 - val_accuracy: 0.9415 - val_loss: 0.3998\n",
      "Epoch 4/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9384 - loss: 0.4199 - val_accuracy: 0.9444 - val_loss: 0.4345\n",
      "Epoch 5/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9488 - loss: 0.4054 - val_accuracy: 0.9357 - val_loss: 0.4646\n",
      "Epoch 6/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9663 - loss: 0.3631 - val_accuracy: 0.9152 - val_loss: 0.4770\n",
      "Epoch 7/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9526 - loss: 0.3719 - val_accuracy: 0.9269 - val_loss: 0.4859\n",
      "Epoch 8/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9696 - loss: 0.3487 - val_accuracy: 0.9152 - val_loss: 0.5145\n",
      "Epoch 9/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9751 - loss: 0.3339 - val_accuracy: 0.9240 - val_loss: 0.5106\n",
      "Epoch 10/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9755 - loss: 0.3241 - val_accuracy: 0.9181 - val_loss: 0.5127\n",
      "Epoch 11/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9678 - loss: 0.3128 - val_accuracy: 0.9211 - val_loss: 0.5204\n",
      "Fold 4 - Validation Accuracy: 0.9620\n",
      "\n",
      "=== Training Fold 5/6 ===\n",
      "Epoch 1/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.8666 - loss: 0.6905 - val_accuracy: 0.9444 - val_loss: 0.3562\n",
      "Epoch 2/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8960 - loss: 0.5491 - val_accuracy: 0.9269 - val_loss: 0.3922\n",
      "Epoch 3/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9168 - loss: 0.4880 - val_accuracy: 0.9181 - val_loss: 0.4211\n",
      "Epoch 4/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9318 - loss: 0.4338 - val_accuracy: 0.9211 - val_loss: 0.4455\n",
      "Epoch 5/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9533 - loss: 0.3793 - val_accuracy: 0.9094 - val_loss: 0.4778\n",
      "Epoch 6/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9550 - loss: 0.3879 - val_accuracy: 0.9064 - val_loss: 0.5110\n",
      "Epoch 7/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9526 - loss: 0.3582 - val_accuracy: 0.8977 - val_loss: 0.5288\n",
      "Epoch 8/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9671 - loss: 0.3365 - val_accuracy: 0.8830 - val_loss: 0.5185\n",
      "Epoch 9/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9734 - loss: 0.3132 - val_accuracy: 0.8889 - val_loss: 0.5358\n",
      "Epoch 10/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9658 - loss: 0.3345 - val_accuracy: 0.8655 - val_loss: 0.5901\n",
      "Epoch 11/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9828 - loss: 0.2938 - val_accuracy: 0.8830 - val_loss: 0.5931\n",
      "Fold 5 - Validation Accuracy: 0.9444\n",
      "\n",
      "=== Training Fold 6/6 ===\n",
      "Epoch 1/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.8606 - loss: 0.6588 - val_accuracy: 0.9327 - val_loss: 0.3696\n",
      "Epoch 2/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8912 - loss: 0.5652 - val_accuracy: 0.9152 - val_loss: 0.4144\n",
      "Epoch 3/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9266 - loss: 0.4623 - val_accuracy: 0.9094 - val_loss: 0.4513\n",
      "Epoch 4/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9332 - loss: 0.4348 - val_accuracy: 0.9094 - val_loss: 0.4737\n",
      "Epoch 5/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9534 - loss: 0.3727 - val_accuracy: 0.9006 - val_loss: 0.4948\n",
      "Epoch 6/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9418 - loss: 0.4039 - val_accuracy: 0.8860 - val_loss: 0.5463\n",
      "Epoch 7/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9592 - loss: 0.3473 - val_accuracy: 0.8860 - val_loss: 0.5666\n",
      "Epoch 8/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9620 - loss: 0.3353 - val_accuracy: 0.8830 - val_loss: 0.5755\n",
      "Epoch 9/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9671 - loss: 0.3093 - val_accuracy: 0.8713 - val_loss: 0.5952\n",
      "Epoch 10/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9726 - loss: 0.2964 - val_accuracy: 0.8772 - val_loss: 0.6084\n",
      "Epoch 11/100\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9731 - loss: 0.2963 - val_accuracy: 0.8626 - val_loss: 0.6419\n",
      "Fold 6 - Validation Accuracy: 0.9327\n",
      "\n",
      "=== Average Validation Accuracy: 0.9230 ===\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "# Hyperparameters\n",
    "num_folds = 6\n",
    "batch_size = 8\n",
    "learning_rate = 1e-4\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "fold_accuracies = []\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(train_x)):\n",
    "    print(f\"\\n=== Training Fold {fold + 1}/{num_folds} ===\")\n",
    "    \n",
    "    X_train, X_val = train_x[train_index], train_x[val_index]\n",
    "    y_train, y_val = train_y[train_index], train_y[val_index]\n",
    "\n",
    "    tensorboard_callback = callbacks.TensorBoard(log_dir=f'./logs/fold_{fold+1}')\n",
    "    early_stopping_callback = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    \n",
    "    optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[tensorboard_callback, early_stopping_callback],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "    print(f\"Fold {fold + 1} - Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    fold_accuracies.append(val_accuracy)\n",
    "    \n",
    "avg_accuracy = np.mean(fold_accuracies)\n",
    "print(f\"\\n=== Average Validation Accuracy: {avg_accuracy:.4f} ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = callbacks.EarlyStopping(monitor='accuracy', patience=10, restore_best_weights=True)\n",
    "tensorboard_callback = callbacks.TensorBoard(log_dir='./logs/full_training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training tanpa split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8473 - loss: 0.6759\n",
      "Epoch 2/100\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8935 - loss: 0.5691\n",
      "Epoch 3/100\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9140 - loss: 0.4894\n",
      "Epoch 4/100\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9303 - loss: 0.4415\n",
      "Epoch 5/100\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9401 - loss: 0.4059\n",
      "Epoch 6/100\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9522 - loss: 0.3817\n",
      "Epoch 7/100\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9611 - loss: 0.3523\n",
      "Epoch 8/100\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9609 - loss: 0.3386\n",
      "Epoch 9/100\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9625 - loss: 0.3256\n",
      "Epoch 10/100\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9626 - loss: 0.3170\n",
      "Epoch 11/100\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9694 - loss: 0.3203\n",
      "Epoch 12/100\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9670 - loss: 0.3096\n",
      "Epoch 13/100\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9779 - loss: 0.2891\n",
      "Epoch 14/100\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9684 - loss: 0.3124\n",
      "Epoch 15/100\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9798 - loss: 0.2707\n",
      "Epoch 16/100\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9888 - loss: 0.2529\n",
      "Epoch 17/100\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9795 - loss: 0.2690\n",
      "Epoch 18/100\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9786 - loss: 0.2801\n",
      "Epoch 19/100\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9859 - loss: 0.2521\n",
      "Epoch 20/100\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9797 - loss: 0.2689\n",
      "Epoch 21/100\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9758 - loss: 0.2642\n",
      "Epoch 22/100\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9770 - loss: 0.2509\n",
      "Epoch 23/100\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9778 - loss: 0.2475\n",
      "Epoch 24/100\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9821 - loss: 0.2499\n",
      "Epoch 25/100\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9815 - loss: 0.2411\n",
      "Epoch 26/100\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9795 - loss: 0.2502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "train_x, train_y = shuffle(train_x, train_y, random_state=42)\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train and save the final model\n",
    "model.fit(train_x, train_y, epochs=100, batch_size=8, callbacks=[tensorboard_callback, early_stopping_callback], verbose=1)\n",
    "model.save('final_model_trained_on_full_data.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save\n",
    "try:\n",
    "    with open(\"training_data.json\", \"w\") as file:\n",
    "        # Convert non-serializable data like NumPy arrays or other objects to lists\n",
    "        data = {'words': words, 'classes': classes, 'train_x': train_x.tolist(), 'train_y': train_y.tolist()}\n",
    "        json.dump(data, file)\n",
    "except IOError as e:\n",
    "    print(f\"Error saving training data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "try:\n",
    "    with open(\"training_data\", \"wb\") as file:\n",
    "        pickle.dump({'words': words, 'classes': classes, 'train_x': train_x, 'train_y': train_y}, file)\n",
    "except IOError as e:\n",
    "    print(f\"Error saving training data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DrOW8S1Y0un5",
    "outputId": "eae11a39-7021-45a3-d529-8717486e4090"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Load\n",
    "try:\n",
    "    with open(\"training_data\", \"rb\") as file:\n",
    "        data = pickle.load(file)\n",
    "\n",
    "    words = data['words']\n",
    "    classes = data['classes']\n",
    "    train_x = np.array(data['train_x'])\n",
    "    train_y = np.array(data['train_y'])\n",
    "except IOError as e:\n",
    "    print(f\"Error loading training data: {e}\")\n",
    "\n",
    "# Load model\n",
    "try:\n",
    "    model = keras.models.load_model('final_model_trained_on_full_data.h5')\n",
    "except IOError as e:\n",
    "    print(f\"Error loading model: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "XVD-P16Q19Ar"
   },
   "outputs": [],
   "source": [
    "def clean_up_sentence(sentence):\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    sentence_words = [stemmer.stem(word.lower()) for word in sentence_words]\n",
    "    return sentence_words\n",
    "\n",
    "def bow(sentence, words, show_details=False):\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    bag = np.zeros(len(words), dtype=np.float32)\n",
    "    for idx, w in enumerate(words):\n",
    "        if w in sentence_words:\n",
    "            bag[idx] = 1\n",
    "            if show_details:\n",
    "                print(f\"Found in bag: {w}\")\n",
    "    return bag\n",
    "\n",
    "ERROR_THRESHOLD = 0.40\n",
    "\n",
    "\n",
    "\n",
    "def classify(sentence):\n",
    "    input_data = bow(sentence, words)\n",
    "    results = model.predict(np.array([input_data]))[0]\n",
    "    results = [[i, r] for i, r in enumerate(results) if r >= ERROR_THRESHOLD]\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return [(classes[r[0]], r[1]) for r in results]\n",
    "\n",
    "def response(sentence, userID='123', show_details=False):\n",
    "    results = classify(sentence)\n",
    "    if results:\n",
    "        for intent in intents:\n",
    "            if intent['tag'] == results[0][0]:\n",
    "                return random.choice(intent['responses'])\n",
    "    return \"Maaf, saya belum mengerti apa yang Anda bicarakan, perlu bantuan?.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FO4ujct85h_h",
    "outputId": "a2cddf3f-f8f6-46fa-f780-79074e416a53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 to close\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " saya mau mati saja\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Tolong jangan membuat keputusan tergesa-gesa. Kamu sangat berarti, dan aku ingin memastikan kamu mendapat dukungan yang tepat. Hubungi seseorang yang kamu percayai atau organisasi dukungan.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " saya lelah dengan capstone project dan Bangkit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Ketika merasa lelah, jangan ragu untuk berhenti sejenak dan mereset pikiranmu.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " saya merasa hampa\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Mencari dukungan sangat penting saat merasa seperti ini. Anda tidak perlu melalui ini sendirian.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " bagaimana cara mengatasi kehampaan?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Ingat bahwa rasa hampa adalah sementara, dan kamu bisa melewatinya.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 0\n"
     ]
    }
   ],
   "source": [
    "print(\"0 to close\")\n",
    "while True:\n",
    "    message = input(\"\")\n",
    "    if message == \"0\":\n",
    "        break\n",
    "    result = response(message)\n",
    "\n",
    "    if result is not None and \"~\" in result:\n",
    "        order = (result[1:])\n",
    "        action(order)\n",
    "    else:\n",
    "        print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xRRvDLhl0kI_",
    "outputId": "180f72b1-0bec-45f4-eb82-9b704c1713d2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\dzikr\\AppData\\Local\\Temp\\tmpupbxtobw\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\dzikr\\AppData\\Local\\Temp\\tmpupbxtobw\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\dzikr\\AppData\\Local\\Temp\\tmpupbxtobw'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 647), dtype=tf.float32, name='input_layer')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 102), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2497633115152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2497633112272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2497633115728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2497633112656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2497633114384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2497633116688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2497633116496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2497633117264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2497633113232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2497633116880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2497633115536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2497633118032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2497633117456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2497633120144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('final_model_trained_on_full_data.h5')\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "\n",
    "with open('model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
