{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OFDSdvxj6ApJ",
    "outputId": "8d7e03b8-3c29-4e9e-f4a0-dd1b619499a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PySastrawi in c:\\users\\dzikr\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install PySastrawi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sgol4Y_Y6ApP",
    "outputId": "bd880933-4700-4196-d8e7-bf0eeea86d4f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dzikr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "nMmyJPc5v2s8"
   },
   "outputs": [],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import pickle\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import nltk\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras import layers, models, callbacks, optimizers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "AyCMTd3BxH5v"
   },
   "outputs": [],
   "source": [
    "# Load the intents file\n",
    "with open('new.json') as data_file:\n",
    "    intents = json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LzYlZchPxkrj",
    "outputId": "a02e3f10-25e2-49bd-99e0-2e6b517310d9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\dzikr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download the 'punkt_tab' data package\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Pre-processing\n",
    "words = []\n",
    "classes = []\n",
    "documents = []\n",
    "ignore = ['!', '\"', \"'\", '(', ')', ',', '-', '.', ':', ';', '?', '[', ']', '_',\n",
    "          'adalah', 'akan', 'aku', 'anda', 'atau', 'dalam', 'dan',\n",
    "          'dari', 'dengan', 'di', 'dia', 'harus', 'ini', 'itu', 'jika', 'kami', 'kamu', 'ke',\n",
    "          'kita', 'mereka', 'oleh', 'pada', 'saya', 'sebuah', 'sedang', 'sementara', 'tanpa',\n",
    "          'tapi', 'telah', 'untuk', 'yang', '{', '}']\n",
    "\n",
    "\n",
    "\n",
    "#tokenize\n",
    "for intent in intents:\n",
    "    for pattern in intent['patterns']:\n",
    "        w = nltk.word_tokenize(pattern.lower())  # Tokenizing and converting to lowercase\n",
    "        words.extend([word for word in w if word not in ignore])  # Exclude words in ignore list\n",
    "        documents.append((w, intent['tag']))\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3OjNRWsryAlH",
    "outputId": "ad6913c3-fa46-4cf9-c12c-29f3ab63c088"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "965 documents\n",
      "47 classes ['apa_itu_gangguan_mental', 'badmood_dampak', 'badmood_efek_jangka_panjang', 'badmood_gejala', 'badmood_pengobatan', 'badmood_penyebab', 'badmood_preventif', 'badmood_solusi_pribadi', 'badmood_terhadap_kesehatan_fisik', 'badmood_terhadap_pekerjaan', 'bunuh_diri', 'cara_mengatasi_gangguan_mental', 'diagnosis_gangguan_mental', 'dukungan_mental_terapi', 'efek_gangguan_mental', 'gangguan_mental_dan_bipolar', 'gangguan_mental_dan_depresi', 'gangguan_mental_dan_kecemasan', 'gangguan_mental_dan_psikoedukasi', 'gangguan_mental_dan_psikoterapi', 'gangguan_mental_dan_stigma', 'gangguan_mental_untuk_anak', 'gejala_gangguan_mental', 'kabar_baik', 'kabar_buruk', 'kabar_netral', 'mood_bahagia', 'mood_cemas', 'mood_marahan', 'mood_membaik', 'mood_motivation', 'mood_sedih', 'mood_stress_relief', 'penanganan_gangguan_mental', 'pencegahan_gangguan_mental', 'pengobatan_gangguan_mental', 'penyebab_gangguan_mental', 'perbedaan_gangguan_mental_dan_stres', 'perkenalan_diri', 'perpisahan', 'salam_halo', 'salam_hi_tes', 'salam_terima_kasih', 'sapaan_pagi', 'sapaan_tanya_kabar', 'tanya_bantuan_terdekat', 'ucapan_terima_kasih']\n",
      "441 unique stemmed words ['ada', 'adil', 'agar', 'ahli', 'ajar', 'akhir', 'akibat', 'aktif', 'alami', 'alas', 'alkohol', 'aman', 'amarah', 'ambil', 'anak', 'antara', 'antidepresan', 'apa', 'apakah', 'arah', 'arti', 'asa', 'asal', 'asmara', 'atas', 'atur', 'awal', 'awat', 'bad', 'badan', 'bagai', 'bagaimana', 'bagi', 'bahagia', 'bahaya', 'bahwa', 'baik', 'balas', 'balik', 'banget', 'bantu', 'banyak', 'baru', 'beda', 'begitu', 'belum', 'benar', 'berapa', 'berat', 'beri', 'besar', 'biasa', 'bicara', 'bipolar', 'bisa', 'boleh', 'buat', 'bugar', 'bukan', 'buruk', 'butuh', 'capai', 'cara', 'cari', 'cegah', 'cemas', 'cepat', 'cerah', 'cerita', 'cerna', 'chat', 'chatbot', 'ciri', 'cuaca', 'cukup', 'dadah', 'damai', 'dampak', 'dapat', 'darah', 'datang', 'definisi', 'dekat', 'dengan', 'dengar', 'depan', 'depresi', 'derita', 'deteksi', 'dewasa', 'diagnosis', 'diet', 'diri', 'dokter', 'dong', 'down', 'dukung', 'dunia', 'edukasi', 'efek', 'efektif', 'ekonomi', 'elektrokonvulsif', 'emosi', 'emosional', 'enak', 'energi', 'energik', 'episode', 'erti', 'faktor', 'fisik', 'frustrasi', 'fungsi', 'ganggu', 'gaya', 'gejala', 'gelap', 'gelisah', 'gembira', 'genetik', 'genetika', 'guna', 'hadap', 'hai', 'hal', 'hallo', 'halo', 'hambat', 'hampa', 'hanya', 'harap', 'harga', 'hari', 'hasil', 'hati', 'hebat', 'henti', 'hi', 'hidup', 'hilang', 'hindar', 'hormon', 'hubung', 'identifikasi', 'ikut', 'implementasi', 'imun', 'indikator', 'individu', 'ingin', 'insomnia', 'inspirasi', 'intens', 'intervensi', 'isolasi', 'istimewa', 'jadi', 'jaga', 'jalan', 'jangka', 'jebak', 'jelas', 'jengkel', 'jenis', 'jepit', 'juga', 'jumpa', 'jurnal', 'kabar', 'kait', 'kalau', 'kantor', 'karena', 'kasih', 'kata', 'kategori', 'kebal', 'kecewa', 'kecil', 'kelola', 'kelompok', 'keluar', 'keluarga', 'kemarin', 'kembali', 'kembang', 'kena', 'kenal', 'kenapa', 'kendali', 'kepala', 'kerja', 'kerjasamanya', 'kesal', 'ketika', 'kewalahan', 'khawatir', 'khusus', 'kognitif', 'komunikasi', 'kondisi', 'konflik', 'konselor', 'kontrol', 'kosong', 'kronis', 'kualitas', 'kurang', 'lagi', 'lain', 'laku', 'lama', 'lancar', 'langkah', 'langsung', 'lanjut', 'lari', 'layan', 'layar', 'lebih', 'ledak', 'lelah', 'lengkap', 'lesu', 'libat', 'lihat', 'lingkung', 'luar', 'luka', 'makan', 'makasih', 'makin', 'maksud', 'malam', 'malas', 'mampu', 'mana', 'mandiri', 'manfaat', 'mania', 'marah', 'masa', 'masalah', 'masuk', 'masyarakat', 'mati', 'medis', 'meditasi', 'mengapa', 'mental', 'meski', 'metabolisme', 'metode', 'mikrofon', 'milik', 'moga', 'mood', 'moodku', 'moral', 'motivasi', 'mudah', 'muncul', 'murung', 'musik', 'nali', 'nama', 'nan', 'negatif', 'netral', 'nggak', 'nomor', 'normal', 'nyaman', 'obat', 'olah', 'olahraga', 'optimis', 'orang', 'pagi', 'paham', 'paling', 'panggil', 'panjang', 'parah', 'peduli', 'pengaruh', 'penting', 'penuh', 'peran', 'perhati', 'periksa', 'perilaku', 'peristiwa', 'perlu', 'pertama', 'picu', 'pikir', 'pilih', 'pola', 'positif', 'preventif', 'pribadi', 'produktif', 'produktivitas', 'profesional', 'proses', 'psikoedukasi', 'psikologi', 'psikologis', 'psikoterapi', 'psikoterapis', 'puas', 'pulih', 'pun', 'punya', 'puruk', 'putus', 'rasa', 'reda', 'rekan', 'rekomendasi', 'relaksasi', 'remaja', 'rencana', 'rentan', 'rileks', 'risiko', 'rumah', 'rusak', 'saat', 'sadar', 'saja', 'sakit', 'sama', 'sampai', 'sana', 'sangat', 'santai', 'saran', 'sebab', 'sebut', 'sedia', 'sedih', 'sedikit', 'segala', 'segar', 'segera', 'sehat', 'sekali', 'sekaligus', 'sekarang', 'sekitar', 'selalu', 'selamat', 'selesai', 'semangat', 'sembuh', 'sempurna', 'semua', 'senang', 'sendiri', 'seperti', 'sering', 'serta', 'sesi', 'sesuatu', 'siap', 'siapa', 'sibuk', 'sih', 'sikap', 'singgung', 'singkat', 'sini', 'sistem', 'situasi', 'solusi', 'sosial', 'spesial', 'stabil', 'stigma', 'stres', 'suara', 'suasana', 'sudah', 'suka', 'sulit', 'syukur', 'tahan', 'tahu', 'tak', 'takut', 'tanda', 'tangan', 'tanya', 'tarik', 'tegang', 'tekan', 'teknik', 'telepon', 'tempat', 'temu', 'tenang', 'tentang', 'tentu', 'tepat', 'terap', 'terapi', 'terima', 'terlalu', 'terus', 'tes', 'tetap', 'tiap', 'tiba', 'tidak', 'tidur', 'tinggal', 'tingkat', 'tips', 'tolong', 'tonjol', 'trauma', 'tua', 'tubuh', 'tuju', 'tunjuk', 'turun', 'uang', 'ubah', 'ujung', 'umum', 'untung', 'utama', 'waktu', 'waris', 'warna', 'waspada', 'ya', 'yoga']\n"
     ]
    }
   ],
   "source": [
    "# Melakukan stemming dan normalisasi data\n",
    "words = [stemmer.stem(w.lower()) for w in words if w not in ignore]\n",
    "words = sorted(list(set(words)))\n",
    "\n",
    "# Menghapus class duplikat dengan 'set'\n",
    "classes = sorted(list(set(classes)))\n",
    "\n",
    "print(len(documents), \"documents\")\n",
    "print(len(classes), \"classes\", classes)\n",
    "print(len(words), \"unique stemmed words\", words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "o3bG67i3yL2q"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "training = []\n",
    "output_empty = [0] * len(classes)\n",
    "\n",
    "for doc in documents:\n",
    "    pattern_words = [stemmer.stem(word.lower()) for word in doc[0]]\n",
    "    bag = [1 if w in pattern_words else 0 for w in words]\n",
    "\n",
    "    output_row = output_empty[:]\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "\n",
    "    training.append([bag, output_row])\n",
    "\n",
    "random.shuffle(training)\n",
    "training = np.array(training, dtype=object)\n",
    "\n",
    "train_x = np.array([item[0] for item in training])\n",
    "train_y = np.array([item[1] for item in training])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "        layers.Input(shape=(len(train_x[0]),), name='input_layer'),\n",
    "        layers.Dense(256, activation='relu', kernel_regularizer='l2', name='hidden_layer1'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3, name='dropout1'),\n",
    "        layers.Dense(128, activation='relu', kernel_regularizer='l2', name='hidden_layer2'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3, name='dropout2'),\n",
    "        layers.Dense(len(train_y[0]), activation='softmax', name='output_layer')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ hidden_layer1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">113,152</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ hidden_layer2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">47</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,063</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ hidden_layer1 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m113,152\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout1 (\u001b[38;5;33mDropout\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ hidden_layer2 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout2 (\u001b[38;5;33mDropout\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m47\u001b[0m)                  │           \u001b[38;5;34m6,063\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">153,647</span> (600.18 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m153,647\u001b[0m (600.18 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">152,879</span> (597.18 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m152,879\u001b[0m (597.18 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = callbacks.EarlyStopping(patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K_FOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2j75XSbGyalB",
    "outputId": "bbad24ff-51fd-4440-d144-bfe4011cf099"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dzikr\\AppData\\Local\\Temp\\ipykernel_16152\\3785205646.py:1: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "\n",
      "=== Training Fold 1/5 ===\n",
      "Epoch 1/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.0297 - loss: 9.5115 - val_accuracy: 0.0155 - val_loss: 8.2621\n",
      "Epoch 2/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0453 - loss: 8.6411 - val_accuracy: 0.0155 - val_loss: 7.9838\n",
      "Epoch 3/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0693 - loss: 8.1164 - val_accuracy: 0.0363 - val_loss: 7.6542\n",
      "Epoch 4/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1003 - loss: 7.4918 - val_accuracy: 0.0881 - val_loss: 7.2704\n",
      "Epoch 5/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1344 - loss: 7.0643 - val_accuracy: 0.1295 - val_loss: 6.8518\n",
      "Epoch 6/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1888 - loss: 6.7148 - val_accuracy: 0.2228 - val_loss: 6.4643\n",
      "Epoch 7/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1818 - loss: 6.5483 - val_accuracy: 0.2953 - val_loss: 6.1742\n",
      "Epoch 8/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2917 - loss: 6.1169 - val_accuracy: 0.3420 - val_loss: 5.9271\n",
      "Epoch 9/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2721 - loss: 5.9841 - val_accuracy: 0.3990 - val_loss: 5.7339\n",
      "Epoch 10/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3354 - loss: 5.8066 - val_accuracy: 0.4301 - val_loss: 5.5607\n",
      "Epoch 11/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4207 - loss: 5.5558 - val_accuracy: 0.4404 - val_loss: 5.4273\n",
      "Epoch 12/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3993 - loss: 5.4500 - val_accuracy: 0.4663 - val_loss: 5.2904\n",
      "Epoch 13/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4671 - loss: 5.1483 - val_accuracy: 0.4767 - val_loss: 5.1792\n",
      "Epoch 14/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4864 - loss: 5.0514 - val_accuracy: 0.5078 - val_loss: 5.0569\n",
      "Epoch 15/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5218 - loss: 4.9619 - val_accuracy: 0.5026 - val_loss: 4.9647\n",
      "Epoch 16/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5652 - loss: 4.7896 - val_accuracy: 0.5337 - val_loss: 4.8726\n",
      "Epoch 17/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5528 - loss: 4.7696 - val_accuracy: 0.5492 - val_loss: 4.7803\n",
      "Epoch 18/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6339 - loss: 4.5445 - val_accuracy: 0.5751 - val_loss: 4.6926\n",
      "Epoch 19/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6399 - loss: 4.4394 - val_accuracy: 0.5907 - val_loss: 4.6117\n",
      "Epoch 20/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6342 - loss: 4.3491 - val_accuracy: 0.5803 - val_loss: 4.5312\n",
      "Epoch 21/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6320 - loss: 4.3622 - val_accuracy: 0.5907 - val_loss: 4.4582\n",
      "Epoch 22/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7019 - loss: 4.1612 - val_accuracy: 0.6166 - val_loss: 4.3881\n",
      "Epoch 23/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7194 - loss: 4.0489 - val_accuracy: 0.6062 - val_loss: 4.3209\n",
      "Epoch 24/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6867 - loss: 4.0648 - val_accuracy: 0.6114 - val_loss: 4.2524\n",
      "Epoch 25/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7383 - loss: 3.8758 - val_accuracy: 0.6114 - val_loss: 4.2047\n",
      "Epoch 26/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7577 - loss: 3.7930 - val_accuracy: 0.6010 - val_loss: 4.1525\n",
      "Epoch 27/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7833 - loss: 3.6834 - val_accuracy: 0.6166 - val_loss: 4.0939\n",
      "Epoch 28/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7718 - loss: 3.6753 - val_accuracy: 0.6218 - val_loss: 4.0328\n",
      "Epoch 29/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7804 - loss: 3.6349 - val_accuracy: 0.6321 - val_loss: 3.9812\n",
      "Epoch 30/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8164 - loss: 3.5491 - val_accuracy: 0.6062 - val_loss: 3.9349\n",
      "Epoch 31/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7900 - loss: 3.5161 - val_accuracy: 0.6166 - val_loss: 3.8837\n",
      "Epoch 32/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8052 - loss: 3.4554 - val_accuracy: 0.6166 - val_loss: 3.8456\n",
      "Epoch 33/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8084 - loss: 3.3688 - val_accuracy: 0.6218 - val_loss: 3.8032\n",
      "Epoch 34/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8346 - loss: 3.2791 - val_accuracy: 0.6269 - val_loss: 3.7607\n",
      "Epoch 35/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8406 - loss: 3.1924 - val_accuracy: 0.6166 - val_loss: 3.7244\n",
      "Epoch 36/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8480 - loss: 3.1604 - val_accuracy: 0.6321 - val_loss: 3.6767\n",
      "Epoch 37/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8434 - loss: 3.1284 - val_accuracy: 0.6269 - val_loss: 3.6394\n",
      "Epoch 38/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8322 - loss: 3.0464 - val_accuracy: 0.6269 - val_loss: 3.6086\n",
      "Epoch 39/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8524 - loss: 3.0115 - val_accuracy: 0.6321 - val_loss: 3.5665\n",
      "Epoch 40/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8583 - loss: 2.9578 - val_accuracy: 0.6269 - val_loss: 3.5208\n",
      "Epoch 41/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8622 - loss: 2.8565 - val_accuracy: 0.6373 - val_loss: 3.4916\n",
      "Epoch 42/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8625 - loss: 2.8687 - val_accuracy: 0.6528 - val_loss: 3.4413\n",
      "Epoch 43/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8892 - loss: 2.7745 - val_accuracy: 0.6425 - val_loss: 3.4137\n",
      "Epoch 44/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8941 - loss: 2.7032 - val_accuracy: 0.6477 - val_loss: 3.3804\n",
      "Epoch 45/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8929 - loss: 2.6716 - val_accuracy: 0.6477 - val_loss: 3.3507\n",
      "Epoch 46/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9012 - loss: 2.6037 - val_accuracy: 0.6788 - val_loss: 3.3066\n",
      "Epoch 47/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8712 - loss: 2.6287 - val_accuracy: 0.6736 - val_loss: 3.2684\n",
      "Epoch 48/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8808 - loss: 2.6143 - val_accuracy: 0.6528 - val_loss: 3.2430\n",
      "Epoch 49/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9165 - loss: 2.4923 - val_accuracy: 0.6580 - val_loss: 3.2197\n",
      "Epoch 50/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8729 - loss: 2.5192 - val_accuracy: 0.6528 - val_loss: 3.1844\n",
      "Epoch 51/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9210 - loss: 2.3896 - val_accuracy: 0.6528 - val_loss: 3.1521\n",
      "Epoch 52/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8954 - loss: 2.3619 - val_accuracy: 0.6580 - val_loss: 3.1194\n",
      "Epoch 53/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9127 - loss: 2.2883 - val_accuracy: 0.6580 - val_loss: 3.0878\n",
      "Epoch 54/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9217 - loss: 2.2618 - val_accuracy: 0.6580 - val_loss: 3.0607\n",
      "Epoch 55/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9245 - loss: 2.2233 - val_accuracy: 0.6632 - val_loss: 3.0313\n",
      "Epoch 56/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9271 - loss: 2.1936 - val_accuracy: 0.6580 - val_loss: 3.0249\n",
      "Epoch 57/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9199 - loss: 2.1868 - val_accuracy: 0.6477 - val_loss: 3.0085\n",
      "Epoch 58/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9401 - loss: 2.1015 - val_accuracy: 0.6477 - val_loss: 2.9861\n",
      "Epoch 59/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9449 - loss: 2.0595 - val_accuracy: 0.6528 - val_loss: 2.9617\n",
      "Epoch 60/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9394 - loss: 2.0131 - val_accuracy: 0.6425 - val_loss: 2.9384\n",
      "Epoch 61/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9259 - loss: 1.9951 - val_accuracy: 0.6425 - val_loss: 2.9164\n",
      "Epoch 62/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9352 - loss: 2.0106 - val_accuracy: 0.6477 - val_loss: 2.8827\n",
      "Epoch 63/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9433 - loss: 1.9346 - val_accuracy: 0.6528 - val_loss: 2.8447\n",
      "Epoch 64/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9274 - loss: 1.9292 - val_accuracy: 0.6528 - val_loss: 2.8357\n",
      "Epoch 65/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9510 - loss: 1.8799 - val_accuracy: 0.6632 - val_loss: 2.8061\n",
      "Epoch 66/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9481 - loss: 1.8353 - val_accuracy: 0.6632 - val_loss: 2.7865\n",
      "Epoch 67/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9282 - loss: 1.8612 - val_accuracy: 0.6632 - val_loss: 2.7582\n",
      "Epoch 68/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9498 - loss: 1.7490 - val_accuracy: 0.6528 - val_loss: 2.7324\n",
      "Epoch 69/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9583 - loss: 1.7298 - val_accuracy: 0.6632 - val_loss: 2.7025\n",
      "Epoch 70/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9392 - loss: 1.7260 - val_accuracy: 0.6580 - val_loss: 2.7081\n",
      "Epoch 71/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9433 - loss: 1.6726 - val_accuracy: 0.6580 - val_loss: 2.6613\n",
      "Epoch 72/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9589 - loss: 1.6298 - val_accuracy: 0.6580 - val_loss: 2.6473\n",
      "Epoch 73/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9438 - loss: 1.6280 - val_accuracy: 0.6632 - val_loss: 2.6278\n",
      "Epoch 74/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9573 - loss: 1.5888 - val_accuracy: 0.6477 - val_loss: 2.6181\n",
      "Epoch 75/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9494 - loss: 1.5984 - val_accuracy: 0.6632 - val_loss: 2.5841\n",
      "Epoch 76/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9596 - loss: 1.5219 - val_accuracy: 0.6580 - val_loss: 2.5806\n",
      "Epoch 77/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9563 - loss: 1.5300 - val_accuracy: 0.6632 - val_loss: 2.5799\n",
      "Epoch 78/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9568 - loss: 1.4852 - val_accuracy: 0.6632 - val_loss: 2.5719\n",
      "Epoch 79/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9597 - loss: 1.4671 - val_accuracy: 0.6684 - val_loss: 2.5526\n",
      "Epoch 80/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9540 - loss: 1.4341 - val_accuracy: 0.6632 - val_loss: 2.5494\n",
      "Epoch 81/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9722 - loss: 1.3955 - val_accuracy: 0.6477 - val_loss: 2.5309\n",
      "Epoch 82/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9699 - loss: 1.3762 - val_accuracy: 0.6425 - val_loss: 2.5243\n",
      "Epoch 83/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9707 - loss: 1.3347 - val_accuracy: 0.6580 - val_loss: 2.4821\n",
      "Epoch 84/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9633 - loss: 1.3274 - val_accuracy: 0.6528 - val_loss: 2.4824\n",
      "Epoch 85/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9652 - loss: 1.3071 - val_accuracy: 0.6632 - val_loss: 2.4909\n",
      "Epoch 86/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9625 - loss: 1.2971 - val_accuracy: 0.6788 - val_loss: 2.4782\n",
      "Epoch 87/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9608 - loss: 1.2422 - val_accuracy: 0.6788 - val_loss: 2.4369\n",
      "Epoch 88/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9589 - loss: 1.2768 - val_accuracy: 0.6632 - val_loss: 2.4359\n",
      "Epoch 89/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9787 - loss: 1.2064 - val_accuracy: 0.6528 - val_loss: 2.4351\n",
      "Epoch 90/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9656 - loss: 1.2149 - val_accuracy: 0.6528 - val_loss: 2.4177\n",
      "Epoch 91/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9662 - loss: 1.1916 - val_accuracy: 0.6580 - val_loss: 2.4187\n",
      "Epoch 92/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9751 - loss: 1.1501 - val_accuracy: 0.6528 - val_loss: 2.3993\n",
      "Epoch 93/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9675 - loss: 1.1309 - val_accuracy: 0.6632 - val_loss: 2.3738\n",
      "Epoch 94/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9683 - loss: 1.1057 - val_accuracy: 0.6632 - val_loss: 2.3476\n",
      "Epoch 95/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9670 - loss: 1.0869 - val_accuracy: 0.6580 - val_loss: 2.3435\n",
      "Epoch 96/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9789 - loss: 1.0592 - val_accuracy: 0.6736 - val_loss: 2.3083\n",
      "Epoch 97/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9879 - loss: 1.0431 - val_accuracy: 0.6788 - val_loss: 2.2984\n",
      "Epoch 98/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9725 - loss: 1.0264 - val_accuracy: 0.6684 - val_loss: 2.3345\n",
      "Epoch 99/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9452 - loss: 1.0623 - val_accuracy: 0.6839 - val_loss: 2.3020\n",
      "Epoch 100/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9695 - loss: 1.0037 - val_accuracy: 0.6736 - val_loss: 2.2854\n",
      "Fold 1 - Validation Accuracy: 0.6736\n",
      "\n",
      "=== Training Fold 2/5 ===\n",
      "Epoch 1/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8811 - loss: 1.3771 - val_accuracy: 0.9689 - val_loss: 0.8607\n",
      "Epoch 2/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8982 - loss: 1.2103 - val_accuracy: 0.9637 - val_loss: 0.8625\n",
      "Epoch 3/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8920 - loss: 1.1747 - val_accuracy: 0.9637 - val_loss: 0.8756\n",
      "Epoch 4/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9094 - loss: 1.1547 - val_accuracy: 0.9585 - val_loss: 0.8767\n",
      "Epoch 5/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9315 - loss: 1.0470 - val_accuracy: 0.9430 - val_loss: 0.8884\n",
      "Epoch 6/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9346 - loss: 1.0276 - val_accuracy: 0.9430 - val_loss: 0.8873\n",
      "Epoch 7/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9259 - loss: 1.0242 - val_accuracy: 0.9378 - val_loss: 0.8968\n",
      "Epoch 8/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9514 - loss: 0.9682 - val_accuracy: 0.9275 - val_loss: 0.9128\n",
      "Epoch 9/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9386 - loss: 0.9714 - val_accuracy: 0.9275 - val_loss: 0.9264\n",
      "Epoch 10/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9496 - loss: 0.9345 - val_accuracy: 0.9223 - val_loss: 0.9274\n",
      "Epoch 11/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9498 - loss: 0.9793 - val_accuracy: 0.9119 - val_loss: 0.9309\n",
      "Fold 2 - Validation Accuracy: 0.9689\n",
      "\n",
      "=== Training Fold 3/5 ===\n",
      "Epoch 1/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8705 - loss: 1.3088 - val_accuracy: 0.9896 - val_loss: 0.8035\n",
      "Epoch 2/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8775 - loss: 1.2018 - val_accuracy: 0.9896 - val_loss: 0.8171\n",
      "Epoch 3/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8870 - loss: 1.1361 - val_accuracy: 0.9585 - val_loss: 0.8292\n",
      "Epoch 4/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9134 - loss: 1.0583 - val_accuracy: 0.9482 - val_loss: 0.8417\n",
      "Epoch 5/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9159 - loss: 1.0416 - val_accuracy: 0.9378 - val_loss: 0.8467\n",
      "Epoch 6/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8700 - loss: 1.0977 - val_accuracy: 0.9326 - val_loss: 0.8591\n",
      "Epoch 7/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9090 - loss: 1.0418 - val_accuracy: 0.9275 - val_loss: 0.8798\n",
      "Epoch 8/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9107 - loss: 1.0270 - val_accuracy: 0.9275 - val_loss: 0.8798\n",
      "Epoch 9/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9386 - loss: 0.9575 - val_accuracy: 0.9275 - val_loss: 0.8743\n",
      "Epoch 10/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9378 - loss: 0.9575 - val_accuracy: 0.9223 - val_loss: 0.8865\n",
      "Epoch 11/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9262 - loss: 0.9431 - val_accuracy: 0.9171 - val_loss: 0.8887\n",
      "Fold 3 - Validation Accuracy: 0.9896\n",
      "\n",
      "=== Training Fold 4/5 ===\n",
      "Epoch 1/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8780 - loss: 1.1403 - val_accuracy: 0.9793 - val_loss: 0.7857\n",
      "Epoch 2/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8768 - loss: 1.1474 - val_accuracy: 0.9689 - val_loss: 0.8139\n",
      "Epoch 3/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8812 - loss: 1.1420 - val_accuracy: 0.9378 - val_loss: 0.8450\n",
      "Epoch 4/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9101 - loss: 1.0710 - val_accuracy: 0.9275 - val_loss: 0.8804\n",
      "Epoch 5/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8983 - loss: 0.9859 - val_accuracy: 0.9275 - val_loss: 0.8872\n",
      "Epoch 6/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9100 - loss: 1.0190 - val_accuracy: 0.9223 - val_loss: 0.9060\n",
      "Epoch 7/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8973 - loss: 1.0312 - val_accuracy: 0.9119 - val_loss: 0.9215\n",
      "Epoch 8/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9108 - loss: 0.9758 - val_accuracy: 0.9119 - val_loss: 0.9316\n",
      "Epoch 9/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9191 - loss: 0.9369 - val_accuracy: 0.9067 - val_loss: 0.9376\n",
      "Epoch 10/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9238 - loss: 0.9257 - val_accuracy: 0.9067 - val_loss: 0.9446\n",
      "Epoch 11/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9069 - loss: 0.9304 - val_accuracy: 0.9016 - val_loss: 0.9470\n",
      "Fold 4 - Validation Accuracy: 0.9793\n",
      "\n",
      "=== Training Fold 5/5 ===\n",
      "Epoch 1/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8369 - loss: 1.2852 - val_accuracy: 0.9793 - val_loss: 0.7685\n",
      "Epoch 2/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8528 - loss: 1.1994 - val_accuracy: 0.9585 - val_loss: 0.8015\n",
      "Epoch 3/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8874 - loss: 1.1050 - val_accuracy: 0.9482 - val_loss: 0.8185\n",
      "Epoch 4/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9023 - loss: 1.0100 - val_accuracy: 0.9482 - val_loss: 0.8313\n",
      "Epoch 5/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8788 - loss: 1.0996 - val_accuracy: 0.9275 - val_loss: 0.8460\n",
      "Epoch 6/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9104 - loss: 0.9983 - val_accuracy: 0.9275 - val_loss: 0.8423\n",
      "Epoch 7/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9139 - loss: 0.9434 - val_accuracy: 0.9275 - val_loss: 0.8493\n",
      "Epoch 8/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9076 - loss: 0.9704 - val_accuracy: 0.9378 - val_loss: 0.8579\n",
      "Epoch 9/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9188 - loss: 0.9227 - val_accuracy: 0.9275 - val_loss: 0.8673\n",
      "Epoch 10/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9344 - loss: 0.8764 - val_accuracy: 0.9223 - val_loss: 0.8735\n",
      "Epoch 11/100\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9313 - loss: 0.8757 - val_accuracy: 0.9223 - val_loss: 0.8712\n",
      "Fold 5 - Validation Accuracy: 0.9793\n",
      "\n",
      "=== Average Validation Accuracy: 0.9181 ===\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "# Hyperparameters\n",
    "num_folds = 5\n",
    "batch_size = 8\n",
    "learning_rate = 1e-4\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "fold_accuracies = []\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(train_x)):\n",
    "    print(f\"\\n=== Training Fold {fold + 1}/{num_folds} ===\")\n",
    "    \n",
    "    X_train, X_val = train_x[train_index], train_x[val_index]\n",
    "    y_train, y_val = train_y[train_index], train_y[val_index]\n",
    "\n",
    "    tensorboard_callback = callbacks.TensorBoard(log_dir=f'./logs/fold_{fold+1}')\n",
    "    early_stopping_callback = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    \n",
    "    optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[tensorboard_callback, early_stopping_callback],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "    print(f\"Fold {fold + 1} - Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    fold_accuracies.append(val_accuracy)\n",
    "    \n",
    "avg_accuracy = np.mean(fold_accuracies)\n",
    "print(f\"\\n=== Average Validation Accuracy: {avg_accuracy:.4f} ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training tanpa split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8873 - loss: 1.1281\n",
      "Epoch 2/100\n",
      "\u001b[1m 63/121\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8554 - loss: 1.1682"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dzikr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\callbacks\\early_stopping.py:155: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: accuracy,loss\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8576 - loss: 1.1474\n",
      "Epoch 3/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8716 - loss: 1.0758\n",
      "Epoch 4/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9032 - loss: 1.0269\n",
      "Epoch 5/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8839 - loss: 1.0117\n",
      "Epoch 6/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9031 - loss: 0.9442\n",
      "Epoch 7/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9180 - loss: 0.9036\n",
      "Epoch 8/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9035 - loss: 0.9113\n",
      "Epoch 9/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9108 - loss: 0.9096\n",
      "Epoch 10/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9322 - loss: 0.8567\n",
      "Epoch 11/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9222 - loss: 0.8650\n",
      "Epoch 12/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9437 - loss: 0.8242\n",
      "Epoch 13/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9315 - loss: 0.8232\n",
      "Epoch 14/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9476 - loss: 0.7729\n",
      "Epoch 15/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9525 - loss: 0.7730\n",
      "Epoch 16/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9559 - loss: 0.7376\n",
      "Epoch 17/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9444 - loss: 0.7913\n",
      "Epoch 18/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9562 - loss: 0.7365\n",
      "Epoch 19/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9474 - loss: 0.7568\n",
      "Epoch 20/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9449 - loss: 0.7405\n",
      "Epoch 21/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9657 - loss: 0.6971\n",
      "Epoch 22/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9630 - loss: 0.7018\n",
      "Epoch 23/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9485 - loss: 0.7086\n",
      "Epoch 24/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9689 - loss: 0.6480\n",
      "Epoch 25/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9651 - loss: 0.6706\n",
      "Epoch 26/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9496 - loss: 0.6710\n",
      "Epoch 27/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9666 - loss: 0.6521\n",
      "Epoch 28/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9667 - loss: 0.6589\n",
      "Epoch 29/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9563 - loss: 0.6487\n",
      "Epoch 30/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9728 - loss: 0.6312\n",
      "Epoch 31/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9621 - loss: 0.6376\n",
      "Epoch 32/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9703 - loss: 0.5977\n",
      "Epoch 33/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9706 - loss: 0.5963\n",
      "Epoch 34/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9597 - loss: 0.6131\n",
      "Epoch 35/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9781 - loss: 0.5588\n",
      "Epoch 36/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9751 - loss: 0.5743\n",
      "Epoch 37/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9623 - loss: 0.5915\n",
      "Epoch 38/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9730 - loss: 0.5697\n",
      "Epoch 39/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9621 - loss: 0.5762\n",
      "Epoch 40/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9704 - loss: 0.5532\n",
      "Epoch 41/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9667 - loss: 0.5543\n",
      "Epoch 42/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9753 - loss: 0.5249\n",
      "Epoch 43/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9663 - loss: 0.5359\n",
      "Epoch 44/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.5412\n",
      "Epoch 45/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9680 - loss: 0.5203\n",
      "Epoch 46/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9606 - loss: 0.5334\n",
      "Epoch 47/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9691 - loss: 0.4990\n",
      "Epoch 48/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9721 - loss: 0.5044\n",
      "Epoch 49/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9707 - loss: 0.4996\n",
      "Epoch 50/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9647 - loss: 0.5035\n",
      "Epoch 51/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9724 - loss: 0.4816\n",
      "Epoch 52/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9669 - loss: 0.4865\n",
      "Epoch 53/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9717 - loss: 0.4642\n",
      "Epoch 54/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9668 - loss: 0.4846\n",
      "Epoch 55/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9802 - loss: 0.4488\n",
      "Epoch 56/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9586 - loss: 0.4798\n",
      "Epoch 57/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9749 - loss: 0.4592\n",
      "Epoch 58/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9702 - loss: 0.4471\n",
      "Epoch 59/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9619 - loss: 0.4567\n",
      "Epoch 60/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9777 - loss: 0.4201\n",
      "Epoch 61/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9682 - loss: 0.4398\n",
      "Epoch 62/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9709 - loss: 0.4149\n",
      "Epoch 63/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9604 - loss: 0.4434\n",
      "Epoch 64/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9635 - loss: 0.4520\n",
      "Epoch 65/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9788 - loss: 0.4001\n",
      "Epoch 66/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9746 - loss: 0.3951\n",
      "Epoch 67/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9765 - loss: 0.3985\n",
      "Epoch 68/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9582 - loss: 0.4454\n",
      "Epoch 69/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9810 - loss: 0.3971\n",
      "Epoch 70/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9779 - loss: 0.3795\n",
      "Epoch 71/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9739 - loss: 0.3806\n",
      "Epoch 72/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9707 - loss: 0.3760\n",
      "Epoch 73/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9792 - loss: 0.3635\n",
      "Epoch 74/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9572 - loss: 0.4011\n",
      "Epoch 75/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9726 - loss: 0.3915\n",
      "Epoch 76/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9734 - loss: 0.3726\n",
      "Epoch 77/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9848 - loss: 0.3612\n",
      "Epoch 78/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9665 - loss: 0.3659\n",
      "Epoch 79/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9792 - loss: 0.3513\n",
      "Epoch 80/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9754 - loss: 0.3476\n",
      "Epoch 81/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9749 - loss: 0.3549\n",
      "Epoch 82/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9694 - loss: 0.3465\n",
      "Epoch 83/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9760 - loss: 0.3323\n",
      "Epoch 84/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9858 - loss: 0.3218\n",
      "Epoch 85/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9727 - loss: 0.3458\n",
      "Epoch 86/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9848 - loss: 0.3096\n",
      "Epoch 87/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9681 - loss: 0.3407\n",
      "Epoch 88/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9814 - loss: 0.3092\n",
      "Epoch 89/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9858 - loss: 0.3092\n",
      "Epoch 90/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9741 - loss: 0.3587\n",
      "Epoch 91/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9762 - loss: 0.3217\n",
      "Epoch 92/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9911 - loss: 0.3046\n",
      "Epoch 93/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9637 - loss: 0.3482\n",
      "Epoch 94/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9769 - loss: 0.3156\n",
      "Epoch 95/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9686 - loss: 0.3229\n",
      "Epoch 96/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9746 - loss: 0.3100\n",
      "Epoch 97/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9687 - loss: 0.2996\n",
      "Epoch 98/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9712 - loss: 0.3118\n",
      "Epoch 99/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9676 - loss: 0.3026\n",
      "Epoch 100/100\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9729 - loss: 0.2905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train and save the final model\n",
    "model.fit(train_x, train_y, epochs=100, batch_size=8, callbacks=[tensorboard_callback, early_stopping_callback], verbose=1)\n",
    "model.save('final_model_trained_on_full_data.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save\n",
    "try:\n",
    "    with open(\"training_data.json\", \"w\") as file:\n",
    "        # Convert non-serializable data like NumPy arrays or other objects to lists\n",
    "        data = {'words': words, 'classes': classes, 'train_x': train_x.tolist(), 'train_y': train_y.tolist()}\n",
    "        json.dump(data, file)\n",
    "except IOError as e:\n",
    "    print(f\"Error saving training data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "try:\n",
    "    with open(\"training_data\", \"wb\") as file:\n",
    "        pickle.dump({'words': words, 'classes': classes, 'train_x': train_x, 'train_y': train_y}, file)\n",
    "except IOError as e:\n",
    "    print(f\"Error saving training data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DrOW8S1Y0un5",
    "outputId": "eae11a39-7021-45a3-d529-8717486e4090"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Load\n",
    "try:\n",
    "    with open(\"training_data\", \"rb\") as file:\n",
    "        data = pickle.load(file)\n",
    "\n",
    "    words = data['words']\n",
    "    classes = data['classes']\n",
    "    train_x = np.array(data['train_x'])\n",
    "    train_y = np.array(data['train_y'])\n",
    "except IOError as e:\n",
    "    print(f\"Error loading training data: {e}\")\n",
    "\n",
    "# Load model\n",
    "try:\n",
    "    model = keras.models.load_model('final_model_trained_on_full_data.h5')\n",
    "except IOError as e:\n",
    "    print(f\"Error loading model: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "XVD-P16Q19Ar"
   },
   "outputs": [],
   "source": [
    "def clean_up_sentence(sentence):\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    sentence_words = [stemmer.stem(word.lower()) for word in sentence_words]\n",
    "    return sentence_words\n",
    "\n",
    "def bow(sentence, words, show_details=False):\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    bag = np.zeros(len(words), dtype=np.float32)\n",
    "    for idx, w in enumerate(words):\n",
    "        if w in sentence_words:\n",
    "            bag[idx] = 1\n",
    "            if show_details:\n",
    "                print(f\"Found in bag: {w}\")\n",
    "    return bag\n",
    "\n",
    "ERROR_THRESHOLD = 0.70\n",
    "\n",
    "\n",
    "\n",
    "def classify(sentence):\n",
    "    input_data = bow(sentence, words)\n",
    "    results = model.predict(np.array([input_data]))[0]\n",
    "    results = [[i, r] for i, r in enumerate(results) if r >= ERROR_THRESHOLD]\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return [(classes[r[0]], r[1]) for r in results]\n",
    "\n",
    "def response(sentence, userID='123', show_details=False):\n",
    "    results = classify(sentence)\n",
    "    if results:\n",
    "        for intent in intents:\n",
    "            if intent['tag'] == results[0][0]:\n",
    "                return random.choice(intent['responses'])\n",
    "    return \"Maaf, saya belum mengerti apa yang Anda bicarakan, perlu bantuan?.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FO4ujct85h_h",
    "outputId": "a2cddf3f-f8f6-46fa-f780-79074e416a53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 to close\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 0\n"
     ]
    }
   ],
   "source": [
    "print(\"0 to close\")\n",
    "while True:\n",
    "    message = input(\"\")\n",
    "    if message == \"0\":\n",
    "        break\n",
    "    result = response(message)\n",
    "\n",
    "    if result is not None and \"~\" in result:\n",
    "        order = (result[1:])\n",
    "        action(order)\n",
    "    else:\n",
    "        print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xRRvDLhl0kI_",
    "outputId": "180f72b1-0bec-45f4-eb82-9b704c1713d2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\dzikr\\AppData\\Local\\Temp\\tmpiossyh0y\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\dzikr\\AppData\\Local\\Temp\\tmpiossyh0y\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\dzikr\\AppData\\Local\\Temp\\tmpiossyh0y'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 441), dtype=tf.float32, name='input_layer')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 47), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2601258342480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2601258344976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2601258345360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2601258343632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2601258344208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2601258346128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2601258344400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2601258348240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2601258347088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2601258347856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2601258347472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2601258349008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2601258348432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2601258351120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('final_model_trained_on_full_data.h5')\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "\n",
    "with open('model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
